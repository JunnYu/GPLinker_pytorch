03/01/2022 11:23:23 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Use FP16 precision: False

03/01/2022 11:23:33 - WARNING - datasets.builder - No config specified, defaulting to: spo/spo
03/01/2022 11:24:34 - INFO - utils.data - Sample 167621 of the training set:
03/01/2022 11:24:34 - INFO - utils.data - input_ids = [101, 8121, 3698, 952, 756, 2128, 1277, 1765, 1905, 762, 4178, 2372, 2108, 7599, 3698, 952, 8024, 3698, 952, 3946, 1469, 8024, 1724, 2108, 1146, 3209, 8024, 7433, 7030, 1041, 3764, 102]
03/01/2022 11:24:34 - INFO - utils.data - attention_mask = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
03/01/2022 11:24:34 - INFO - utils.data - labels = [[4, 6, 44, 9, 15]]
03/01/2022 11:24:37 - INFO - __main__ - ********** Running training **********
03/01/2022 11:24:37 - INFO - __main__ -   Num examples = 172858
03/01/2022 11:24:37 - INFO - __main__ -   Num Epochs = 20
03/01/2022 11:24:37 - INFO - __main__ -   Instantaneous batch size per device = 16
03/01/2022 11:24:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
03/01/2022 11:24:37 - INFO - __main__ -   Gradient Accumulation steps = 1
03/01/2022 11:24:37 - INFO - __main__ -   Gradient Accumulation steps = 1
03/01/2022 11:24:37 - INFO - __main__ -   Total optimization steps = 216080
03/01/2022 11:24:37 - INFO - __main__ - **********  Configuration Arguments **********
03/01/2022 11:24:37 - INFO - __main__ - adam_epsilon: 1e-08
03/01/2022 11:24:37 - INFO - __main__ - cache_dir: data_caches
03/01/2022 11:24:37 - INFO - __main__ - gradient_accumulation_steps: 1
03/01/2022 11:24:37 - INFO - __main__ - id2predicate: {0: '祖籍', 1: '父亲', 2: '总部地点', 3: '出生地', 4: '目', 5: '面积', 6: '简称', 7: '上映时间', 8: '妻子', 9: '所属专辑', 10: '注册资本', 11: '首都', 12: '导演', 13: '字', 14: '身高', 15: '出品公司', 16: '修业年限', 17: '出生日期', 18: '制片人', 19: '母亲', 20: '编剧', 21: '国籍', 22: '海拔', 23: '连载网站', 24: '丈夫', 25: '朝代', 26: '民族', 27: '号', 28: '出版社', 29: '主持人', 30: '专业代码', 31: '歌手', 32: '作词', 33: '主角', 34: '董事长', 35: '成立日期', 36: '毕业院校', 37: '占地面积', 38: '官方语言', 39: '邮政编码', 40: '人口数量', 41: '所在城市', 42: '作者', 43: '作曲', 44: '气候', 45: '嘉宾', 46: '主演', 47: '改编自', 48: '创始人'}
03/01/2022 11:24:37 - INFO - __main__ - id2tag: {0: '祖籍=SH2OH', 1: '父亲=SH2OH', 2: '总部地点=SH2OH', 3: '出生地=SH2OH', 4: '目=SH2OH', 5: '面积=SH2OH', 6: '简称=SH2OH', 7: '上映时间=SH2OH', 8: '妻子=SH2OH', 9: '所属专辑=SH2OH', 10: '注册资本=SH2OH', 11: '首都=SH2OH', 12: '导演=SH2OH', 13: '字=SH2OH', 14: '身高=SH2OH', 15: '出品公司=SH2OH', 16: '修业年限=SH2OH', 17: '出生日期=SH2OH', 18: '制片人=SH2OH', 19: '母亲=SH2OH', 20: '编剧=SH2OH', 21: '国籍=SH2OH', 22: '海拔=SH2OH', 23: '连载网站=SH2OH', 24: '丈夫=SH2OH', 25: '朝代=SH2OH', 26: '民族=SH2OH', 27: '号=SH2OH', 28: '出版社=SH2OH', 29: '主持人=SH2OH', 30: '专业代码=SH2OH', 31: '歌手=SH2OH', 32: '作词=SH2OH', 33: '主角=SH2OH', 34: '董事长=SH2OH', 35: '成立日期=SH2OH', 36: '毕业院校=SH2OH', 37: '占地面积=SH2OH', 38: '官方语言=SH2OH', 39: '邮政编码=SH2OH', 40: '人口数量=SH2OH', 41: '所在城市=SH2OH', 42: '作者=SH2OH', 43: '作曲=SH2OH', 44: '气候=SH2OH', 45: '嘉宾=SH2OH', 46: '主演=SH2OH', 47: '改编自=SH2OH', 48: '创始人=SH2OH', 49: '祖籍=OH2SH', 50: '父亲=OH2SH', 51: '总部地点=OH2SH', 52: '出生地=OH2SH', 53: '目=OH2SH', 54: '面积=OH2SH', 55: '简称=OH2SH', 56: '上映时间=OH2SH', 57: '妻子=OH2SH', 58: '所属专辑=OH2SH', 59: '注册资本=OH2SH', 60: '首都=OH2SH', 61: '导演=OH2SH', 62: '字=OH2SH', 63: '身高=OH2SH', 64: '出品公司=OH2SH', 65: '修业年限=OH2SH', 66: '出生日期=OH2SH', 67: '制片人=OH2SH', 68: '母亲=OH2SH', 69: '编剧=OH2SH', 70: '国籍=OH2SH', 71: '海拔=OH2SH', 72: '连载网站=OH2SH', 73: '丈夫=OH2SH', 74: '朝代=OH2SH', 75: '民族=OH2SH', 76: '号=OH2SH', 77: '出版社=OH2SH', 78: '主持人=OH2SH', 79: '专业代码=OH2SH', 80: '歌手=OH2SH', 81: '作词=OH2SH', 82: '主角=OH2SH', 83: '董事长=OH2SH', 84: '成立日期=OH2SH', 85: '毕业院校=OH2SH', 86: '占地面积=OH2SH', 87: '官方语言=OH2SH', 88: '邮政编码=OH2SH', 89: '人口数量=OH2SH', 90: '所在城市=OH2SH', 91: '作者=OH2SH', 92: '作曲=OH2SH', 93: '气候=OH2SH', 94: '嘉宾=OH2SH', 95: '主演=OH2SH', 96: '改编自=OH2SH', 97: '创始人=OH2SH', 98: '祖籍=ST2OT', 99: '父亲=ST2OT', 100: '总部地点=ST2OT', 101: '出生地=ST2OT', 102: '目=ST2OT', 103: '面积=ST2OT', 104: '简称=ST2OT', 105: '上映时间=ST2OT', 106: '妻子=ST2OT', 107: '所属专辑=ST2OT', 108: '注册资本=ST2OT', 109: '首都=ST2OT', 110: '导演=ST2OT', 111: '字=ST2OT', 112: '身高=ST2OT', 113: '出品公司=ST2OT', 114: '修业年限=ST2OT', 115: '出生日期=ST2OT', 116: '制片人=ST2OT', 117: '母亲=ST2OT', 118: '编剧=ST2OT', 119: '国籍=ST2OT', 120: '海拔=ST2OT', 121: '连载网站=ST2OT', 122: '丈夫=ST2OT', 123: '朝代=ST2OT', 124: '民族=ST2OT', 125: '号=ST2OT', 126: '出版社=ST2OT', 127: '主持人=ST2OT', 128: '专业代码=ST2OT', 129: '歌手=ST2OT', 130: '作词=ST2OT', 131: '主角=ST2OT', 132: '董事长=ST2OT', 133: '成立日期=ST2OT', 134: '毕业院校=ST2OT', 135: '占地面积=ST2OT', 136: '官方语言=ST2OT', 137: '邮政编码=ST2OT', 138: '人口数量=ST2OT', 139: '所在城市=ST2OT', 140: '作者=ST2OT', 141: '作曲=ST2OT', 142: '气候=ST2OT', 143: '嘉宾=ST2OT', 144: '主演=ST2OT', 145: '改编自=ST2OT', 146: '创始人=ST2OT', 147: '祖籍=OT2ST', 148: '父亲=OT2ST', 149: '总部地点=OT2ST', 150: '出生地=OT2ST', 151: '目=OT2ST', 152: '面积=OT2ST', 153: '简称=OT2ST', 154: '上映时间=OT2ST', 155: '妻子=OT2ST', 156: '所属专辑=OT2ST', 157: '注册资本=OT2ST', 158: '首都=OT2ST', 159: '导演=OT2ST', 160: '字=OT2ST', 161: '身高=OT2ST', 162: '出品公司=OT2ST', 163: '修业年限=OT2ST', 164: '出生日期=OT2ST', 165: '制片人=OT2ST', 166: '母亲=OT2ST', 167: '编剧=OT2ST', 168: '国籍=OT2ST', 169: '海拔=OT2ST', 170: '连载网站=OT2ST', 171: '丈夫=OT2ST', 172: '朝代=OT2ST', 173: '民族=OT2ST', 174: '号=OT2ST', 175: '出版社=OT2ST', 176: '主持人=OT2ST', 177: '专业代码=OT2ST', 178: '歌手=OT2ST', 179: '作词=OT2ST', 180: '主角=OT2ST', 181: '董事长=OT2ST', 182: '成立日期=OT2ST', 183: '毕业院校=OT2ST', 184: '占地面积=OT2ST', 185: '官方语言=OT2ST', 186: '邮政编码=OT2ST', 187: '人口数量=OT2ST', 188: '所在城市=OT2ST', 189: '作者=OT2ST', 190: '作曲=OT2ST', 191: '气候=OT2ST', 192: '嘉宾=OT2ST', 193: '主演=OT2ST', 194: '改编自=OT2ST', 195: '创始人=OT2ST', 196: 'DEFAULT=EH2ET'}
03/01/2022 11:24:37 - INFO - __main__ - learning_rate: 3e-05
03/01/2022 11:24:37 - INFO - __main__ - log_dir: ./outputs/bert-bert-base-chinese/logs
03/01/2022 11:24:37 - INFO - __main__ - logging_steps: 200
03/01/2022 11:24:37 - INFO - __main__ - lr_scheduler_type: linear
03/01/2022 11:24:37 - INFO - __main__ - max_grad_norm: 1.0
03/01/2022 11:24:37 - INFO - __main__ - max_length: 128
03/01/2022 11:24:37 - INFO - __main__ - max_train_steps: 216080
03/01/2022 11:24:37 - INFO - __main__ - method: tplinker_plus
03/01/2022 11:24:37 - INFO - __main__ - model_cache_dir: /mnt/f/hf/models
03/01/2022 11:24:37 - INFO - __main__ - model_type: bert
03/01/2022 11:24:37 - INFO - __main__ - model_weights: bert-base-chinese
03/01/2022 11:24:37 - INFO - __main__ - num_labels: 49
03/01/2022 11:24:37 - INFO - __main__ - num_train_epochs: 20
03/01/2022 11:24:37 - INFO - __main__ - num_warmup_steps: 21608
03/01/2022 11:24:37 - INFO - __main__ - num_warmup_steps_or_radios: 0.1
03/01/2022 11:24:37 - INFO - __main__ - num_workers: 6
03/01/2022 11:24:37 - INFO - __main__ - output_dir: ./outputs/bert-bert-base-chinese
03/01/2022 11:24:37 - INFO - __main__ - per_device_eval_batch_size: 32
03/01/2022 11:24:37 - INFO - __main__ - per_device_train_batch_size: 16
03/01/2022 11:24:37 - INFO - __main__ - predicate2id: {'祖籍': 0, '父亲': 1, '总部地点': 2, '出生地': 3, '目': 4, '面积': 5, '简称': 6, '上映时间': 7, '妻子': 8, '所属专辑': 9, '注册资本': 10, '首都': 11, '导演': 12, '字': 13, '身高': 14, '出品公司': 15, '修业年限': 16, '出生日期': 17, '制片人': 18, '母亲': 19, '编剧': 20, '国籍': 21, '海拔': 22, '连载网站': 23, '丈夫': 24, '朝代': 25, '民族': 26, '号': 27, '出版社': 28, '主持人': 29, '专业代码': 30, '歌手': 31, '作词': 32, '主角': 33, '董事长': 34, '成立日期': 35, '毕业院校': 36, '占地面积': 37, '官方语言': 38, '邮政编码': 39, '人口数量': 40, '所在城市': 41, '作者': 42, '作曲': 43, '气候': 44, '嘉宾': 45, '主演': 46, '改编自': 47, '创始人': 48}
03/01/2022 11:24:37 - INFO - __main__ - pretrained_model_name_or_path: bert-base-chinese
03/01/2022 11:24:37 - INFO - __main__ - save_steps: 10804
03/01/2022 11:24:37 - INFO - __main__ - seed: 42
03/01/2022 11:24:37 - INFO - __main__ - tag2id: {'祖籍=SH2OH': 0, '父亲=SH2OH': 1, '总部地点=SH2OH': 2, '出生地=SH2OH': 3, '目=SH2OH': 4, '面积=SH2OH': 5, '简称=SH2OH': 6, '上映时间=SH2OH': 7, '妻子=SH2OH': 8, '所属专辑=SH2OH': 9, '注册资本=SH2OH': 10, '首都=SH2OH': 11, '导演=SH2OH': 12, '字=SH2OH': 13, '身高=SH2OH': 14, '出品公司=SH2OH': 15, '修业年限=SH2OH': 16, '出生日期=SH2OH': 17, '制片人=SH2OH': 18, '母亲=SH2OH': 19, '编剧=SH2OH': 20, '国籍=SH2OH': 21, '海拔=SH2OH': 22, '连载网站=SH2OH': 23, '丈夫=SH2OH': 24, '朝代=SH2OH': 25, '民族=SH2OH': 26, '号=SH2OH': 27, '出版社=SH2OH': 28, '主持人=SH2OH': 29, '专业代码=SH2OH': 30, '歌手=SH2OH': 31, '作词=SH2OH': 32, '主角=SH2OH': 33, '董事长=SH2OH': 34, '成立日期=SH2OH': 35, '毕业院校=SH2OH': 36, '占地面积=SH2OH': 37, '官方语言=SH2OH': 38, '邮政编码=SH2OH': 39, '人口数量=SH2OH': 40, '所在城市=SH2OH': 41, '作者=SH2OH': 42, '作曲=SH2OH': 43, '气候=SH2OH': 44, '嘉宾=SH2OH': 45, '主演=SH2OH': 46, '改编自=SH2OH': 47, '创始人=SH2OH': 48, '祖籍=OH2SH': 49, '父亲=OH2SH': 50, '总部地点=OH2SH': 51, '出生地=OH2SH': 52, '目=OH2SH': 53, '面积=OH2SH': 54, '简称=OH2SH': 55, '上映时间=OH2SH': 56, '妻子=OH2SH': 57, '所属专辑=OH2SH': 58, '注册资本=OH2SH': 59, '首都=OH2SH': 60, '导演=OH2SH': 61, '字=OH2SH': 62, '身高=OH2SH': 63, '出品公司=OH2SH': 64, '修业年限=OH2SH': 65, '出生日期=OH2SH': 66, '制片人=OH2SH': 67, '母亲=OH2SH': 68, '编剧=OH2SH': 69, '国籍=OH2SH': 70, '海拔=OH2SH': 71, '连载网站=OH2SH': 72, '丈夫=OH2SH': 73, '朝代=OH2SH': 74, '民族=OH2SH': 75, '号=OH2SH': 76, '出版社=OH2SH': 77, '主持人=OH2SH': 78, '专业代码=OH2SH': 79, '歌手=OH2SH': 80, '作词=OH2SH': 81, '主角=OH2SH': 82, '董事长=OH2SH': 83, '成立日期=OH2SH': 84, '毕业院校=OH2SH': 85, '占地面积=OH2SH': 86, '官方语言=OH2SH': 87, '邮政编码=OH2SH': 88, '人口数量=OH2SH': 89, '所在城市=OH2SH': 90, '作者=OH2SH': 91, '作曲=OH2SH': 92, '气候=OH2SH': 93, '嘉宾=OH2SH': 94, '主演=OH2SH': 95, '改编自=OH2SH': 96, '创始人=OH2SH': 97, '祖籍=ST2OT': 98, '父亲=ST2OT': 99, '总部地点=ST2OT': 100, '出生地=ST2OT': 101, '目=ST2OT': 102, '面积=ST2OT': 103, '简称=ST2OT': 104, '上映时间=ST2OT': 105, '妻子=ST2OT': 106, '所属专辑=ST2OT': 107, '注册资本=ST2OT': 108, '首都=ST2OT': 109, '导演=ST2OT': 110, '字=ST2OT': 111, '身高=ST2OT': 112, '出品公司=ST2OT': 113, '修业年限=ST2OT': 114, '出生日期=ST2OT': 115, '制片人=ST2OT': 116, '母亲=ST2OT': 117, '编剧=ST2OT': 118, '国籍=ST2OT': 119, '海拔=ST2OT': 120, '连载网站=ST2OT': 121, '丈夫=ST2OT': 122, '朝代=ST2OT': 123, '民族=ST2OT': 124, '号=ST2OT': 125, '出版社=ST2OT': 126, '主持人=ST2OT': 127, '专业代码=ST2OT': 128, '歌手=ST2OT': 129, '作词=ST2OT': 130, '主角=ST2OT': 131, '董事长=ST2OT': 132, '成立日期=ST2OT': 133, '毕业院校=ST2OT': 134, '占地面积=ST2OT': 135, '官方语言=ST2OT': 136, '邮政编码=ST2OT': 137, '人口数量=ST2OT': 138, '所在城市=ST2OT': 139, '作者=ST2OT': 140, '作曲=ST2OT': 141, '气候=ST2OT': 142, '嘉宾=ST2OT': 143, '主演=ST2OT': 144, '改编自=ST2OT': 145, '创始人=ST2OT': 146, '祖籍=OT2ST': 147, '父亲=OT2ST': 148, '总部地点=OT2ST': 149, '出生地=OT2ST': 150, '目=OT2ST': 151, '面积=OT2ST': 152, '简称=OT2ST': 153, '上映时间=OT2ST': 154, '妻子=OT2ST': 155, '所属专辑=OT2ST': 156, '注册资本=OT2ST': 157, '首都=OT2ST': 158, '导演=OT2ST': 159, '字=OT2ST': 160, '身高=OT2ST': 161, '出品公司=OT2ST': 162, '修业年限=OT2ST': 163, '出生日期=OT2ST': 164, '制片人=OT2ST': 165, '母亲=OT2ST': 166, '编剧=OT2ST': 167, '国籍=OT2ST': 168, '海拔=OT2ST': 169, '连载网站=OT2ST': 170, '丈夫=OT2ST': 171, '朝代=OT2ST': 172, '民族=OT2ST': 173, '号=OT2ST': 174, '出版社=OT2ST': 175, '主持人=OT2ST': 176, '专业代码=OT2ST': 177, '歌手=OT2ST': 178, '作词=OT2ST': 179, '主角=OT2ST': 180, '董事长=OT2ST': 181, '成立日期=OT2ST': 182, '毕业院校=OT2ST': 183, '占地面积=OT2ST': 184, '官方语言=OT2ST': 185, '邮政编码=OT2ST': 186, '人口数量=OT2ST': 187, '所在城市=OT2ST': 188, '作者=OT2ST': 189, '作曲=OT2ST': 190, '气候=OT2ST': 191, '嘉宾=OT2ST': 192, '主演=OT2ST': 193, '改编自=OT2ST': 194, '创始人=OT2ST': 195, 'DEFAULT=EH2ET': 196}
03/01/2022 11:24:37 - INFO - __main__ - tokenizer_name: None
03/01/2022 11:24:37 - INFO - __main__ - topk: 1
03/01/2022 11:24:37 - INFO - __main__ - total_batch_size: 16
03/01/2022 11:24:37 - INFO - __main__ - weight_decay: 0.02
03/01/2022 11:24:37 - INFO - __main__ - writer_type: tensorboard
03/01/2022 11:24:37 - INFO - __main__ - **************************************************
03/01/2022 11:25:31 - INFO - __main__ - global_steps 200 - lr: 0.00000028  loss: 6.36230171
03/01/2022 11:26:27 - INFO - __main__ - global_steps 400 - lr: 0.00000056  loss: 5.35159109
03/01/2022 11:27:21 - INFO - __main__ - global_steps 600 - lr: 0.00000083  loss: 3.85690084
03/01/2022 11:28:14 - INFO - __main__ - global_steps 800 - lr: 0.00000111  loss: 2.30692923
03/01/2022 11:29:08 - INFO - __main__ - global_steps 1000 - lr: 0.00000139  loss: 1.03444797
03/01/2022 11:30:05 - INFO - __main__ - global_steps 1200 - lr: 0.00000167  loss: 0.24046603
03/01/2022 11:30:59 - INFO - __main__ - global_steps 1400 - lr: 0.00000194  loss: 0.04162083
03/01/2022 11:31:52 - INFO - __main__ - global_steps 1600 - lr: 0.00000222  loss: 0.02264410
03/01/2022 11:32:46 - INFO - __main__ - global_steps 1800 - lr: 0.00000250  loss: 0.01716225
03/01/2022 11:33:39 - INFO - __main__ - global_steps 2000 - lr: 0.00000278  loss: 0.01507018
03/01/2022 11:34:33 - INFO - __main__ - global_steps 2200 - lr: 0.00000305  loss: 0.01287395
03/01/2022 11:35:27 - INFO - __main__ - global_steps 2400 - lr: 0.00000333  loss: 0.01216996
03/01/2022 11:36:22 - INFO - __main__ - global_steps 2600 - lr: 0.00000361  loss: 0.01126327
03/01/2022 11:37:13 - INFO - __main__ - global_steps 2800 - lr: 0.00000389  loss: 0.00961043
03/01/2022 11:38:06 - INFO - __main__ - global_steps 3000 - lr: 0.00000417  loss: 0.00862037
03/01/2022 11:38:59 - INFO - __main__ - global_steps 3200 - lr: 0.00000444  loss: 0.00739390
03/01/2022 11:39:51 - INFO - __main__ - global_steps 3400 - lr: 0.00000472  loss: 0.00623457
03/01/2022 11:40:45 - INFO - __main__ - global_steps 3600 - lr: 0.00000500  loss: 0.00584162
03/01/2022 11:41:39 - INFO - __main__ - global_steps 3800 - lr: 0.00000528  loss: 0.00520081
03/01/2022 11:42:34 - INFO - __main__ - global_steps 4000 - lr: 0.00000555  loss: 0.00449289
03/01/2022 11:43:27 - INFO - __main__ - global_steps 4200 - lr: 0.00000583  loss: 0.00425216
03/01/2022 11:44:22 - INFO - __main__ - global_steps 4400 - lr: 0.00000611  loss: 0.00380403
03/01/2022 11:45:14 - INFO - __main__ - global_steps 4600 - lr: 0.00000639  loss: 0.00361214
03/01/2022 11:46:08 - INFO - __main__ - global_steps 4800 - lr: 0.00000666  loss: 0.00329387
03/01/2022 11:46:59 - INFO - __main__ - global_steps 5000 - lr: 0.00000694  loss: 0.00316956
03/01/2022 11:47:54 - INFO - __main__ - global_steps 5200 - lr: 0.00000722  loss: 0.00301104
03/01/2022 11:48:48 - INFO - __main__ - global_steps 5400 - lr: 0.00000750  loss: 0.00270269
03/01/2022 11:49:43 - INFO - __main__ - global_steps 5600 - lr: 0.00000777  loss: 0.00245876
03/01/2022 11:50:35 - INFO - __main__ - global_steps 5800 - lr: 0.00000805  loss: 0.00256737
03/01/2022 11:51:30 - INFO - __main__ - global_steps 6000 - lr: 0.00000833  loss: 0.00236288
03/01/2022 11:52:26 - INFO - __main__ - global_steps 6200 - lr: 0.00000861  loss: 0.00235183
03/01/2022 11:53:17 - INFO - __main__ - global_steps 6400 - lr: 0.00000889  loss: 0.00228745
03/01/2022 11:54:10 - INFO - __main__ - global_steps 6600 - lr: 0.00000916  loss: 0.00218744
03/01/2022 11:55:04 - INFO - __main__ - global_steps 6800 - lr: 0.00000944  loss: 0.00199561
03/01/2022 11:55:57 - INFO - __main__ - global_steps 7000 - lr: 0.00000972  loss: 0.00199199
03/01/2022 11:56:51 - INFO - __main__ - global_steps 7200 - lr: 0.00001000  loss: 0.00192513
03/01/2022 11:57:44 - INFO - __main__ - global_steps 7400 - lr: 0.00001027  loss: 0.00198937
03/01/2022 11:58:38 - INFO - __main__ - global_steps 7600 - lr: 0.00001055  loss: 0.00182970
03/01/2022 11:59:32 - INFO - __main__ - global_steps 7800 - lr: 0.00001083  loss: 0.00186055
03/01/2022 12:00:26 - INFO - __main__ - global_steps 8000 - lr: 0.00001111  loss: 0.00176200
03/01/2022 12:01:19 - INFO - __main__ - global_steps 8200 - lr: 0.00001138  loss: 0.00169327
03/01/2022 12:02:11 - INFO - __main__ - global_steps 8400 - lr: 0.00001166  loss: 0.00180359
03/01/2022 12:03:03 - INFO - __main__ - global_steps 8600 - lr: 0.00001194  loss: 0.00184147
03/01/2022 12:03:56 - INFO - __main__ - global_steps 8800 - lr: 0.00001222  loss: 0.00167127
03/01/2022 12:04:50 - INFO - __main__ - global_steps 9000 - lr: 0.00001250  loss: 0.00153032
03/01/2022 12:05:44 - INFO - __main__ - global_steps 9200 - lr: 0.00001277  loss: 0.00162873
03/01/2022 12:06:39 - INFO - __main__ - global_steps 9400 - lr: 0.00001305  loss: 0.00160468
03/01/2022 12:07:33 - INFO - __main__ - global_steps 9600 - lr: 0.00001333  loss: 0.00159264
03/01/2022 12:08:26 - INFO - __main__ - global_steps 9800 - lr: 0.00001361  loss: 0.00164570
03/01/2022 12:09:17 - INFO - __main__ - global_steps 10000 - lr: 0.00001388  loss: 0.00174055
03/01/2022 12:10:10 - INFO - __main__ - global_steps 10200 - lr: 0.00001416  loss: 0.00160866
03/01/2022 12:11:01 - INFO - __main__ - global_steps 10400 - lr: 0.00001444  loss: 0.00162596
03/01/2022 12:11:54 - INFO - __main__ - global_steps 10600 - lr: 0.00001472  loss: 0.00155726
03/01/2022 12:12:47 - INFO - __main__ - global_steps 10800 - lr: 0.00001499  loss: 0.00144479
03/01/2022 12:12:48 - INFO - __main__ - ********** Evaluate Step 10804 **********
03/01/2022 12:12:48 - INFO - __main__ - ##--------------------- Dev
03/01/2022 12:16:11 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 12:16:11 - INFO - __main__ - f1 = 0.7610688557943677
03/01/2022 12:16:11 - INFO - __main__ - precision = 0.8252738513634852
03/01/2022 12:16:11 - INFO - __main__ - recall = 0.7061328416523998
03/01/2022 12:16:11 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 12:16:11 - INFO - __main__ - **--------------------- Dev End
03/01/2022 12:16:11 - INFO - __main__ - *************************************
03/01/2022 12:17:07 - INFO - __main__ - global_steps 11000 - lr: 0.00001527  loss: 0.00144853
03/01/2022 12:18:01 - INFO - __main__ - global_steps 11200 - lr: 0.00001555  loss: 0.00137674
03/01/2022 12:18:51 - INFO - __main__ - global_steps 11400 - lr: 0.00001583  loss: 0.00149514
03/01/2022 12:19:42 - INFO - __main__ - global_steps 11600 - lr: 0.00001611  loss: 0.00148071
03/01/2022 12:20:35 - INFO - __main__ - global_steps 11800 - lr: 0.00001638  loss: 0.00144264
03/01/2022 12:21:29 - INFO - __main__ - global_steps 12000 - lr: 0.00001666  loss: 0.00135459
03/01/2022 12:22:22 - INFO - __main__ - global_steps 12200 - lr: 0.00001694  loss: 0.00137282
03/01/2022 12:23:15 - INFO - __main__ - global_steps 12400 - lr: 0.00001722  loss: 0.00143292
03/01/2022 12:24:08 - INFO - __main__ - global_steps 12600 - lr: 0.00001749  loss: 0.00138445
03/01/2022 12:25:02 - INFO - __main__ - global_steps 12800 - lr: 0.00001777  loss: 0.00129252
03/01/2022 12:25:56 - INFO - __main__ - global_steps 13000 - lr: 0.00001805  loss: 0.00139264
03/01/2022 12:26:51 - INFO - __main__ - global_steps 13200 - lr: 0.00001833  loss: 0.00134572
03/01/2022 12:27:46 - INFO - __main__ - global_steps 13400 - lr: 0.00001860  loss: 0.00138538
03/01/2022 12:28:40 - INFO - __main__ - global_steps 13600 - lr: 0.00001888  loss: 0.00131357
03/01/2022 12:29:34 - INFO - __main__ - global_steps 13800 - lr: 0.00001916  loss: 0.00132862
03/01/2022 12:30:26 - INFO - __main__ - global_steps 14000 - lr: 0.00001944  loss: 0.00135985
03/01/2022 12:31:19 - INFO - __main__ - global_steps 14200 - lr: 0.00001971  loss: 0.00139700
03/01/2022 12:32:12 - INFO - __main__ - global_steps 14400 - lr: 0.00001999  loss: 0.00132426
03/01/2022 12:33:06 - INFO - __main__ - global_steps 14600 - lr: 0.00002027  loss: 0.00133931
03/01/2022 12:34:00 - INFO - __main__ - global_steps 14800 - lr: 0.00002055  loss: 0.00133504
03/01/2022 12:34:54 - INFO - __main__ - global_steps 15000 - lr: 0.00002083  loss: 0.00134278
03/01/2022 12:35:48 - INFO - __main__ - global_steps 15200 - lr: 0.00002110  loss: 0.00131538
03/01/2022 12:36:42 - INFO - __main__ - global_steps 15400 - lr: 0.00002138  loss: 0.00127220
03/01/2022 12:37:35 - INFO - __main__ - global_steps 15600 - lr: 0.00002166  loss: 0.00128735
03/01/2022 12:38:31 - INFO - __main__ - global_steps 15800 - lr: 0.00002194  loss: 0.00119069
03/01/2022 12:39:24 - INFO - __main__ - global_steps 16000 - lr: 0.00002221  loss: 0.00131219
03/01/2022 12:40:15 - INFO - __main__ - global_steps 16200 - lr: 0.00002249  loss: 0.00126921
03/01/2022 12:41:06 - INFO - __main__ - global_steps 16400 - lr: 0.00002277  loss: 0.00138000
03/01/2022 12:41:58 - INFO - __main__ - global_steps 16600 - lr: 0.00002305  loss: 0.00132067
03/01/2022 12:42:51 - INFO - __main__ - global_steps 16800 - lr: 0.00002332  loss: 0.00127370
03/01/2022 12:43:46 - INFO - __main__ - global_steps 17000 - lr: 0.00002360  loss: 0.00122944
03/01/2022 12:44:39 - INFO - __main__ - global_steps 17200 - lr: 0.00002388  loss: 0.00123615
03/01/2022 12:45:33 - INFO - __main__ - global_steps 17400 - lr: 0.00002416  loss: 0.00128864
03/01/2022 12:46:26 - INFO - __main__ - global_steps 17600 - lr: 0.00002444  loss: 0.00121608
03/01/2022 12:47:20 - INFO - __main__ - global_steps 17800 - lr: 0.00002471  loss: 0.00126581
03/01/2022 12:48:14 - INFO - __main__ - global_steps 18000 - lr: 0.00002499  loss: 0.00118991
03/01/2022 12:49:07 - INFO - __main__ - global_steps 18200 - lr: 0.00002527  loss: 0.00120071
03/01/2022 12:50:00 - INFO - __main__ - global_steps 18400 - lr: 0.00002555  loss: 0.00123161
03/01/2022 12:50:54 - INFO - __main__ - global_steps 18600 - lr: 0.00002582  loss: 0.00117845
03/01/2022 12:51:48 - INFO - __main__ - global_steps 18800 - lr: 0.00002610  loss: 0.00123898
03/01/2022 12:52:40 - INFO - __main__ - global_steps 19000 - lr: 0.00002638  loss: 0.00132467
03/01/2022 12:53:33 - INFO - __main__ - global_steps 19200 - lr: 0.00002666  loss: 0.00119772
03/01/2022 12:54:30 - INFO - __main__ - global_steps 19400 - lr: 0.00002693  loss: 0.00115018
03/01/2022 12:55:24 - INFO - __main__ - global_steps 19600 - lr: 0.00002721  loss: 0.00114351
03/01/2022 12:56:18 - INFO - __main__ - global_steps 19800 - lr: 0.00002749  loss: 0.00122399
03/01/2022 12:57:12 - INFO - __main__ - global_steps 20000 - lr: 0.00002777  loss: 0.00119281
03/01/2022 12:58:07 - INFO - __main__ - global_steps 20200 - lr: 0.00002805  loss: 0.00108551
03/01/2022 12:58:58 - INFO - __main__ - global_steps 20400 - lr: 0.00002832  loss: 0.00120468
03/01/2022 12:59:52 - INFO - __main__ - global_steps 20600 - lr: 0.00002860  loss: 0.00118175
03/01/2022 13:00:46 - INFO - __main__ - global_steps 20800 - lr: 0.00002888  loss: 0.00115899
03/01/2022 13:01:40 - INFO - __main__ - global_steps 21000 - lr: 0.00002916  loss: 0.00116447
03/01/2022 13:02:32 - INFO - __main__ - global_steps 21200 - lr: 0.00002943  loss: 0.00136627
03/01/2022 13:03:25 - INFO - __main__ - global_steps 21400 - lr: 0.00002971  loss: 0.00118251
03/01/2022 13:04:18 - INFO - __main__ - global_steps 21600 - lr: 0.00002999  loss: 0.00119899
03/01/2022 13:04:20 - INFO - __main__ - ********** Evaluate Step 21608 **********
03/01/2022 13:04:20 - INFO - __main__ - ##--------------------- Dev
03/01/2022 13:07:43 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 13:07:43 - INFO - __main__ - f1 = 0.7963355688803251
03/01/2022 13:07:43 - INFO - __main__ - precision = 0.7813879792965042
03/01/2022 13:07:43 - INFO - __main__ - recall = 0.8118661925457663
03/01/2022 13:07:43 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 13:07:43 - INFO - __main__ - **--------------------- Dev End
03/01/2022 13:07:44 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-10804-spo-f1-0.7610688557943677
03/01/2022 13:07:44 - INFO - __main__ - *************************************
03/01/2022 13:08:39 - INFO - __main__ - global_steps 21800 - lr: 0.00002997  loss: 0.00107391
03/01/2022 13:09:33 - INFO - __main__ - global_steps 22000 - lr: 0.00002994  loss: 0.00107511
03/01/2022 13:10:25 - INFO - __main__ - global_steps 22200 - lr: 0.00002991  loss: 0.00120231
03/01/2022 13:11:19 - INFO - __main__ - global_steps 22400 - lr: 0.00002988  loss: 0.00106157
03/01/2022 13:12:13 - INFO - __main__ - global_steps 22600 - lr: 0.00002985  loss: 0.00108812
03/01/2022 13:13:07 - INFO - __main__ - global_steps 22800 - lr: 0.00002982  loss: 0.00105811
03/01/2022 13:14:01 - INFO - __main__ - global_steps 23000 - lr: 0.00002979  loss: 0.00114844
03/01/2022 13:14:53 - INFO - __main__ - global_steps 23200 - lr: 0.00002975  loss: 0.00112813
03/01/2022 13:15:49 - INFO - __main__ - global_steps 23400 - lr: 0.00002972  loss: 0.00109504
03/01/2022 13:16:42 - INFO - __main__ - global_steps 23600 - lr: 0.00002969  loss: 0.00105479
03/01/2022 13:17:35 - INFO - __main__ - global_steps 23800 - lr: 0.00002966  loss: 0.00106800
03/01/2022 13:18:27 - INFO - __main__ - global_steps 24000 - lr: 0.00002963  loss: 0.00111120
03/01/2022 13:19:20 - INFO - __main__ - global_steps 24200 - lr: 0.00002960  loss: 0.00112450
03/01/2022 13:20:11 - INFO - __main__ - global_steps 24400 - lr: 0.00002957  loss: 0.00106819
03/01/2022 13:21:04 - INFO - __main__ - global_steps 24600 - lr: 0.00002954  loss: 0.00111315
03/01/2022 13:21:57 - INFO - __main__ - global_steps 24800 - lr: 0.00002951  loss: 0.00103460
03/01/2022 13:22:52 - INFO - __main__ - global_steps 25000 - lr: 0.00002948  loss: 0.00107374
03/01/2022 13:23:44 - INFO - __main__ - global_steps 25200 - lr: 0.00002945  loss: 0.00114729
03/01/2022 13:24:39 - INFO - __main__ - global_steps 25400 - lr: 0.00002942  loss: 0.00103969
03/01/2022 13:25:33 - INFO - __main__ - global_steps 25600 - lr: 0.00002938  loss: 0.00104253
03/01/2022 13:26:28 - INFO - __main__ - global_steps 25800 - lr: 0.00002935  loss: 0.00108080
03/01/2022 13:27:20 - INFO - __main__ - global_steps 26000 - lr: 0.00002932  loss: 0.00110927
03/01/2022 13:28:12 - INFO - __main__ - global_steps 26200 - lr: 0.00002929  loss: 0.00109893
03/01/2022 13:29:05 - INFO - __main__ - global_steps 26400 - lr: 0.00002926  loss: 0.00103175
03/01/2022 13:29:59 - INFO - __main__ - global_steps 26600 - lr: 0.00002923  loss: 0.00116493
03/01/2022 13:30:52 - INFO - __main__ - global_steps 26800 - lr: 0.00002920  loss: 0.00107218
03/01/2022 13:31:45 - INFO - __main__ - global_steps 27000 - lr: 0.00002917  loss: 0.00103984
03/01/2022 13:32:38 - INFO - __main__ - global_steps 27200 - lr: 0.00002914  loss: 0.00106788
03/01/2022 13:33:30 - INFO - __main__ - global_steps 27400 - lr: 0.00002911  loss: 0.00109940
03/01/2022 13:34:24 - INFO - __main__ - global_steps 27600 - lr: 0.00002908  loss: 0.00104673
03/01/2022 13:35:18 - INFO - __main__ - global_steps 27800 - lr: 0.00002904  loss: 0.00108131
03/01/2022 13:36:13 - INFO - __main__ - global_steps 28000 - lr: 0.00002901  loss: 0.00105022
03/01/2022 13:37:08 - INFO - __main__ - global_steps 28200 - lr: 0.00002898  loss: 0.00106512
03/01/2022 13:38:02 - INFO - __main__ - global_steps 28400 - lr: 0.00002895  loss: 0.00103646
03/01/2022 13:38:56 - INFO - __main__ - global_steps 28600 - lr: 0.00002892  loss: 0.00097512
03/01/2022 13:39:49 - INFO - __main__ - global_steps 28800 - lr: 0.00002889  loss: 0.00103720
03/01/2022 13:40:41 - INFO - __main__ - global_steps 29000 - lr: 0.00002886  loss: 0.00106524
03/01/2022 13:41:36 - INFO - __main__ - global_steps 29200 - lr: 0.00002883  loss: 0.00103343
03/01/2022 13:42:30 - INFO - __main__ - global_steps 29400 - lr: 0.00002880  loss: 0.00110853
03/01/2022 13:43:24 - INFO - __main__ - global_steps 29600 - lr: 0.00002877  loss: 0.00106447
03/01/2022 13:44:19 - INFO - __main__ - global_steps 29800 - lr: 0.00002874  loss: 0.00110481
03/01/2022 13:45:12 - INFO - __main__ - global_steps 30000 - lr: 0.00002871  loss: 0.00110912
03/01/2022 13:46:05 - INFO - __main__ - global_steps 30200 - lr: 0.00002867  loss: 0.00101296
03/01/2022 13:46:55 - INFO - __main__ - global_steps 30400 - lr: 0.00002864  loss: 0.00108297
03/01/2022 13:47:46 - INFO - __main__ - global_steps 30600 - lr: 0.00002861  loss: 0.00102298
03/01/2022 13:48:38 - INFO - __main__ - global_steps 30800 - lr: 0.00002858  loss: 0.00115031
03/01/2022 13:49:31 - INFO - __main__ - global_steps 31000 - lr: 0.00002855  loss: 0.00103880
03/01/2022 13:50:24 - INFO - __main__ - global_steps 31200 - lr: 0.00002852  loss: 0.00107647
03/01/2022 13:51:16 - INFO - __main__ - global_steps 31400 - lr: 0.00002849  loss: 0.00101260
03/01/2022 13:52:07 - INFO - __main__ - global_steps 31600 - lr: 0.00002846  loss: 0.00106721
03/01/2022 13:52:58 - INFO - __main__ - global_steps 31800 - lr: 0.00002843  loss: 0.00099292
03/01/2022 13:53:51 - INFO - __main__ - global_steps 32000 - lr: 0.00002840  loss: 0.00104694
03/01/2022 13:54:43 - INFO - __main__ - global_steps 32200 - lr: 0.00002837  loss: 0.00097617
03/01/2022 13:55:35 - INFO - __main__ - global_steps 32400 - lr: 0.00002834  loss: 0.00105833
03/01/2022 13:55:37 - INFO - __main__ - ********** Evaluate Step 32412 **********
03/01/2022 13:55:37 - INFO - __main__ - ##--------------------- Dev
03/01/2022 13:58:55 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 13:58:55 - INFO - __main__ - f1 = 0.8078224566029448
03/01/2022 13:58:55 - INFO - __main__ - precision = 0.8086753772381333
03/01/2022 13:58:55 - INFO - __main__ - recall = 0.8069713332455336
03/01/2022 13:58:55 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 13:58:55 - INFO - __main__ - **--------------------- Dev End
03/01/2022 13:58:56 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-21608-spo-f1-0.7963355688803251
03/01/2022 13:58:56 - INFO - __main__ - *************************************
03/01/2022 13:59:46 - INFO - __main__ - global_steps 32600 - lr: 0.00002830  loss: 0.00095260
03/01/2022 14:00:40 - INFO - __main__ - global_steps 32800 - lr: 0.00002827  loss: 0.00087311
03/01/2022 14:01:34 - INFO - __main__ - global_steps 33000 - lr: 0.00002824  loss: 0.00085621
03/01/2022 14:02:26 - INFO - __main__ - global_steps 33200 - lr: 0.00002821  loss: 0.00095231
03/01/2022 14:03:19 - INFO - __main__ - global_steps 33400 - lr: 0.00002818  loss: 0.00093045
03/01/2022 14:04:12 - INFO - __main__ - global_steps 33600 - lr: 0.00002815  loss: 0.00085726
03/01/2022 14:05:03 - INFO - __main__ - global_steps 33800 - lr: 0.00002812  loss: 0.00096798
03/01/2022 14:05:57 - INFO - __main__ - global_steps 34000 - lr: 0.00002809  loss: 0.00087393
03/01/2022 14:06:50 - INFO - __main__ - global_steps 34200 - lr: 0.00002806  loss: 0.00091220
03/01/2022 14:07:43 - INFO - __main__ - global_steps 34400 - lr: 0.00002803  loss: 0.00090327
03/01/2022 14:08:37 - INFO - __main__ - global_steps 34600 - lr: 0.00002800  loss: 0.00097260
03/01/2022 14:09:32 - INFO - __main__ - global_steps 34800 - lr: 0.00002796  loss: 0.00093782
03/01/2022 14:10:25 - INFO - __main__ - global_steps 35000 - lr: 0.00002793  loss: 0.00095697
03/01/2022 14:11:20 - INFO - __main__ - global_steps 35200 - lr: 0.00002790  loss: 0.00093176
03/01/2022 14:12:14 - INFO - __main__ - global_steps 35400 - lr: 0.00002787  loss: 0.00093097
03/01/2022 14:13:06 - INFO - __main__ - global_steps 35600 - lr: 0.00002784  loss: 0.00092397
03/01/2022 14:13:58 - INFO - __main__ - global_steps 35800 - lr: 0.00002781  loss: 0.00095183
03/01/2022 14:14:51 - INFO - __main__ - global_steps 36000 - lr: 0.00002778  loss: 0.00093678
03/01/2022 14:15:45 - INFO - __main__ - global_steps 36200 - lr: 0.00002775  loss: 0.00090774
03/01/2022 14:16:38 - INFO - __main__ - global_steps 36400 - lr: 0.00002772  loss: 0.00096249
03/01/2022 14:17:33 - INFO - __main__ - global_steps 36600 - lr: 0.00002769  loss: 0.00092774
03/01/2022 14:18:27 - INFO - __main__ - global_steps 36800 - lr: 0.00002766  loss: 0.00096414
03/01/2022 14:19:19 - INFO - __main__ - global_steps 37000 - lr: 0.00002763  loss: 0.00094949
03/01/2022 14:20:12 - INFO - __main__ - global_steps 37200 - lr: 0.00002759  loss: 0.00091977
03/01/2022 14:21:04 - INFO - __main__ - global_steps 37400 - lr: 0.00002756  loss: 0.00103367
03/01/2022 14:21:57 - INFO - __main__ - global_steps 37600 - lr: 0.00002753  loss: 0.00093238
03/01/2022 14:22:51 - INFO - __main__ - global_steps 37800 - lr: 0.00002750  loss: 0.00092530
03/01/2022 14:23:46 - INFO - __main__ - global_steps 38000 - lr: 0.00002747  loss: 0.00092487
03/01/2022 14:24:41 - INFO - __main__ - global_steps 38200 - lr: 0.00002744  loss: 0.00091670
03/01/2022 14:25:34 - INFO - __main__ - global_steps 38400 - lr: 0.00002741  loss: 0.00097982
03/01/2022 14:26:27 - INFO - __main__ - global_steps 38600 - lr: 0.00002738  loss: 0.00087440
03/01/2022 14:27:22 - INFO - __main__ - global_steps 38800 - lr: 0.00002735  loss: 0.00086362
03/01/2022 14:28:15 - INFO - __main__ - global_steps 39000 - lr: 0.00002732  loss: 0.00097591
03/01/2022 14:29:07 - INFO - __main__ - global_steps 39200 - lr: 0.00002729  loss: 0.00098707
03/01/2022 14:30:00 - INFO - __main__ - global_steps 39400 - lr: 0.00002726  loss: 0.00100042
03/01/2022 14:30:52 - INFO - __main__ - global_steps 39600 - lr: 0.00002722  loss: 0.00093477
03/01/2022 14:31:45 - INFO - __main__ - global_steps 39800 - lr: 0.00002719  loss: 0.00096109
03/01/2022 14:32:39 - INFO - __main__ - global_steps 40000 - lr: 0.00002716  loss: 0.00090757
03/01/2022 14:33:30 - INFO - __main__ - global_steps 40200 - lr: 0.00002713  loss: 0.00095506
03/01/2022 14:34:23 - INFO - __main__ - global_steps 40400 - lr: 0.00002710  loss: 0.00090085
03/01/2022 14:35:17 - INFO - __main__ - global_steps 40600 - lr: 0.00002707  loss: 0.00092752
03/01/2022 14:36:08 - INFO - __main__ - global_steps 40800 - lr: 0.00002704  loss: 0.00091098
03/01/2022 14:37:03 - INFO - __main__ - global_steps 41000 - lr: 0.00002701  loss: 0.00091620
03/01/2022 14:37:57 - INFO - __main__ - global_steps 41200 - lr: 0.00002698  loss: 0.00092978
03/01/2022 14:38:51 - INFO - __main__ - global_steps 41400 - lr: 0.00002695  loss: 0.00088399
03/01/2022 14:39:42 - INFO - __main__ - global_steps 41600 - lr: 0.00002692  loss: 0.00094585
03/01/2022 14:40:36 - INFO - __main__ - global_steps 41800 - lr: 0.00002689  loss: 0.00095711
03/01/2022 14:41:30 - INFO - __main__ - global_steps 42000 - lr: 0.00002685  loss: 0.00096161
03/01/2022 14:42:21 - INFO - __main__ - global_steps 42200 - lr: 0.00002682  loss: 0.00098058
03/01/2022 14:43:16 - INFO - __main__ - global_steps 42400 - lr: 0.00002679  loss: 0.00090867
03/01/2022 14:44:07 - INFO - __main__ - global_steps 42600 - lr: 0.00002676  loss: 0.00096142
03/01/2022 14:45:00 - INFO - __main__ - global_steps 42800 - lr: 0.00002673  loss: 0.00097114
03/01/2022 14:45:53 - INFO - __main__ - global_steps 43000 - lr: 0.00002670  loss: 0.00087562
03/01/2022 14:46:46 - INFO - __main__ - global_steps 43200 - lr: 0.00002667  loss: 0.00094536
03/01/2022 14:46:50 - INFO - __main__ - ********** Evaluate Step 43216 **********
03/01/2022 14:46:50 - INFO - __main__ - ##--------------------- Dev
03/01/2022 14:50:14 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 14:50:14 - INFO - __main__ - f1 = 0.8103291548363208
03/01/2022 14:50:14 - INFO - __main__ - precision = 0.8290201841603715
03/01/2022 14:50:14 - INFO - __main__ - recall = 0.7924623556784762
03/01/2022 14:50:14 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 14:50:14 - INFO - __main__ - **--------------------- Dev End
03/01/2022 14:50:14 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-32412-spo-f1-0.8078224566029448
03/01/2022 14:50:14 - INFO - __main__ - *************************************
03/01/2022 14:51:02 - INFO - __main__ - global_steps 43400 - lr: 0.00002664  loss: 0.00085319
03/01/2022 14:51:56 - INFO - __main__ - global_steps 43600 - lr: 0.00002661  loss: 0.00082754
03/01/2022 14:52:50 - INFO - __main__ - global_steps 43800 - lr: 0.00002658  loss: 0.00082189
03/01/2022 14:53:45 - INFO - __main__ - global_steps 44000 - lr: 0.00002655  loss: 0.00080341
03/01/2022 14:54:41 - INFO - __main__ - global_steps 44200 - lr: 0.00002651  loss: 0.00075801
03/01/2022 14:55:35 - INFO - __main__ - global_steps 44400 - lr: 0.00002648  loss: 0.00075581
03/01/2022 14:56:28 - INFO - __main__ - global_steps 44600 - lr: 0.00002645  loss: 0.00080725
03/01/2022 14:57:21 - INFO - __main__ - global_steps 44800 - lr: 0.00002642  loss: 0.00085491
03/01/2022 14:58:15 - INFO - __main__ - global_steps 45000 - lr: 0.00002639  loss: 0.00081597
03/01/2022 14:59:08 - INFO - __main__ - global_steps 45200 - lr: 0.00002636  loss: 0.00087159
03/01/2022 15:00:01 - INFO - __main__ - global_steps 45400 - lr: 0.00002633  loss: 0.00091738
03/01/2022 15:00:54 - INFO - __main__ - global_steps 45600 - lr: 0.00002630  loss: 0.00081250
03/01/2022 15:01:47 - INFO - __main__ - global_steps 45800 - lr: 0.00002627  loss: 0.00082202
03/01/2022 15:02:39 - INFO - __main__ - global_steps 46000 - lr: 0.00002624  loss: 0.00081596
03/01/2022 15:03:33 - INFO - __main__ - global_steps 46200 - lr: 0.00002621  loss: 0.00081972
03/01/2022 15:04:26 - INFO - __main__ - global_steps 46400 - lr: 0.00002618  loss: 0.00084796
03/01/2022 15:05:21 - INFO - __main__ - global_steps 46600 - lr: 0.00002614  loss: 0.00078970
03/01/2022 15:06:14 - INFO - __main__ - global_steps 46800 - lr: 0.00002611  loss: 0.00084376
03/01/2022 15:07:08 - INFO - __main__ - global_steps 47000 - lr: 0.00002608  loss: 0.00076593
03/01/2022 15:08:00 - INFO - __main__ - global_steps 47200 - lr: 0.00002605  loss: 0.00083780
03/01/2022 15:08:51 - INFO - __main__ - global_steps 47400 - lr: 0.00002602  loss: 0.00086079
03/01/2022 15:09:42 - INFO - __main__ - global_steps 47600 - lr: 0.00002599  loss: 0.00081036
03/01/2022 15:10:34 - INFO - __main__ - global_steps 47800 - lr: 0.00002596  loss: 0.00079680
03/01/2022 15:11:27 - INFO - __main__ - global_steps 48000 - lr: 0.00002593  loss: 0.00082973
03/01/2022 15:12:20 - INFO - __main__ - global_steps 48200 - lr: 0.00002590  loss: 0.00078970
03/01/2022 15:13:10 - INFO - __main__ - global_steps 48400 - lr: 0.00002587  loss: 0.00081814
03/01/2022 15:14:01 - INFO - __main__ - global_steps 48600 - lr: 0.00002584  loss: 0.00089606
03/01/2022 15:14:54 - INFO - __main__ - global_steps 48800 - lr: 0.00002581  loss: 0.00081158
03/01/2022 15:15:46 - INFO - __main__ - global_steps 49000 - lr: 0.00002577  loss: 0.00081467
03/01/2022 15:16:38 - INFO - __main__ - global_steps 49200 - lr: 0.00002574  loss: 0.00084149
03/01/2022 15:17:28 - INFO - __main__ - global_steps 49400 - lr: 0.00002571  loss: 0.00089644
03/01/2022 15:18:18 - INFO - __main__ - global_steps 49600 - lr: 0.00002568  loss: 0.00080164
03/01/2022 15:19:10 - INFO - __main__ - global_steps 49800 - lr: 0.00002565  loss: 0.00084073
03/01/2022 15:20:01 - INFO - __main__ - global_steps 50000 - lr: 0.00002562  loss: 0.00085258
03/01/2022 15:20:53 - INFO - __main__ - global_steps 50200 - lr: 0.00002559  loss: 0.00082904
03/01/2022 15:21:45 - INFO - __main__ - global_steps 50400 - lr: 0.00002556  loss: 0.00080809
03/01/2022 15:22:35 - INFO - __main__ - global_steps 50600 - lr: 0.00002553  loss: 0.00083926
03/01/2022 15:23:26 - INFO - __main__ - global_steps 50800 - lr: 0.00002550  loss: 0.00086957
03/01/2022 15:24:18 - INFO - __main__ - global_steps 51000 - lr: 0.00002547  loss: 0.00082148
03/01/2022 15:25:10 - INFO - __main__ - global_steps 51200 - lr: 0.00002544  loss: 0.00082725
03/01/2022 15:26:02 - INFO - __main__ - global_steps 51400 - lr: 0.00002540  loss: 0.00079244
03/01/2022 15:26:53 - INFO - __main__ - global_steps 51600 - lr: 0.00002537  loss: 0.00080525
03/01/2022 15:27:45 - INFO - __main__ - global_steps 51800 - lr: 0.00002534  loss: 0.00082027
03/01/2022 15:28:38 - INFO - __main__ - global_steps 52000 - lr: 0.00002531  loss: 0.00081856
03/01/2022 15:29:30 - INFO - __main__ - global_steps 52200 - lr: 0.00002528  loss: 0.00079039
03/01/2022 15:30:22 - INFO - __main__ - global_steps 52400 - lr: 0.00002525  loss: 0.00079639
03/01/2022 15:31:14 - INFO - __main__ - global_steps 52600 - lr: 0.00002522  loss: 0.00086665
03/01/2022 15:32:08 - INFO - __main__ - global_steps 52800 - lr: 0.00002519  loss: 0.00078004
03/01/2022 15:33:01 - INFO - __main__ - global_steps 53000 - lr: 0.00002516  loss: 0.00085171
03/01/2022 15:33:55 - INFO - __main__ - global_steps 53200 - lr: 0.00002513  loss: 0.00080282
03/01/2022 15:34:47 - INFO - __main__ - global_steps 53400 - lr: 0.00002510  loss: 0.00079972
03/01/2022 15:35:42 - INFO - __main__ - global_steps 53600 - lr: 0.00002506  loss: 0.00083235
03/01/2022 15:36:38 - INFO - __main__ - global_steps 53800 - lr: 0.00002503  loss: 0.00080534
03/01/2022 15:37:32 - INFO - __main__ - global_steps 54000 - lr: 0.00002500  loss: 0.00080495
03/01/2022 15:37:38 - INFO - __main__ - ********** Evaluate Step 54020 **********
03/01/2022 15:37:38 - INFO - __main__ - ##--------------------- Dev
03/01/2022 15:41:02 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 15:41:02 - INFO - __main__ - f1 = 0.8202398259785976
03/01/2022 15:41:02 - INFO - __main__ - precision = 0.8169624387588463
03/01/2022 15:41:02 - INFO - __main__ - recall = 0.8235436147328684
03/01/2022 15:41:02 - INFO - __main__ - --------------------------------------------------------------------------------
03/01/2022 15:41:02 - INFO - __main__ - **--------------------- Dev End
03/01/2022 15:41:03 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-43216-spo-f1-0.8103291548363208
03/01/2022 15:41:03 - INFO - __main__ - *************************************
03/01/2022 15:41:54 - INFO - __main__ - global_steps 54200 - lr: 0.00002497  loss: 0.00071974
03/01/2022 15:42:45 - INFO - __main__ - global_steps 54400 - lr: 0.00002494  loss: 0.00073423
03/01/2022 15:43:36 - INFO - __main__ - global_steps 54600 - lr: 0.00002491  loss: 0.00071542
03/01/2022 15:44:30 - INFO - __main__ - global_steps 54800 - lr: 0.00002488  loss: 0.00073150
03/01/2022 15:45:22 - INFO - __main__ - global_steps 55000 - lr: 0.00002485  loss: 0.00072391
03/01/2022 15:46:15 - INFO - __main__ - global_steps 55200 - lr: 0.00002482  loss: 0.00073795
03/01/2022 15:47:06 - INFO - __main__ - global_steps 55400 - lr: 0.00002479  loss: 0.00074740
03/01/2022 15:47:59 - INFO - __main__ - global_steps 55600 - lr: 0.00002476  loss: 0.00078261
03/01/2022 15:48:51 - INFO - __main__ - global_steps 55800 - lr: 0.00002473  loss: 0.00072366
03/01/2022 15:49:44 - INFO - __main__ - global_steps 56000 - lr: 0.00002469  loss: 0.00074949
03/01/2022 15:50:40 - INFO - __main__ - global_steps 56200 - lr: 0.00002466  loss: 0.00074346
03/01/2022 15:51:36 - INFO - __main__ - global_steps 56400 - lr: 0.00002463  loss: 0.00071123
03/01/2022 15:52:28 - INFO - __main__ - global_steps 56600 - lr: 0.00002460  loss: 0.00069575
03/01/2022 15:53:21 - INFO - __main__ - global_steps 56800 - lr: 0.00002457  loss: 0.00073630
03/01/2022 15:54:14 - INFO - __main__ - global_steps 57000 - lr: 0.00002454  loss: 0.00071906
03/01/2022 15:55:04 - INFO - __main__ - global_steps 57200 - lr: 0.00002451  loss: 0.00075267
03/01/2022 15:55:56 - INFO - __main__ - global_steps 57400 - lr: 0.00002448  loss: 0.00073222
03/01/2022 15:56:47 - INFO - __main__ - global_steps 57600 - lr: 0.00002445  loss: 0.00070567
03/01/2022 15:57:39 - INFO - __main__ - global_steps 57800 - lr: 0.00002442  loss: 0.00072660
03/01/2022 15:58:33 - INFO - __main__ - global_steps 58000 - lr: 0.00002439  loss: 0.00072300
03/01/2022 15:59:25 - INFO - __main__ - global_steps 58200 - lr: 0.00002436  loss: 0.00074833
03/01/2022 16:00:18 - INFO - __main__ - global_steps 58400 - lr: 0.00002432  loss: 0.00075663
03/01/2022 16:01:10 - INFO - __main__ - global_steps 58600 - lr: 0.00002429  loss: 0.00075727
03/01/2022 16:02:02 - INFO - __main__ - global_steps 58800 - lr: 0.00002426  loss: 0.00073447
03/01/2022 16:02:54 - INFO - __main__ - global_steps 59000 - lr: 0.00002423  loss: 0.00075637
03/01/2022 16:03:44 - INFO - __main__ - global_steps 59200 - lr: 0.00002420  loss: 0.00076173
03/01/2022 16:04:33 - INFO - __main__ - global_steps 59400 - lr: 0.00002417  loss: 0.00074980
03/01/2022 16:05:26 - INFO - __main__ - global_steps 59600 - lr: 0.00002414  loss: 0.00068345
03/01/2022 16:06:19 - INFO - __main__ - global_steps 59800 - lr: 0.00002411  loss: 0.00073572
03/01/2022 16:07:11 - INFO - __main__ - global_steps 60000 - lr: 0.00002408  loss: 0.00072764
03/01/2022 16:08:02 - INFO - __main__ - global_steps 60200 - lr: 0.00002405  loss: 0.00073803
03/01/2022 16:08:53 - INFO - __main__ - global_steps 60400 - lr: 0.00002402  loss: 0.00068069
03/01/2022 16:09:44 - INFO - __main__ - global_steps 60600 - lr: 0.00002398  loss: 0.00077910
03/01/2022 16:10:36 - INFO - __main__ - global_steps 60800 - lr: 0.00002395  loss: 0.00070471
03/01/2022 16:11:30 - INFO - __main__ - global_steps 61000 - lr: 0.00002392  loss: 0.00073111
03/01/2022 16:12:22 - INFO - __main__ - global_steps 61200 - lr: 0.00002389  loss: 0.00072367
03/01/2022 16:13:14 - INFO - __main__ - global_steps 61400 - lr: 0.00002386  loss: 0.00073676
03/01/2022 16:14:07 - INFO - __main__ - global_steps 61600 - lr: 0.00002383  loss: 0.00068609
03/01/2022 16:14:59 - INFO - __main__ - global_steps 61800 - lr: 0.00002380  loss: 0.00074549
03/01/2022 16:15:50 - INFO - __main__ - global_steps 62000 - lr: 0.00002377  loss: 0.00073821
03/01/2022 16:16:43 - INFO - __main__ - global_steps 62200 - lr: 0.00002374  loss: 0.00078150
