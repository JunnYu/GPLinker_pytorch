03/02/2022 17:48:07 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda
Use FP16 precision: False

03/02/2022 17:48:19 - WARNING - datasets.builder - No config specified, defaulting to: spo/spo
03/02/2022 17:48:19 - WARNING - datasets.builder - Reusing dataset spo (data_caches/spo/spo/1.0.0/60031c4297281bb2dda3c491c97718942eb9494eed0a6e80739b7b1b5e7f130b)
03/02/2022 17:48:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at data_caches/spo/spo/1.0.0/60031c4297281bb2dda3c491c97718942eb9494eed0a6e80739b7b1b5e7f130b/cache-f07d89a51ab89641.arrow
03/02/2022 17:48:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at data_caches/spo/spo/1.0.0/60031c4297281bb2dda3c491c97718942eb9494eed0a6e80739b7b1b5e7f130b/cache-60afefe1b5fb2bc0.arrow
03/02/2022 17:48:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at data_caches/spo/spo/1.0.0/60031c4297281bb2dda3c491c97718942eb9494eed0a6e80739b7b1b5e7f130b/cache-0c78b79a93ec483d.arrow
03/02/2022 17:48:38 - INFO - utils.data - Sample 167621 of the training set:
03/02/2022 17:48:38 - INFO - utils.data - input_ids = [101, 8121, 3698, 952, 756, 2128, 1277, 1765, 1905, 762, 4178, 2372, 2108, 7599, 3698, 952, 8024, 3698, 952, 3946, 1469, 8024, 1724, 2108, 1146, 3209, 8024, 7433, 7030, 1041, 3764, 102]
03/02/2022 17:48:38 - INFO - utils.data - attention_mask = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
03/02/2022 17:48:38 - INFO - utils.data - labels = [[4, 6, 44, 9, 15]]
03/02/2022 17:48:41 - INFO - __main__ - ********** Running training **********
03/02/2022 17:48:41 - INFO - __main__ -   Num examples = 172858
03/02/2022 17:48:41 - INFO - __main__ -   Num Epochs = 20
03/02/2022 17:48:41 - INFO - __main__ -   Instantaneous batch size per device = 16
03/02/2022 17:48:41 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
03/02/2022 17:48:41 - INFO - __main__ -   Gradient Accumulation steps = 1
03/02/2022 17:48:41 - INFO - __main__ -   Gradient Accumulation steps = 1
03/02/2022 17:48:41 - INFO - __main__ -   Total optimization steps = 216080
03/02/2022 17:48:41 - INFO - __main__ - **********  Configuration Arguments **********
03/02/2022 17:48:41 - INFO - __main__ - adam_epsilon: 1e-08
03/02/2022 17:48:41 - INFO - __main__ - cache_dir: data_caches
03/02/2022 17:48:41 - INFO - __main__ - gradient_accumulation_steps: 1
03/02/2022 17:48:41 - INFO - __main__ - id2predicate: {0: '祖籍', 1: '父亲', 2: '总部地点', 3: '出生地', 4: '目', 5: '面积', 6: '简称', 7: '上映时间', 8: '妻子', 9: '所属专辑', 10: '注册资本', 11: '首都', 12: '导演', 13: '字', 14: '身高', 15: '出品公司', 16: '修业年限', 17: '出生日期', 18: '制片人', 19: '母亲', 20: '编剧', 21: '国籍', 22: '海拔', 23: '连载网站', 24: '丈夫', 25: '朝代', 26: '民族', 27: '号', 28: '出版社', 29: '主持人', 30: '专业代码', 31: '歌手', 32: '作词', 33: '主角', 34: '董事长', 35: '成立日期', 36: '毕业院校', 37: '占地面积', 38: '官方语言', 39: '邮政编码', 40: '人口数量', 41: '所在城市', 42: '作者', 43: '作曲', 44: '气候', 45: '嘉宾', 46: '主演', 47: '改编自', 48: '创始人'}
03/02/2022 17:48:41 - INFO - __main__ - id2tag: {0: '祖籍=SH2OH', 1: '父亲=SH2OH', 2: '总部地点=SH2OH', 3: '出生地=SH2OH', 4: '目=SH2OH', 5: '面积=SH2OH', 6: '简称=SH2OH', 7: '上映时间=SH2OH', 8: '妻子=SH2OH', 9: '所属专辑=SH2OH', 10: '注册资本=SH2OH', 11: '首都=SH2OH', 12: '导演=SH2OH', 13: '字=SH2OH', 14: '身高=SH2OH', 15: '出品公司=SH2OH', 16: '修业年限=SH2OH', 17: '出生日期=SH2OH', 18: '制片人=SH2OH', 19: '母亲=SH2OH', 20: '编剧=SH2OH', 21: '国籍=SH2OH', 22: '海拔=SH2OH', 23: '连载网站=SH2OH', 24: '丈夫=SH2OH', 25: '朝代=SH2OH', 26: '民族=SH2OH', 27: '号=SH2OH', 28: '出版社=SH2OH', 29: '主持人=SH2OH', 30: '专业代码=SH2OH', 31: '歌手=SH2OH', 32: '作词=SH2OH', 33: '主角=SH2OH', 34: '董事长=SH2OH', 35: '成立日期=SH2OH', 36: '毕业院校=SH2OH', 37: '占地面积=SH2OH', 38: '官方语言=SH2OH', 39: '邮政编码=SH2OH', 40: '人口数量=SH2OH', 41: '所在城市=SH2OH', 42: '作者=SH2OH', 43: '作曲=SH2OH', 44: '气候=SH2OH', 45: '嘉宾=SH2OH', 46: '主演=SH2OH', 47: '改编自=SH2OH', 48: '创始人=SH2OH', 49: '祖籍=OH2SH', 50: '父亲=OH2SH', 51: '总部地点=OH2SH', 52: '出生地=OH2SH', 53: '目=OH2SH', 54: '面积=OH2SH', 55: '简称=OH2SH', 56: '上映时间=OH2SH', 57: '妻子=OH2SH', 58: '所属专辑=OH2SH', 59: '注册资本=OH2SH', 60: '首都=OH2SH', 61: '导演=OH2SH', 62: '字=OH2SH', 63: '身高=OH2SH', 64: '出品公司=OH2SH', 65: '修业年限=OH2SH', 66: '出生日期=OH2SH', 67: '制片人=OH2SH', 68: '母亲=OH2SH', 69: '编剧=OH2SH', 70: '国籍=OH2SH', 71: '海拔=OH2SH', 72: '连载网站=OH2SH', 73: '丈夫=OH2SH', 74: '朝代=OH2SH', 75: '民族=OH2SH', 76: '号=OH2SH', 77: '出版社=OH2SH', 78: '主持人=OH2SH', 79: '专业代码=OH2SH', 80: '歌手=OH2SH', 81: '作词=OH2SH', 82: '主角=OH2SH', 83: '董事长=OH2SH', 84: '成立日期=OH2SH', 85: '毕业院校=OH2SH', 86: '占地面积=OH2SH', 87: '官方语言=OH2SH', 88: '邮政编码=OH2SH', 89: '人口数量=OH2SH', 90: '所在城市=OH2SH', 91: '作者=OH2SH', 92: '作曲=OH2SH', 93: '气候=OH2SH', 94: '嘉宾=OH2SH', 95: '主演=OH2SH', 96: '改编自=OH2SH', 97: '创始人=OH2SH', 98: '祖籍=ST2OT', 99: '父亲=ST2OT', 100: '总部地点=ST2OT', 101: '出生地=ST2OT', 102: '目=ST2OT', 103: '面积=ST2OT', 104: '简称=ST2OT', 105: '上映时间=ST2OT', 106: '妻子=ST2OT', 107: '所属专辑=ST2OT', 108: '注册资本=ST2OT', 109: '首都=ST2OT', 110: '导演=ST2OT', 111: '字=ST2OT', 112: '身高=ST2OT', 113: '出品公司=ST2OT', 114: '修业年限=ST2OT', 115: '出生日期=ST2OT', 116: '制片人=ST2OT', 117: '母亲=ST2OT', 118: '编剧=ST2OT', 119: '国籍=ST2OT', 120: '海拔=ST2OT', 121: '连载网站=ST2OT', 122: '丈夫=ST2OT', 123: '朝代=ST2OT', 124: '民族=ST2OT', 125: '号=ST2OT', 126: '出版社=ST2OT', 127: '主持人=ST2OT', 128: '专业代码=ST2OT', 129: '歌手=ST2OT', 130: '作词=ST2OT', 131: '主角=ST2OT', 132: '董事长=ST2OT', 133: '成立日期=ST2OT', 134: '毕业院校=ST2OT', 135: '占地面积=ST2OT', 136: '官方语言=ST2OT', 137: '邮政编码=ST2OT', 138: '人口数量=ST2OT', 139: '所在城市=ST2OT', 140: '作者=ST2OT', 141: '作曲=ST2OT', 142: '气候=ST2OT', 143: '嘉宾=ST2OT', 144: '主演=ST2OT', 145: '改编自=ST2OT', 146: '创始人=ST2OT', 147: '祖籍=OT2ST', 148: '父亲=OT2ST', 149: '总部地点=OT2ST', 150: '出生地=OT2ST', 151: '目=OT2ST', 152: '面积=OT2ST', 153: '简称=OT2ST', 154: '上映时间=OT2ST', 155: '妻子=OT2ST', 156: '所属专辑=OT2ST', 157: '注册资本=OT2ST', 158: '首都=OT2ST', 159: '导演=OT2ST', 160: '字=OT2ST', 161: '身高=OT2ST', 162: '出品公司=OT2ST', 163: '修业年限=OT2ST', 164: '出生日期=OT2ST', 165: '制片人=OT2ST', 166: '母亲=OT2ST', 167: '编剧=OT2ST', 168: '国籍=OT2ST', 169: '海拔=OT2ST', 170: '连载网站=OT2ST', 171: '丈夫=OT2ST', 172: '朝代=OT2ST', 173: '民族=OT2ST', 174: '号=OT2ST', 175: '出版社=OT2ST', 176: '主持人=OT2ST', 177: '专业代码=OT2ST', 178: '歌手=OT2ST', 179: '作词=OT2ST', 180: '主角=OT2ST', 181: '董事长=OT2ST', 182: '成立日期=OT2ST', 183: '毕业院校=OT2ST', 184: '占地面积=OT2ST', 185: '官方语言=OT2ST', 186: '邮政编码=OT2ST', 187: '人口数量=OT2ST', 188: '所在城市=OT2ST', 189: '作者=OT2ST', 190: '作曲=OT2ST', 191: '气候=OT2ST', 192: '嘉宾=OT2ST', 193: '主演=OT2ST', 194: '改编自=OT2ST', 195: '创始人=OT2ST', 196: 'DEFAULT=EH2ET'}
03/02/2022 17:48:41 - INFO - __main__ - learning_rate: 3e-05
03/02/2022 17:48:41 - INFO - __main__ - log_dir: ./outputs/bert-bert-base-chinese/logs
03/02/2022 17:48:41 - INFO - __main__ - logging_steps: 200
03/02/2022 17:48:41 - INFO - __main__ - lr_scheduler_type: linear
03/02/2022 17:48:41 - INFO - __main__ - max_grad_norm: 1.0
03/02/2022 17:48:41 - INFO - __main__ - max_length: 128
03/02/2022 17:48:41 - INFO - __main__ - max_train_steps: 216080
03/02/2022 17:48:41 - INFO - __main__ - method: tplinker_plus
03/02/2022 17:48:41 - INFO - __main__ - model_cache_dir: /mnt/f/hf/models
03/02/2022 17:48:41 - INFO - __main__ - model_type: bert
03/02/2022 17:48:41 - INFO - __main__ - model_weights: bert-base-chinese
03/02/2022 17:48:41 - INFO - __main__ - num_labels: 49
03/02/2022 17:48:41 - INFO - __main__ - num_train_epochs: 20
03/02/2022 17:48:41 - INFO - __main__ - num_warmup_steps: 21608
03/02/2022 17:48:41 - INFO - __main__ - num_warmup_steps_or_radios: 0.1
03/02/2022 17:48:41 - INFO - __main__ - num_workers: 6
03/02/2022 17:48:41 - INFO - __main__ - output_dir: ./outputs/bert-bert-base-chinese
03/02/2022 17:48:41 - INFO - __main__ - per_device_eval_batch_size: 32
03/02/2022 17:48:41 - INFO - __main__ - per_device_train_batch_size: 16
03/02/2022 17:48:41 - INFO - __main__ - predicate2id: {'祖籍': 0, '父亲': 1, '总部地点': 2, '出生地': 3, '目': 4, '面积': 5, '简称': 6, '上映时间': 7, '妻子': 8, '所属专辑': 9, '注册资本': 10, '首都': 11, '导演': 12, '字': 13, '身高': 14, '出品公司': 15, '修业年限': 16, '出生日期': 17, '制片人': 18, '母亲': 19, '编剧': 20, '国籍': 21, '海拔': 22, '连载网站': 23, '丈夫': 24, '朝代': 25, '民族': 26, '号': 27, '出版社': 28, '主持人': 29, '专业代码': 30, '歌手': 31, '作词': 32, '主角': 33, '董事长': 34, '成立日期': 35, '毕业院校': 36, '占地面积': 37, '官方语言': 38, '邮政编码': 39, '人口数量': 40, '所在城市': 41, '作者': 42, '作曲': 43, '气候': 44, '嘉宾': 45, '主演': 46, '改编自': 47, '创始人': 48}
03/02/2022 17:48:41 - INFO - __main__ - pretrained_model_name_or_path: bert-base-chinese
03/02/2022 17:48:41 - INFO - __main__ - save_steps: 10804
03/02/2022 17:48:41 - INFO - __main__ - seed: 42
03/02/2022 17:48:41 - INFO - __main__ - tag2id: {'祖籍=SH2OH': 0, '父亲=SH2OH': 1, '总部地点=SH2OH': 2, '出生地=SH2OH': 3, '目=SH2OH': 4, '面积=SH2OH': 5, '简称=SH2OH': 6, '上映时间=SH2OH': 7, '妻子=SH2OH': 8, '所属专辑=SH2OH': 9, '注册资本=SH2OH': 10, '首都=SH2OH': 11, '导演=SH2OH': 12, '字=SH2OH': 13, '身高=SH2OH': 14, '出品公司=SH2OH': 15, '修业年限=SH2OH': 16, '出生日期=SH2OH': 17, '制片人=SH2OH': 18, '母亲=SH2OH': 19, '编剧=SH2OH': 20, '国籍=SH2OH': 21, '海拔=SH2OH': 22, '连载网站=SH2OH': 23, '丈夫=SH2OH': 24, '朝代=SH2OH': 25, '民族=SH2OH': 26, '号=SH2OH': 27, '出版社=SH2OH': 28, '主持人=SH2OH': 29, '专业代码=SH2OH': 30, '歌手=SH2OH': 31, '作词=SH2OH': 32, '主角=SH2OH': 33, '董事长=SH2OH': 34, '成立日期=SH2OH': 35, '毕业院校=SH2OH': 36, '占地面积=SH2OH': 37, '官方语言=SH2OH': 38, '邮政编码=SH2OH': 39, '人口数量=SH2OH': 40, '所在城市=SH2OH': 41, '作者=SH2OH': 42, '作曲=SH2OH': 43, '气候=SH2OH': 44, '嘉宾=SH2OH': 45, '主演=SH2OH': 46, '改编自=SH2OH': 47, '创始人=SH2OH': 48, '祖籍=OH2SH': 49, '父亲=OH2SH': 50, '总部地点=OH2SH': 51, '出生地=OH2SH': 52, '目=OH2SH': 53, '面积=OH2SH': 54, '简称=OH2SH': 55, '上映时间=OH2SH': 56, '妻子=OH2SH': 57, '所属专辑=OH2SH': 58, '注册资本=OH2SH': 59, '首都=OH2SH': 60, '导演=OH2SH': 61, '字=OH2SH': 62, '身高=OH2SH': 63, '出品公司=OH2SH': 64, '修业年限=OH2SH': 65, '出生日期=OH2SH': 66, '制片人=OH2SH': 67, '母亲=OH2SH': 68, '编剧=OH2SH': 69, '国籍=OH2SH': 70, '海拔=OH2SH': 71, '连载网站=OH2SH': 72, '丈夫=OH2SH': 73, '朝代=OH2SH': 74, '民族=OH2SH': 75, '号=OH2SH': 76, '出版社=OH2SH': 77, '主持人=OH2SH': 78, '专业代码=OH2SH': 79, '歌手=OH2SH': 80, '作词=OH2SH': 81, '主角=OH2SH': 82, '董事长=OH2SH': 83, '成立日期=OH2SH': 84, '毕业院校=OH2SH': 85, '占地面积=OH2SH': 86, '官方语言=OH2SH': 87, '邮政编码=OH2SH': 88, '人口数量=OH2SH': 89, '所在城市=OH2SH': 90, '作者=OH2SH': 91, '作曲=OH2SH': 92, '气候=OH2SH': 93, '嘉宾=OH2SH': 94, '主演=OH2SH': 95, '改编自=OH2SH': 96, '创始人=OH2SH': 97, '祖籍=ST2OT': 98, '父亲=ST2OT': 99, '总部地点=ST2OT': 100, '出生地=ST2OT': 101, '目=ST2OT': 102, '面积=ST2OT': 103, '简称=ST2OT': 104, '上映时间=ST2OT': 105, '妻子=ST2OT': 106, '所属专辑=ST2OT': 107, '注册资本=ST2OT': 108, '首都=ST2OT': 109, '导演=ST2OT': 110, '字=ST2OT': 111, '身高=ST2OT': 112, '出品公司=ST2OT': 113, '修业年限=ST2OT': 114, '出生日期=ST2OT': 115, '制片人=ST2OT': 116, '母亲=ST2OT': 117, '编剧=ST2OT': 118, '国籍=ST2OT': 119, '海拔=ST2OT': 120, '连载网站=ST2OT': 121, '丈夫=ST2OT': 122, '朝代=ST2OT': 123, '民族=ST2OT': 124, '号=ST2OT': 125, '出版社=ST2OT': 126, '主持人=ST2OT': 127, '专业代码=ST2OT': 128, '歌手=ST2OT': 129, '作词=ST2OT': 130, '主角=ST2OT': 131, '董事长=ST2OT': 132, '成立日期=ST2OT': 133, '毕业院校=ST2OT': 134, '占地面积=ST2OT': 135, '官方语言=ST2OT': 136, '邮政编码=ST2OT': 137, '人口数量=ST2OT': 138, '所在城市=ST2OT': 139, '作者=ST2OT': 140, '作曲=ST2OT': 141, '气候=ST2OT': 142, '嘉宾=ST2OT': 143, '主演=ST2OT': 144, '改编自=ST2OT': 145, '创始人=ST2OT': 146, '祖籍=OT2ST': 147, '父亲=OT2ST': 148, '总部地点=OT2ST': 149, '出生地=OT2ST': 150, '目=OT2ST': 151, '面积=OT2ST': 152, '简称=OT2ST': 153, '上映时间=OT2ST': 154, '妻子=OT2ST': 155, '所属专辑=OT2ST': 156, '注册资本=OT2ST': 157, '首都=OT2ST': 158, '导演=OT2ST': 159, '字=OT2ST': 160, '身高=OT2ST': 161, '出品公司=OT2ST': 162, '修业年限=OT2ST': 163, '出生日期=OT2ST': 164, '制片人=OT2ST': 165, '母亲=OT2ST': 166, '编剧=OT2ST': 167, '国籍=OT2ST': 168, '海拔=OT2ST': 169, '连载网站=OT2ST': 170, '丈夫=OT2ST': 171, '朝代=OT2ST': 172, '民族=OT2ST': 173, '号=OT2ST': 174, '出版社=OT2ST': 175, '主持人=OT2ST': 176, '专业代码=OT2ST': 177, '歌手=OT2ST': 178, '作词=OT2ST': 179, '主角=OT2ST': 180, '董事长=OT2ST': 181, '成立日期=OT2ST': 182, '毕业院校=OT2ST': 183, '占地面积=OT2ST': 184, '官方语言=OT2ST': 185, '邮政编码=OT2ST': 186, '人口数量=OT2ST': 187, '所在城市=OT2ST': 188, '作者=OT2ST': 189, '作曲=OT2ST': 190, '气候=OT2ST': 191, '嘉宾=OT2ST': 192, '主演=OT2ST': 193, '改编自=OT2ST': 194, '创始人=OT2ST': 195, 'DEFAULT=EH2ET': 196}
03/02/2022 17:48:41 - INFO - __main__ - tokenizer_name: None
03/02/2022 17:48:41 - INFO - __main__ - topk: 1
03/02/2022 17:48:41 - INFO - __main__ - total_batch_size: 16
03/02/2022 17:48:41 - INFO - __main__ - weight_decay: 0.02
03/02/2022 17:48:41 - INFO - __main__ - writer_type: tensorboard
03/02/2022 17:48:41 - INFO - __main__ - **************************************************
03/02/2022 17:49:34 - INFO - __main__ - global_steps 200 - lr: 0.00000028  loss: 6.36230171
03/02/2022 17:50:29 - INFO - __main__ - global_steps 400 - lr: 0.00000056  loss: 5.35159109
03/02/2022 17:51:21 - INFO - __main__ - global_steps 600 - lr: 0.00000083  loss: 3.85690084
03/02/2022 17:52:13 - INFO - __main__ - global_steps 800 - lr: 0.00000111  loss: 2.30692923
03/02/2022 17:53:04 - INFO - __main__ - global_steps 1000 - lr: 0.00000139  loss: 1.03444797
03/02/2022 17:53:56 - INFO - __main__ - global_steps 1200 - lr: 0.00000167  loss: 0.24046603
03/02/2022 17:54:48 - INFO - __main__ - global_steps 1400 - lr: 0.00000194  loss: 0.04162083
03/02/2022 17:55:38 - INFO - __main__ - global_steps 1600 - lr: 0.00000222  loss: 0.02264410
03/02/2022 17:56:30 - INFO - __main__ - global_steps 1800 - lr: 0.00000250  loss: 0.01716225
03/02/2022 17:57:21 - INFO - __main__ - global_steps 2000 - lr: 0.00000278  loss: 0.01507018
03/02/2022 17:58:13 - INFO - __main__ - global_steps 2200 - lr: 0.00000305  loss: 0.01287395
03/02/2022 17:59:04 - INFO - __main__ - global_steps 2400 - lr: 0.00000333  loss: 0.01216996
03/02/2022 17:59:56 - INFO - __main__ - global_steps 2600 - lr: 0.00000361  loss: 0.01126327
03/02/2022 18:00:47 - INFO - __main__ - global_steps 2800 - lr: 0.00000389  loss: 0.00961043
03/02/2022 18:01:38 - INFO - __main__ - global_steps 3000 - lr: 0.00000417  loss: 0.00862037
03/02/2022 18:02:30 - INFO - __main__ - global_steps 3200 - lr: 0.00000444  loss: 0.00739390
03/02/2022 18:03:21 - INFO - __main__ - global_steps 3400 - lr: 0.00000472  loss: 0.00623457
03/02/2022 18:04:12 - INFO - __main__ - global_steps 3600 - lr: 0.00000500  loss: 0.00584162
03/02/2022 18:05:03 - INFO - __main__ - global_steps 3800 - lr: 0.00000528  loss: 0.00520081
03/02/2022 18:05:54 - INFO - __main__ - global_steps 4000 - lr: 0.00000555  loss: 0.00449289
03/02/2022 18:06:46 - INFO - __main__ - global_steps 4200 - lr: 0.00000583  loss: 0.00425216
03/02/2022 18:07:39 - INFO - __main__ - global_steps 4400 - lr: 0.00000611  loss: 0.00380403
03/02/2022 18:08:28 - INFO - __main__ - global_steps 4600 - lr: 0.00000639  loss: 0.00361214
03/02/2022 18:09:19 - INFO - __main__ - global_steps 4800 - lr: 0.00000666  loss: 0.00329387
03/02/2022 18:10:09 - INFO - __main__ - global_steps 5000 - lr: 0.00000694  loss: 0.00316956
03/02/2022 18:10:58 - INFO - __main__ - global_steps 5200 - lr: 0.00000722  loss: 0.00301104
03/02/2022 18:11:50 - INFO - __main__ - global_steps 5400 - lr: 0.00000750  loss: 0.00270269
03/02/2022 18:12:43 - INFO - __main__ - global_steps 5600 - lr: 0.00000777  loss: 0.00245876
03/02/2022 18:13:33 - INFO - __main__ - global_steps 5800 - lr: 0.00000805  loss: 0.00256737
03/02/2022 18:14:24 - INFO - __main__ - global_steps 6000 - lr: 0.00000833  loss: 0.00236288
03/02/2022 18:15:15 - INFO - __main__ - global_steps 6200 - lr: 0.00000861  loss: 0.00235183
03/02/2022 18:16:07 - INFO - __main__ - global_steps 6400 - lr: 0.00000889  loss: 0.00228745
03/02/2022 18:16:58 - INFO - __main__ - global_steps 6600 - lr: 0.00000916  loss: 0.00218744
03/02/2022 18:17:50 - INFO - __main__ - global_steps 6800 - lr: 0.00000944  loss: 0.00199561
03/02/2022 18:18:41 - INFO - __main__ - global_steps 7000 - lr: 0.00000972  loss: 0.00199199
03/02/2022 18:19:34 - INFO - __main__ - global_steps 7200 - lr: 0.00001000  loss: 0.00192513
03/02/2022 18:20:25 - INFO - __main__ - global_steps 7400 - lr: 0.00001027  loss: 0.00198937
03/02/2022 18:21:18 - INFO - __main__ - global_steps 7600 - lr: 0.00001055  loss: 0.00182970
03/02/2022 18:22:11 - INFO - __main__ - global_steps 7800 - lr: 0.00001083  loss: 0.00186055
03/02/2022 18:23:02 - INFO - __main__ - global_steps 8000 - lr: 0.00001111  loss: 0.00176200
03/02/2022 18:23:54 - INFO - __main__ - global_steps 8200 - lr: 0.00001138  loss: 0.00169327
03/02/2022 18:24:44 - INFO - __main__ - global_steps 8400 - lr: 0.00001166  loss: 0.00180359
03/02/2022 18:25:38 - INFO - __main__ - global_steps 8600 - lr: 0.00001194  loss: 0.00184147
03/02/2022 18:26:29 - INFO - __main__ - global_steps 8800 - lr: 0.00001222  loss: 0.00167127
03/02/2022 18:27:21 - INFO - __main__ - global_steps 9000 - lr: 0.00001250  loss: 0.00153032
03/02/2022 18:28:12 - INFO - __main__ - global_steps 9200 - lr: 0.00001277  loss: 0.00162873
03/02/2022 18:29:04 - INFO - __main__ - global_steps 9400 - lr: 0.00001305  loss: 0.00160468
03/02/2022 18:29:55 - INFO - __main__ - global_steps 9600 - lr: 0.00001333  loss: 0.00159264
03/02/2022 18:30:45 - INFO - __main__ - global_steps 9800 - lr: 0.00001361  loss: 0.00164570
03/02/2022 18:31:36 - INFO - __main__ - global_steps 10000 - lr: 0.00001388  loss: 0.00174055
03/02/2022 18:32:26 - INFO - __main__ - global_steps 10200 - lr: 0.00001416  loss: 0.00160866
03/02/2022 18:33:17 - INFO - __main__ - global_steps 10400 - lr: 0.00001444  loss: 0.00162596
03/02/2022 18:34:07 - INFO - __main__ - global_steps 10600 - lr: 0.00001472  loss: 0.00155726
03/02/2022 18:34:59 - INFO - __main__ - global_steps 10800 - lr: 0.00001499  loss: 0.00144479
03/02/2022 18:35:00 - INFO - __main__ - ********** Evaluate Step 10804 **********
03/02/2022 18:35:00 - INFO - __main__ - ##--------------------- Dev
03/02/2022 18:38:11 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 18:38:11 - INFO - __main__ - f1 = 0.7610688557943677
03/02/2022 18:38:11 - INFO - __main__ - precision = 0.8252738513634852
03/02/2022 18:38:11 - INFO - __main__ - recall = 0.7061328416523998
03/02/2022 18:38:11 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 18:38:11 - INFO - __main__ - **--------------------- Dev End
03/02/2022 18:38:12 - INFO - __main__ - *************************************
03/02/2022 18:39:04 - INFO - __main__ - global_steps 11000 - lr: 0.00001527  loss: 0.00144853
03/02/2022 18:39:54 - INFO - __main__ - global_steps 11200 - lr: 0.00001555  loss: 0.00137674
03/02/2022 18:40:44 - INFO - __main__ - global_steps 11400 - lr: 0.00001583  loss: 0.00149514
03/02/2022 18:41:34 - INFO - __main__ - global_steps 11600 - lr: 0.00001611  loss: 0.00148071
03/02/2022 18:42:25 - INFO - __main__ - global_steps 11800 - lr: 0.00001638  loss: 0.00144264
03/02/2022 18:43:16 - INFO - __main__ - global_steps 12000 - lr: 0.00001666  loss: 0.00135459
03/02/2022 18:44:06 - INFO - __main__ - global_steps 12200 - lr: 0.00001694  loss: 0.00137282
03/02/2022 18:44:59 - INFO - __main__ - global_steps 12400 - lr: 0.00001722  loss: 0.00143292
03/02/2022 18:45:50 - INFO - __main__ - global_steps 12600 - lr: 0.00001749  loss: 0.00138445
03/02/2022 18:46:44 - INFO - __main__ - global_steps 12800 - lr: 0.00001777  loss: 0.00129252
03/02/2022 18:47:34 - INFO - __main__ - global_steps 13000 - lr: 0.00001805  loss: 0.00139264
03/02/2022 18:48:27 - INFO - __main__ - global_steps 13200 - lr: 0.00001833  loss: 0.00134572
03/02/2022 18:49:19 - INFO - __main__ - global_steps 13400 - lr: 0.00001860  loss: 0.00138538
03/02/2022 18:50:12 - INFO - __main__ - global_steps 13600 - lr: 0.00001888  loss: 0.00131357
03/02/2022 18:51:03 - INFO - __main__ - global_steps 13800 - lr: 0.00001916  loss: 0.00132862
03/02/2022 18:51:53 - INFO - __main__ - global_steps 14000 - lr: 0.00001944  loss: 0.00135985
03/02/2022 18:52:44 - INFO - __main__ - global_steps 14200 - lr: 0.00001971  loss: 0.00139700
03/02/2022 18:53:35 - INFO - __main__ - global_steps 14400 - lr: 0.00001999  loss: 0.00132426
03/02/2022 18:54:27 - INFO - __main__ - global_steps 14600 - lr: 0.00002027  loss: 0.00133931
03/02/2022 18:55:23 - INFO - __main__ - global_steps 14800 - lr: 0.00002055  loss: 0.00133504
03/02/2022 18:56:13 - INFO - __main__ - global_steps 15000 - lr: 0.00002083  loss: 0.00134278
03/02/2022 18:57:05 - INFO - __main__ - global_steps 15200 - lr: 0.00002110  loss: 0.00131538
03/02/2022 18:57:57 - INFO - __main__ - global_steps 15400 - lr: 0.00002138  loss: 0.00127220
03/02/2022 18:58:49 - INFO - __main__ - global_steps 15600 - lr: 0.00002166  loss: 0.00128735
03/02/2022 18:59:42 - INFO - __main__ - global_steps 15800 - lr: 0.00002194  loss: 0.00119069
03/02/2022 19:00:32 - INFO - __main__ - global_steps 16000 - lr: 0.00002221  loss: 0.00131219
03/02/2022 19:01:22 - INFO - __main__ - global_steps 16200 - lr: 0.00002249  loss: 0.00126921
03/02/2022 19:02:11 - INFO - __main__ - global_steps 16400 - lr: 0.00002277  loss: 0.00138000
03/02/2022 19:03:01 - INFO - __main__ - global_steps 16600 - lr: 0.00002305  loss: 0.00132067
03/02/2022 19:03:52 - INFO - __main__ - global_steps 16800 - lr: 0.00002332  loss: 0.00127370
03/02/2022 19:04:45 - INFO - __main__ - global_steps 17000 - lr: 0.00002360  loss: 0.00122944
03/02/2022 19:05:37 - INFO - __main__ - global_steps 17200 - lr: 0.00002388  loss: 0.00123615
03/02/2022 19:06:29 - INFO - __main__ - global_steps 17400 - lr: 0.00002416  loss: 0.00128864
03/02/2022 19:07:20 - INFO - __main__ - global_steps 17600 - lr: 0.00002444  loss: 0.00121608
03/02/2022 19:08:10 - INFO - __main__ - global_steps 17800 - lr: 0.00002471  loss: 0.00126581
03/02/2022 19:09:02 - INFO - __main__ - global_steps 18000 - lr: 0.00002499  loss: 0.00118991
03/02/2022 19:09:55 - INFO - __main__ - global_steps 18200 - lr: 0.00002527  loss: 0.00120071
03/02/2022 19:10:47 - INFO - __main__ - global_steps 18400 - lr: 0.00002555  loss: 0.00123161
03/02/2022 19:11:40 - INFO - __main__ - global_steps 18600 - lr: 0.00002582  loss: 0.00117845
03/02/2022 19:12:32 - INFO - __main__ - global_steps 18800 - lr: 0.00002610  loss: 0.00123898
03/02/2022 19:13:23 - INFO - __main__ - global_steps 19000 - lr: 0.00002638  loss: 0.00132467
03/02/2022 19:14:14 - INFO - __main__ - global_steps 19200 - lr: 0.00002666  loss: 0.00119772
03/02/2022 19:15:07 - INFO - __main__ - global_steps 19400 - lr: 0.00002693  loss: 0.00115018
03/02/2022 19:15:59 - INFO - __main__ - global_steps 19600 - lr: 0.00002721  loss: 0.00114351
03/02/2022 19:16:52 - INFO - __main__ - global_steps 19800 - lr: 0.00002749  loss: 0.00122399
03/02/2022 19:17:44 - INFO - __main__ - global_steps 20000 - lr: 0.00002777  loss: 0.00119281
03/02/2022 19:18:36 - INFO - __main__ - global_steps 20200 - lr: 0.00002805  loss: 0.00108551
03/02/2022 19:19:27 - INFO - __main__ - global_steps 20400 - lr: 0.00002832  loss: 0.00120468
03/02/2022 19:20:20 - INFO - __main__ - global_steps 20600 - lr: 0.00002860  loss: 0.00118175
03/02/2022 19:21:08 - INFO - __main__ - global_steps 20800 - lr: 0.00002888  loss: 0.00115899
03/02/2022 19:22:00 - INFO - __main__ - global_steps 21000 - lr: 0.00002916  loss: 0.00116447
03/02/2022 19:22:50 - INFO - __main__ - global_steps 21200 - lr: 0.00002943  loss: 0.00136627
03/02/2022 19:23:42 - INFO - __main__ - global_steps 21400 - lr: 0.00002971  loss: 0.00118251
03/02/2022 19:24:33 - INFO - __main__ - global_steps 21600 - lr: 0.00002999  loss: 0.00119899
03/02/2022 19:24:34 - INFO - __main__ - ********** Evaluate Step 21608 **********
03/02/2022 19:24:34 - INFO - __main__ - ##--------------------- Dev
03/02/2022 19:27:45 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 19:27:45 - INFO - __main__ - f1 = 0.7963355688803251
03/02/2022 19:27:45 - INFO - __main__ - precision = 0.7813879792965042
03/02/2022 19:27:45 - INFO - __main__ - recall = 0.8118661925457663
03/02/2022 19:27:45 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 19:27:45 - INFO - __main__ - **--------------------- Dev End
03/02/2022 19:27:46 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-10804-spo-f1-0.7610688557943677
03/02/2022 19:27:46 - INFO - __main__ - *************************************
03/02/2022 19:28:38 - INFO - __main__ - global_steps 21800 - lr: 0.00002997  loss: 0.00107391
03/02/2022 19:29:30 - INFO - __main__ - global_steps 22000 - lr: 0.00002994  loss: 0.00107511
03/02/2022 19:30:19 - INFO - __main__ - global_steps 22200 - lr: 0.00002991  loss: 0.00120231
03/02/2022 19:31:12 - INFO - __main__ - global_steps 22400 - lr: 0.00002988  loss: 0.00106157
03/02/2022 19:32:07 - INFO - __main__ - global_steps 22600 - lr: 0.00002985  loss: 0.00108812
03/02/2022 19:32:59 - INFO - __main__ - global_steps 22800 - lr: 0.00002982  loss: 0.00105811
03/02/2022 19:33:51 - INFO - __main__ - global_steps 23000 - lr: 0.00002979  loss: 0.00114844
03/02/2022 19:34:42 - INFO - __main__ - global_steps 23200 - lr: 0.00002975  loss: 0.00112813
03/02/2022 19:35:35 - INFO - __main__ - global_steps 23400 - lr: 0.00002972  loss: 0.00109504
03/02/2022 19:36:25 - INFO - __main__ - global_steps 23600 - lr: 0.00002969  loss: 0.00105479
03/02/2022 19:37:16 - INFO - __main__ - global_steps 23800 - lr: 0.00002966  loss: 0.00106800
03/02/2022 19:38:06 - INFO - __main__ - global_steps 24000 - lr: 0.00002963  loss: 0.00111120
03/02/2022 19:38:58 - INFO - __main__ - global_steps 24200 - lr: 0.00002960  loss: 0.00112450
03/02/2022 19:39:49 - INFO - __main__ - global_steps 24400 - lr: 0.00002957  loss: 0.00106819
03/02/2022 19:40:42 - INFO - __main__ - global_steps 24600 - lr: 0.00002954  loss: 0.00111315
03/02/2022 19:41:33 - INFO - __main__ - global_steps 24800 - lr: 0.00002951  loss: 0.00103460
03/02/2022 19:42:26 - INFO - __main__ - global_steps 25000 - lr: 0.00002948  loss: 0.00107374
03/02/2022 19:43:16 - INFO - __main__ - global_steps 25200 - lr: 0.00002945  loss: 0.00114729
03/02/2022 19:44:07 - INFO - __main__ - global_steps 25400 - lr: 0.00002942  loss: 0.00103969
03/02/2022 19:45:00 - INFO - __main__ - global_steps 25600 - lr: 0.00002938  loss: 0.00104253
03/02/2022 19:45:52 - INFO - __main__ - global_steps 25800 - lr: 0.00002935  loss: 0.00108080
03/02/2022 19:46:42 - INFO - __main__ - global_steps 26000 - lr: 0.00002932  loss: 0.00110927
03/02/2022 19:47:33 - INFO - __main__ - global_steps 26200 - lr: 0.00002929  loss: 0.00109893
03/02/2022 19:48:26 - INFO - __main__ - global_steps 26400 - lr: 0.00002926  loss: 0.00103175
03/02/2022 19:49:17 - INFO - __main__ - global_steps 26600 - lr: 0.00002923  loss: 0.00116493
03/02/2022 19:50:08 - INFO - __main__ - global_steps 26800 - lr: 0.00002920  loss: 0.00107218
03/02/2022 19:50:59 - INFO - __main__ - global_steps 27000 - lr: 0.00002917  loss: 0.00103984
03/02/2022 19:51:53 - INFO - __main__ - global_steps 27200 - lr: 0.00002914  loss: 0.00106788
03/02/2022 19:52:43 - INFO - __main__ - global_steps 27400 - lr: 0.00002911  loss: 0.00109940
03/02/2022 19:53:34 - INFO - __main__ - global_steps 27600 - lr: 0.00002908  loss: 0.00104673
03/02/2022 19:54:26 - INFO - __main__ - global_steps 27800 - lr: 0.00002904  loss: 0.00108131
03/02/2022 19:55:18 - INFO - __main__ - global_steps 28000 - lr: 0.00002901  loss: 0.00105022
03/02/2022 19:56:10 - INFO - __main__ - global_steps 28200 - lr: 0.00002898  loss: 0.00106512
03/02/2022 19:57:01 - INFO - __main__ - global_steps 28400 - lr: 0.00002895  loss: 0.00103646
03/02/2022 19:57:53 - INFO - __main__ - global_steps 28600 - lr: 0.00002892  loss: 0.00097512
03/02/2022 19:58:45 - INFO - __main__ - global_steps 28800 - lr: 0.00002889  loss: 0.00103720
03/02/2022 19:59:37 - INFO - __main__ - global_steps 29000 - lr: 0.00002886  loss: 0.00106524
03/02/2022 20:00:29 - INFO - __main__ - global_steps 29200 - lr: 0.00002883  loss: 0.00103343
03/02/2022 20:01:19 - INFO - __main__ - global_steps 29400 - lr: 0.00002880  loss: 0.00110853
03/02/2022 20:02:11 - INFO - __main__ - global_steps 29600 - lr: 0.00002877  loss: 0.00106447
03/02/2022 20:03:01 - INFO - __main__ - global_steps 29800 - lr: 0.00002874  loss: 0.00110481
03/02/2022 20:03:53 - INFO - __main__ - global_steps 30000 - lr: 0.00002871  loss: 0.00110912
03/02/2022 20:04:47 - INFO - __main__ - global_steps 30200 - lr: 0.00002867  loss: 0.00101296
03/02/2022 20:05:36 - INFO - __main__ - global_steps 30400 - lr: 0.00002864  loss: 0.00108297
03/02/2022 20:06:27 - INFO - __main__ - global_steps 30600 - lr: 0.00002861  loss: 0.00102298
03/02/2022 20:07:17 - INFO - __main__ - global_steps 30800 - lr: 0.00002858  loss: 0.00115031
03/02/2022 20:08:08 - INFO - __main__ - global_steps 31000 - lr: 0.00002855  loss: 0.00103880
03/02/2022 20:09:01 - INFO - __main__ - global_steps 31200 - lr: 0.00002852  loss: 0.00107647
03/02/2022 20:09:52 - INFO - __main__ - global_steps 31400 - lr: 0.00002849  loss: 0.00101260
03/02/2022 20:10:43 - INFO - __main__ - global_steps 31600 - lr: 0.00002846  loss: 0.00106721
03/02/2022 20:11:32 - INFO - __main__ - global_steps 31800 - lr: 0.00002843  loss: 0.00099292
03/02/2022 20:12:25 - INFO - __main__ - global_steps 32000 - lr: 0.00002840  loss: 0.00104694
03/02/2022 20:13:18 - INFO - __main__ - global_steps 32200 - lr: 0.00002837  loss: 0.00097617
03/02/2022 20:14:11 - INFO - __main__ - global_steps 32400 - lr: 0.00002834  loss: 0.00105833
03/02/2022 20:14:14 - INFO - __main__ - ********** Evaluate Step 32412 **********
03/02/2022 20:14:14 - INFO - __main__ - ##--------------------- Dev
03/02/2022 20:17:26 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 20:17:26 - INFO - __main__ - f1 = 0.8078224566029448
03/02/2022 20:17:26 - INFO - __main__ - precision = 0.8086753772381333
03/02/2022 20:17:26 - INFO - __main__ - recall = 0.8069713332455336
03/02/2022 20:17:26 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 20:17:26 - INFO - __main__ - **--------------------- Dev End
03/02/2022 20:17:26 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-21608-spo-f1-0.7963355688803251
03/02/2022 20:17:26 - INFO - __main__ - *************************************
03/02/2022 20:18:17 - INFO - __main__ - global_steps 32600 - lr: 0.00002830  loss: 0.00095260
03/02/2022 20:19:11 - INFO - __main__ - global_steps 32800 - lr: 0.00002827  loss: 0.00087311
03/02/2022 20:20:04 - INFO - __main__ - global_steps 33000 - lr: 0.00002824  loss: 0.00085621
03/02/2022 20:20:55 - INFO - __main__ - global_steps 33200 - lr: 0.00002821  loss: 0.00095231
03/02/2022 20:21:46 - INFO - __main__ - global_steps 33400 - lr: 0.00002818  loss: 0.00093045
03/02/2022 20:22:37 - INFO - __main__ - global_steps 33600 - lr: 0.00002815  loss: 0.00085726
03/02/2022 20:23:28 - INFO - __main__ - global_steps 33800 - lr: 0.00002812  loss: 0.00096798
03/02/2022 20:24:20 - INFO - __main__ - global_steps 34000 - lr: 0.00002809  loss: 0.00087393
03/02/2022 20:25:14 - INFO - __main__ - global_steps 34200 - lr: 0.00002806  loss: 0.00091220
03/02/2022 20:26:07 - INFO - __main__ - global_steps 34400 - lr: 0.00002803  loss: 0.00090327
03/02/2022 20:26:59 - INFO - __main__ - global_steps 34600 - lr: 0.00002800  loss: 0.00097260
03/02/2022 20:27:52 - INFO - __main__ - global_steps 34800 - lr: 0.00002796  loss: 0.00093782
03/02/2022 20:28:44 - INFO - __main__ - global_steps 35000 - lr: 0.00002793  loss: 0.00095697
03/02/2022 20:29:36 - INFO - __main__ - global_steps 35200 - lr: 0.00002790  loss: 0.00093176
03/02/2022 20:30:27 - INFO - __main__ - global_steps 35400 - lr: 0.00002787  loss: 0.00093097
03/02/2022 20:31:18 - INFO - __main__ - global_steps 35600 - lr: 0.00002784  loss: 0.00092397
03/02/2022 20:32:11 - INFO - __main__ - global_steps 35800 - lr: 0.00002781  loss: 0.00095183
03/02/2022 20:33:03 - INFO - __main__ - global_steps 36000 - lr: 0.00002778  loss: 0.00093678
03/02/2022 20:33:54 - INFO - __main__ - global_steps 36200 - lr: 0.00002775  loss: 0.00090774
03/02/2022 20:34:45 - INFO - __main__ - global_steps 36400 - lr: 0.00002772  loss: 0.00096249
03/02/2022 20:35:38 - INFO - __main__ - global_steps 36600 - lr: 0.00002769  loss: 0.00092774
03/02/2022 20:36:30 - INFO - __main__ - global_steps 36800 - lr: 0.00002766  loss: 0.00096414
03/02/2022 20:37:21 - INFO - __main__ - global_steps 37000 - lr: 0.00002763  loss: 0.00094949
03/02/2022 20:38:13 - INFO - __main__ - global_steps 37200 - lr: 0.00002759  loss: 0.00091977
03/02/2022 20:39:05 - INFO - __main__ - global_steps 37400 - lr: 0.00002756  loss: 0.00103367
03/02/2022 20:39:59 - INFO - __main__ - global_steps 37600 - lr: 0.00002753  loss: 0.00093238
03/02/2022 20:40:53 - INFO - __main__ - global_steps 37800 - lr: 0.00002750  loss: 0.00092530
03/02/2022 20:41:47 - INFO - __main__ - global_steps 38000 - lr: 0.00002747  loss: 0.00092487
03/02/2022 20:42:41 - INFO - __main__ - global_steps 38200 - lr: 0.00002744  loss: 0.00091670
03/02/2022 20:43:33 - INFO - __main__ - global_steps 38400 - lr: 0.00002741  loss: 0.00097982
03/02/2022 20:44:25 - INFO - __main__ - global_steps 38600 - lr: 0.00002738  loss: 0.00087440
03/02/2022 20:45:20 - INFO - __main__ - global_steps 38800 - lr: 0.00002735  loss: 0.00086362
03/02/2022 20:46:13 - INFO - __main__ - global_steps 39000 - lr: 0.00002732  loss: 0.00097591
03/02/2022 20:47:07 - INFO - __main__ - global_steps 39200 - lr: 0.00002729  loss: 0.00098707
03/02/2022 20:47:59 - INFO - __main__ - global_steps 39400 - lr: 0.00002726  loss: 0.00100042
03/02/2022 20:48:53 - INFO - __main__ - global_steps 39600 - lr: 0.00002722  loss: 0.00093477
03/02/2022 20:49:45 - INFO - __main__ - global_steps 39800 - lr: 0.00002719  loss: 0.00096109
03/02/2022 20:50:39 - INFO - __main__ - global_steps 40000 - lr: 0.00002716  loss: 0.00090757
03/02/2022 20:51:33 - INFO - __main__ - global_steps 40200 - lr: 0.00002713  loss: 0.00095506
03/02/2022 20:52:27 - INFO - __main__ - global_steps 40400 - lr: 0.00002710  loss: 0.00090085
03/02/2022 20:53:20 - INFO - __main__ - global_steps 40600 - lr: 0.00002707  loss: 0.00092752
03/02/2022 20:54:12 - INFO - __main__ - global_steps 40800 - lr: 0.00002704  loss: 0.00091098
03/02/2022 20:55:06 - INFO - __main__ - global_steps 41000 - lr: 0.00002701  loss: 0.00091620
03/02/2022 20:56:00 - INFO - __main__ - global_steps 41200 - lr: 0.00002698  loss: 0.00092978
03/02/2022 20:56:55 - INFO - __main__ - global_steps 41400 - lr: 0.00002695  loss: 0.00088399
03/02/2022 20:57:46 - INFO - __main__ - global_steps 41600 - lr: 0.00002692  loss: 0.00094585
03/02/2022 20:58:38 - INFO - __main__ - global_steps 41800 - lr: 0.00002689  loss: 0.00095711
03/02/2022 20:59:32 - INFO - __main__ - global_steps 42000 - lr: 0.00002685  loss: 0.00096161
03/02/2022 21:00:24 - INFO - __main__ - global_steps 42200 - lr: 0.00002682  loss: 0.00098058
03/02/2022 21:01:20 - INFO - __main__ - global_steps 42400 - lr: 0.00002679  loss: 0.00090867
03/02/2022 21:02:13 - INFO - __main__ - global_steps 42600 - lr: 0.00002676  loss: 0.00096142
03/02/2022 21:03:04 - INFO - __main__ - global_steps 42800 - lr: 0.00002673  loss: 0.00097114
03/02/2022 21:03:59 - INFO - __main__ - global_steps 43000 - lr: 0.00002670  loss: 0.00087562
03/02/2022 21:04:52 - INFO - __main__ - global_steps 43200 - lr: 0.00002667  loss: 0.00094536
03/02/2022 21:04:56 - INFO - __main__ - ********** Evaluate Step 43216 **********
03/02/2022 21:04:56 - INFO - __main__ - ##--------------------- Dev
03/02/2022 21:08:15 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 21:08:15 - INFO - __main__ - f1 = 0.8103291548363208
03/02/2022 21:08:15 - INFO - __main__ - precision = 0.8290201841603715
03/02/2022 21:08:15 - INFO - __main__ - recall = 0.7924623556784762
03/02/2022 21:08:15 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 21:08:15 - INFO - __main__ - **--------------------- Dev End
03/02/2022 21:08:15 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-32412-spo-f1-0.8078224566029448
03/02/2022 21:08:15 - INFO - __main__ - *************************************
03/02/2022 21:09:04 - INFO - __main__ - global_steps 43400 - lr: 0.00002664  loss: 0.00085319
03/02/2022 21:09:58 - INFO - __main__ - global_steps 43600 - lr: 0.00002661  loss: 0.00082754
03/02/2022 21:10:52 - INFO - __main__ - global_steps 43800 - lr: 0.00002658  loss: 0.00082189
03/02/2022 21:11:49 - INFO - __main__ - global_steps 44000 - lr: 0.00002655  loss: 0.00080341
03/02/2022 21:12:44 - INFO - __main__ - global_steps 44200 - lr: 0.00002651  loss: 0.00075801
03/02/2022 21:13:38 - INFO - __main__ - global_steps 44400 - lr: 0.00002648  loss: 0.00075581
03/02/2022 21:14:31 - INFO - __main__ - global_steps 44600 - lr: 0.00002645  loss: 0.00080725
03/02/2022 21:15:23 - INFO - __main__ - global_steps 44800 - lr: 0.00002642  loss: 0.00085491
03/02/2022 21:16:17 - INFO - __main__ - global_steps 45000 - lr: 0.00002639  loss: 0.00081597
03/02/2022 21:17:07 - INFO - __main__ - global_steps 45200 - lr: 0.00002636  loss: 0.00087159
03/02/2022 21:17:59 - INFO - __main__ - global_steps 45400 - lr: 0.00002633  loss: 0.00091738
03/02/2022 21:18:51 - INFO - __main__ - global_steps 45600 - lr: 0.00002630  loss: 0.00081250
03/02/2022 21:19:44 - INFO - __main__ - global_steps 45800 - lr: 0.00002627  loss: 0.00082202
03/02/2022 21:20:38 - INFO - __main__ - global_steps 46000 - lr: 0.00002624  loss: 0.00081596
03/02/2022 21:21:32 - INFO - __main__ - global_steps 46200 - lr: 0.00002621  loss: 0.00081972
03/02/2022 21:22:24 - INFO - __main__ - global_steps 46400 - lr: 0.00002618  loss: 0.00084796
03/02/2022 21:23:18 - INFO - __main__ - global_steps 46600 - lr: 0.00002614  loss: 0.00078970
03/02/2022 21:24:11 - INFO - __main__ - global_steps 46800 - lr: 0.00002611  loss: 0.00084376
03/02/2022 21:25:04 - INFO - __main__ - global_steps 47000 - lr: 0.00002608  loss: 0.00076593
03/02/2022 21:25:57 - INFO - __main__ - global_steps 47200 - lr: 0.00002605  loss: 0.00083780
03/02/2022 21:26:50 - INFO - __main__ - global_steps 47400 - lr: 0.00002602  loss: 0.00086079
03/02/2022 21:27:43 - INFO - __main__ - global_steps 47600 - lr: 0.00002599  loss: 0.00081036
03/02/2022 21:28:37 - INFO - __main__ - global_steps 47800 - lr: 0.00002596  loss: 0.00079680
03/02/2022 21:29:30 - INFO - __main__ - global_steps 48000 - lr: 0.00002593  loss: 0.00082973
03/02/2022 21:30:23 - INFO - __main__ - global_steps 48200 - lr: 0.00002590  loss: 0.00078970
03/02/2022 21:31:16 - INFO - __main__ - global_steps 48400 - lr: 0.00002587  loss: 0.00081814
03/02/2022 21:32:09 - INFO - __main__ - global_steps 48600 - lr: 0.00002584  loss: 0.00089606
03/02/2022 21:33:02 - INFO - __main__ - global_steps 48800 - lr: 0.00002581  loss: 0.00081158
03/02/2022 21:33:55 - INFO - __main__ - global_steps 49000 - lr: 0.00002577  loss: 0.00081467
03/02/2022 21:34:47 - INFO - __main__ - global_steps 49200 - lr: 0.00002574  loss: 0.00084149
03/02/2022 21:35:40 - INFO - __main__ - global_steps 49400 - lr: 0.00002571  loss: 0.00089644
03/02/2022 21:36:34 - INFO - __main__ - global_steps 49600 - lr: 0.00002568  loss: 0.00080164
03/02/2022 21:37:28 - INFO - __main__ - global_steps 49800 - lr: 0.00002565  loss: 0.00084073
03/02/2022 21:38:21 - INFO - __main__ - global_steps 50000 - lr: 0.00002562  loss: 0.00085258
03/02/2022 21:39:16 - INFO - __main__ - global_steps 50200 - lr: 0.00002559  loss: 0.00082904
03/02/2022 21:40:10 - INFO - __main__ - global_steps 50400 - lr: 0.00002556  loss: 0.00080809
03/02/2022 21:41:03 - INFO - __main__ - global_steps 50600 - lr: 0.00002553  loss: 0.00083926
03/02/2022 21:41:54 - INFO - __main__ - global_steps 50800 - lr: 0.00002550  loss: 0.00086957
03/02/2022 21:42:49 - INFO - __main__ - global_steps 51000 - lr: 0.00002547  loss: 0.00082148
03/02/2022 21:43:43 - INFO - __main__ - global_steps 51200 - lr: 0.00002544  loss: 0.00082725
03/02/2022 21:44:37 - INFO - __main__ - global_steps 51400 - lr: 0.00002540  loss: 0.00079244
03/02/2022 21:45:32 - INFO - __main__ - global_steps 51600 - lr: 0.00002537  loss: 0.00080525
03/02/2022 21:46:26 - INFO - __main__ - global_steps 51800 - lr: 0.00002534  loss: 0.00082027
03/02/2022 21:47:19 - INFO - __main__ - global_steps 52000 - lr: 0.00002531  loss: 0.00081856
03/02/2022 21:48:12 - INFO - __main__ - global_steps 52200 - lr: 0.00002528  loss: 0.00079039
03/02/2022 21:49:05 - INFO - __main__ - global_steps 52400 - lr: 0.00002525  loss: 0.00079639
03/02/2022 21:49:59 - INFO - __main__ - global_steps 52600 - lr: 0.00002522  loss: 0.00086665
03/02/2022 21:50:54 - INFO - __main__ - global_steps 52800 - lr: 0.00002519  loss: 0.00078004
03/02/2022 21:51:48 - INFO - __main__ - global_steps 53000 - lr: 0.00002516  loss: 0.00085171
03/02/2022 21:52:43 - INFO - __main__ - global_steps 53200 - lr: 0.00002513  loss: 0.00080282
03/02/2022 21:53:37 - INFO - __main__ - global_steps 53400 - lr: 0.00002510  loss: 0.00079972
03/02/2022 21:54:32 - INFO - __main__ - global_steps 53600 - lr: 0.00002506  loss: 0.00083235
03/02/2022 21:55:26 - INFO - __main__ - global_steps 53800 - lr: 0.00002503  loss: 0.00080534
03/02/2022 21:56:20 - INFO - __main__ - global_steps 54000 - lr: 0.00002500  loss: 0.00080495
03/02/2022 21:56:25 - INFO - __main__ - ********** Evaluate Step 54020 **********
03/02/2022 21:56:25 - INFO - __main__ - ##--------------------- Dev
03/02/2022 21:59:43 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 21:59:43 - INFO - __main__ - f1 = 0.8202398259785976
03/02/2022 21:59:43 - INFO - __main__ - precision = 0.8169624387588463
03/02/2022 21:59:43 - INFO - __main__ - recall = 0.8235436147328684
03/02/2022 21:59:43 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 21:59:43 - INFO - __main__ - **--------------------- Dev End
03/02/2022 21:59:44 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-43216-spo-f1-0.8103291548363208
03/02/2022 21:59:44 - INFO - __main__ - *************************************
03/02/2022 22:00:34 - INFO - __main__ - global_steps 54200 - lr: 0.00002497  loss: 0.00071974
03/02/2022 22:01:26 - INFO - __main__ - global_steps 54400 - lr: 0.00002494  loss: 0.00073423
03/02/2022 22:02:20 - INFO - __main__ - global_steps 54600 - lr: 0.00002491  loss: 0.00071542
03/02/2022 22:03:13 - INFO - __main__ - global_steps 54800 - lr: 0.00002488  loss: 0.00073150
03/02/2022 22:04:07 - INFO - __main__ - global_steps 55000 - lr: 0.00002485  loss: 0.00072391
03/02/2022 22:05:01 - INFO - __main__ - global_steps 55200 - lr: 0.00002482  loss: 0.00073795
03/02/2022 22:05:53 - INFO - __main__ - global_steps 55400 - lr: 0.00002479  loss: 0.00074740
03/02/2022 22:06:46 - INFO - __main__ - global_steps 55600 - lr: 0.00002476  loss: 0.00078261
03/02/2022 22:07:38 - INFO - __main__ - global_steps 55800 - lr: 0.00002473  loss: 0.00072366
03/02/2022 22:08:32 - INFO - __main__ - global_steps 56000 - lr: 0.00002469  loss: 0.00074949
03/02/2022 22:09:24 - INFO - __main__ - global_steps 56200 - lr: 0.00002466  loss: 0.00074346
03/02/2022 22:10:19 - INFO - __main__ - global_steps 56400 - lr: 0.00002463  loss: 0.00071123
03/02/2022 22:11:14 - INFO - __main__ - global_steps 56600 - lr: 0.00002460  loss: 0.00069575
03/02/2022 22:12:08 - INFO - __main__ - global_steps 56800 - lr: 0.00002457  loss: 0.00073630
03/02/2022 22:13:01 - INFO - __main__ - global_steps 57000 - lr: 0.00002454  loss: 0.00071906
03/02/2022 22:13:55 - INFO - __main__ - global_steps 57200 - lr: 0.00002451  loss: 0.00075267
03/02/2022 22:14:48 - INFO - __main__ - global_steps 57400 - lr: 0.00002448  loss: 0.00073222
03/02/2022 22:15:44 - INFO - __main__ - global_steps 57600 - lr: 0.00002445  loss: 0.00070567
03/02/2022 22:16:37 - INFO - __main__ - global_steps 57800 - lr: 0.00002442  loss: 0.00072660
03/02/2022 22:17:31 - INFO - __main__ - global_steps 58000 - lr: 0.00002439  loss: 0.00072300
03/02/2022 22:18:24 - INFO - __main__ - global_steps 58200 - lr: 0.00002436  loss: 0.00074833
03/02/2022 22:19:19 - INFO - __main__ - global_steps 58400 - lr: 0.00002432  loss: 0.00075663
03/02/2022 22:20:12 - INFO - __main__ - global_steps 58600 - lr: 0.00002429  loss: 0.00075727
03/02/2022 22:21:05 - INFO - __main__ - global_steps 58800 - lr: 0.00002426  loss: 0.00073447
03/02/2022 22:22:00 - INFO - __main__ - global_steps 59000 - lr: 0.00002423  loss: 0.00075637
03/02/2022 22:22:53 - INFO - __main__ - global_steps 59200 - lr: 0.00002420  loss: 0.00076173
03/02/2022 22:23:45 - INFO - __main__ - global_steps 59400 - lr: 0.00002417  loss: 0.00074980
03/02/2022 22:24:39 - INFO - __main__ - global_steps 59600 - lr: 0.00002414  loss: 0.00068345
03/02/2022 22:25:32 - INFO - __main__ - global_steps 59800 - lr: 0.00002411  loss: 0.00073572
03/02/2022 22:26:24 - INFO - __main__ - global_steps 60000 - lr: 0.00002408  loss: 0.00072764
03/02/2022 22:27:17 - INFO - __main__ - global_steps 60200 - lr: 0.00002405  loss: 0.00073803
03/02/2022 22:28:11 - INFO - __main__ - global_steps 60400 - lr: 0.00002402  loss: 0.00068069
03/02/2022 22:29:04 - INFO - __main__ - global_steps 60600 - lr: 0.00002398  loss: 0.00077910
03/02/2022 22:30:01 - INFO - __main__ - global_steps 60800 - lr: 0.00002395  loss: 0.00070471
03/02/2022 22:30:55 - INFO - __main__ - global_steps 61000 - lr: 0.00002392  loss: 0.00073111
03/02/2022 22:31:49 - INFO - __main__ - global_steps 61200 - lr: 0.00002389  loss: 0.00072367
03/02/2022 22:32:43 - INFO - __main__ - global_steps 61400 - lr: 0.00002386  loss: 0.00073676
03/02/2022 22:33:37 - INFO - __main__ - global_steps 61600 - lr: 0.00002383  loss: 0.00068609
03/02/2022 22:34:30 - INFO - __main__ - global_steps 61800 - lr: 0.00002380  loss: 0.00074549
03/02/2022 22:35:24 - INFO - __main__ - global_steps 62000 - lr: 0.00002377  loss: 0.00073821
03/02/2022 22:36:17 - INFO - __main__ - global_steps 62200 - lr: 0.00002374  loss: 0.00078150
03/02/2022 22:37:11 - INFO - __main__ - global_steps 62400 - lr: 0.00002371  loss: 0.00071841
03/02/2022 22:38:03 - INFO - __main__ - global_steps 62600 - lr: 0.00002368  loss: 0.00076525
03/02/2022 22:38:55 - INFO - __main__ - global_steps 62800 - lr: 0.00002365  loss: 0.00070098
03/02/2022 22:39:49 - INFO - __main__ - global_steps 63000 - lr: 0.00002361  loss: 0.00071338
03/02/2022 22:40:42 - INFO - __main__ - global_steps 63200 - lr: 0.00002358  loss: 0.00075025
03/02/2022 22:41:35 - INFO - __main__ - global_steps 63400 - lr: 0.00002355  loss: 0.00072800
03/02/2022 22:42:29 - INFO - __main__ - global_steps 63600 - lr: 0.00002352  loss: 0.00070245
03/02/2022 22:43:24 - INFO - __main__ - global_steps 63800 - lr: 0.00002349  loss: 0.00069642
03/02/2022 22:44:17 - INFO - __main__ - global_steps 64000 - lr: 0.00002346  loss: 0.00069216
03/02/2022 22:45:11 - INFO - __main__ - global_steps 64200 - lr: 0.00002343  loss: 0.00075114
03/02/2022 22:46:03 - INFO - __main__ - global_steps 64400 - lr: 0.00002340  loss: 0.00071142
03/02/2022 22:46:55 - INFO - __main__ - global_steps 64600 - lr: 0.00002337  loss: 0.00084741
03/02/2022 22:47:48 - INFO - __main__ - global_steps 64800 - lr: 0.00002334  loss: 0.00075973
03/02/2022 22:47:55 - INFO - __main__ - ********** Evaluate Step 64824 **********
03/02/2022 22:47:55 - INFO - __main__ - ##--------------------- Dev
03/02/2022 22:51:07 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 22:51:07 - INFO - __main__ - f1 = 0.8211803640375073
03/02/2022 22:51:07 - INFO - __main__ - precision = 0.8254235784618118
03/02/2022 22:51:07 - INFO - __main__ - recall = 0.8169805522630497
03/02/2022 22:51:07 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 22:51:07 - INFO - __main__ - **--------------------- Dev End
03/02/2022 22:51:08 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-54020-spo-f1-0.8202398259785976
03/02/2022 22:51:08 - INFO - __main__ - *************************************
03/02/2022 22:51:56 - INFO - __main__ - global_steps 65000 - lr: 0.00002331  loss: 0.00059099
03/02/2022 22:52:48 - INFO - __main__ - global_steps 65200 - lr: 0.00002328  loss: 0.00060658
03/02/2022 22:53:40 - INFO - __main__ - global_steps 65400 - lr: 0.00002324  loss: 0.00060966
03/02/2022 22:54:32 - INFO - __main__ - global_steps 65600 - lr: 0.00002321  loss: 0.00062921
03/02/2022 22:55:26 - INFO - __main__ - global_steps 65800 - lr: 0.00002318  loss: 0.00065113
03/02/2022 22:56:17 - INFO - __main__ - global_steps 66000 - lr: 0.00002315  loss: 0.00061053
03/02/2022 22:57:10 - INFO - __main__ - global_steps 66200 - lr: 0.00002312  loss: 0.00065028
03/02/2022 22:58:02 - INFO - __main__ - global_steps 66400 - lr: 0.00002309  loss: 0.00060836
03/02/2022 22:58:54 - INFO - __main__ - global_steps 66600 - lr: 0.00002306  loss: 0.00060405
03/02/2022 22:59:45 - INFO - __main__ - global_steps 66800 - lr: 0.00002303  loss: 0.00062541
03/02/2022 23:00:37 - INFO - __main__ - global_steps 67000 - lr: 0.00002300  loss: 0.00065220
03/02/2022 23:01:30 - INFO - __main__ - global_steps 67200 - lr: 0.00002297  loss: 0.00064659
03/02/2022 23:02:23 - INFO - __main__ - global_steps 67400 - lr: 0.00002294  loss: 0.00064858
03/02/2022 23:03:15 - INFO - __main__ - global_steps 67600 - lr: 0.00002291  loss: 0.00063573
03/02/2022 23:04:09 - INFO - __main__ - global_steps 67800 - lr: 0.00002287  loss: 0.00065387
03/02/2022 23:05:00 - INFO - __main__ - global_steps 68000 - lr: 0.00002284  loss: 0.00062482
03/02/2022 23:05:51 - INFO - __main__ - global_steps 68200 - lr: 0.00002281  loss: 0.00070277
03/02/2022 23:06:42 - INFO - __main__ - global_steps 68400 - lr: 0.00002278  loss: 0.00061694
03/02/2022 23:07:32 - INFO - __main__ - global_steps 68600 - lr: 0.00002275  loss: 0.00067680
03/02/2022 23:08:25 - INFO - __main__ - global_steps 68800 - lr: 0.00002272  loss: 0.00070545
03/02/2022 23:09:16 - INFO - __main__ - global_steps 69000 - lr: 0.00002269  loss: 0.00065248
03/02/2022 23:10:07 - INFO - __main__ - global_steps 69200 - lr: 0.00002266  loss: 0.00064559
03/02/2022 23:11:01 - INFO - __main__ - global_steps 69400 - lr: 0.00002263  loss: 0.00064537
03/02/2022 23:11:53 - INFO - __main__ - global_steps 69600 - lr: 0.00002260  loss: 0.00062782
03/02/2022 23:12:47 - INFO - __main__ - global_steps 69800 - lr: 0.00002257  loss: 0.00062260
03/02/2022 23:13:38 - INFO - __main__ - global_steps 70000 - lr: 0.00002253  loss: 0.00065742
03/02/2022 23:14:33 - INFO - __main__ - global_steps 70200 - lr: 0.00002250  loss: 0.00064798
03/02/2022 23:15:26 - INFO - __main__ - global_steps 70400 - lr: 0.00002247  loss: 0.00064123
03/02/2022 23:16:22 - INFO - __main__ - global_steps 70600 - lr: 0.00002244  loss: 0.00064748
03/02/2022 23:17:14 - INFO - __main__ - global_steps 70800 - lr: 0.00002241  loss: 0.00063609
03/02/2022 23:18:07 - INFO - __main__ - global_steps 71000 - lr: 0.00002238  loss: 0.00071863
03/02/2022 23:19:01 - INFO - __main__ - global_steps 71200 - lr: 0.00002235  loss: 0.00066303
03/02/2022 23:19:55 - INFO - __main__ - global_steps 71400 - lr: 0.00002232  loss: 0.00067805
03/02/2022 23:20:48 - INFO - __main__ - global_steps 71600 - lr: 0.00002229  loss: 0.00067723
03/02/2022 23:21:43 - INFO - __main__ - global_steps 71800 - lr: 0.00002226  loss: 0.00065004
03/02/2022 23:22:38 - INFO - __main__ - global_steps 72000 - lr: 0.00002223  loss: 0.00064665
03/02/2022 23:23:32 - INFO - __main__ - global_steps 72200 - lr: 0.00002220  loss: 0.00067968
03/02/2022 23:24:25 - INFO - __main__ - global_steps 72400 - lr: 0.00002216  loss: 0.00062133
03/02/2022 23:25:19 - INFO - __main__ - global_steps 72600 - lr: 0.00002213  loss: 0.00065279
03/02/2022 23:26:12 - INFO - __main__ - global_steps 72800 - lr: 0.00002210  loss: 0.00069107
03/02/2022 23:27:06 - INFO - __main__ - global_steps 73000 - lr: 0.00002207  loss: 0.00067793
03/02/2022 23:28:00 - INFO - __main__ - global_steps 73200 - lr: 0.00002204  loss: 0.00068493
03/02/2022 23:28:54 - INFO - __main__ - global_steps 73400 - lr: 0.00002201  loss: 0.00065803
03/02/2022 23:29:48 - INFO - __main__ - global_steps 73600 - lr: 0.00002198  loss: 0.00067525
03/02/2022 23:30:42 - INFO - __main__ - global_steps 73800 - lr: 0.00002195  loss: 0.00067860
03/02/2022 23:31:39 - INFO - __main__ - global_steps 74000 - lr: 0.00002192  loss: 0.00066143
03/02/2022 23:32:34 - INFO - __main__ - global_steps 74200 - lr: 0.00002189  loss: 0.00064079
03/02/2022 23:33:27 - INFO - __main__ - global_steps 74400 - lr: 0.00002186  loss: 0.00066972
03/02/2022 23:34:20 - INFO - __main__ - global_steps 74600 - lr: 0.00002183  loss: 0.00067996
03/02/2022 23:35:13 - INFO - __main__ - global_steps 74800 - lr: 0.00002179  loss: 0.00064940
03/02/2022 23:36:08 - INFO - __main__ - global_steps 75000 - lr: 0.00002176  loss: 0.00067615
03/02/2022 23:36:59 - INFO - __main__ - global_steps 75200 - lr: 0.00002173  loss: 0.00068844
03/02/2022 23:37:53 - INFO - __main__ - global_steps 75400 - lr: 0.00002170  loss: 0.00064768
03/02/2022 23:38:47 - INFO - __main__ - global_steps 75600 - lr: 0.00002167  loss: 0.00068249
03/02/2022 23:38:54 - INFO - __main__ - ********** Evaluate Step 75628 **********
03/02/2022 23:38:54 - INFO - __main__ - ##--------------------- Dev
03/02/2022 23:42:12 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 23:42:12 - INFO - __main__ - f1 = 0.8177556305937125
03/02/2022 23:42:12 - INFO - __main__ - precision = 0.8142586668407655
03/02/2022 23:42:12 - INFO - __main__ - recall = 0.8212827604372452
03/02/2022 23:42:12 - INFO - __main__ - --------------------------------------------------------------------------------
03/02/2022 23:42:12 - INFO - __main__ - **--------------------- Dev End
03/02/2022 23:42:13 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-75628-spo-f1-0.8177556305937125
03/02/2022 23:42:13 - INFO - __main__ - *************************************
03/02/2022 23:42:59 - INFO - __main__ - global_steps 75800 - lr: 0.00002164  loss: 0.00058871
03/02/2022 23:43:53 - INFO - __main__ - global_steps 76000 - lr: 0.00002161  loss: 0.00055907
03/02/2022 23:44:47 - INFO - __main__ - global_steps 76200 - lr: 0.00002158  loss: 0.00055935
03/02/2022 23:45:41 - INFO - __main__ - global_steps 76400 - lr: 0.00002155  loss: 0.00056314
03/02/2022 23:46:34 - INFO - __main__ - global_steps 76600 - lr: 0.00002152  loss: 0.00056257
03/02/2022 23:47:29 - INFO - __main__ - global_steps 76800 - lr: 0.00002149  loss: 0.00055508
03/02/2022 23:48:23 - INFO - __main__ - global_steps 77000 - lr: 0.00002146  loss: 0.00051901
03/02/2022 23:49:16 - INFO - __main__ - global_steps 77200 - lr: 0.00002142  loss: 0.00056037
03/02/2022 23:50:11 - INFO - __main__ - global_steps 77400 - lr: 0.00002139  loss: 0.00053785
03/02/2022 23:51:05 - INFO - __main__ - global_steps 77600 - lr: 0.00002136  loss: 0.00054354
03/02/2022 23:51:58 - INFO - __main__ - global_steps 77800 - lr: 0.00002133  loss: 0.00058814
03/02/2022 23:52:51 - INFO - __main__ - global_steps 78000 - lr: 0.00002130  loss: 0.00054577
03/02/2022 23:53:46 - INFO - __main__ - global_steps 78200 - lr: 0.00002127  loss: 0.00055736
03/02/2022 23:54:40 - INFO - __main__ - global_steps 78400 - lr: 0.00002124  loss: 0.00055023
03/02/2022 23:55:34 - INFO - __main__ - global_steps 78600 - lr: 0.00002121  loss: 0.00057375
03/02/2022 23:56:27 - INFO - __main__ - global_steps 78800 - lr: 0.00002118  loss: 0.00054282
03/02/2022 23:57:19 - INFO - __main__ - global_steps 79000 - lr: 0.00002115  loss: 0.00059895
03/02/2022 23:58:12 - INFO - __main__ - global_steps 79200 - lr: 0.00002112  loss: 0.00059254
03/02/2022 23:59:06 - INFO - __main__ - global_steps 79400 - lr: 0.00002108  loss: 0.00064904
03/02/2022 23:59:58 - INFO - __main__ - global_steps 79600 - lr: 0.00002105  loss: 0.00060316
03/03/2022 00:00:52 - INFO - __main__ - global_steps 79800 - lr: 0.00002102  loss: 0.00056338
03/03/2022 00:01:45 - INFO - __main__ - global_steps 80000 - lr: 0.00002099  loss: 0.00059118
03/03/2022 00:02:37 - INFO - __main__ - global_steps 80200 - lr: 0.00002096  loss: 0.00061463
03/03/2022 00:03:30 - INFO - __main__ - global_steps 80400 - lr: 0.00002093  loss: 0.00056521
03/03/2022 00:04:25 - INFO - __main__ - global_steps 80600 - lr: 0.00002090  loss: 0.00054406
03/03/2022 00:05:20 - INFO - __main__ - global_steps 80800 - lr: 0.00002087  loss: 0.00058578
03/03/2022 00:06:12 - INFO - __main__ - global_steps 81000 - lr: 0.00002084  loss: 0.00057600
03/03/2022 00:07:06 - INFO - __main__ - global_steps 81200 - lr: 0.00002081  loss: 0.00055976
03/03/2022 00:08:00 - INFO - __main__ - global_steps 81400 - lr: 0.00002078  loss: 0.00056257
03/03/2022 00:08:53 - INFO - __main__ - global_steps 81600 - lr: 0.00002075  loss: 0.00060178
03/03/2022 00:09:45 - INFO - __main__ - global_steps 81800 - lr: 0.00002071  loss: 0.00060161
03/03/2022 00:10:39 - INFO - __main__ - global_steps 82000 - lr: 0.00002068  loss: 0.00058040
03/03/2022 00:11:35 - INFO - __main__ - global_steps 82200 - lr: 0.00002065  loss: 0.00056455
03/03/2022 00:12:29 - INFO - __main__ - global_steps 82400 - lr: 0.00002062  loss: 0.00059999
03/03/2022 00:13:22 - INFO - __main__ - global_steps 82600 - lr: 0.00002059  loss: 0.00057332
03/03/2022 00:14:16 - INFO - __main__ - global_steps 82800 - lr: 0.00002056  loss: 0.00058064
03/03/2022 00:15:10 - INFO - __main__ - global_steps 83000 - lr: 0.00002053  loss: 0.00058490
03/03/2022 00:16:02 - INFO - __main__ - global_steps 83200 - lr: 0.00002050  loss: 0.00063705
03/03/2022 00:16:56 - INFO - __main__ - global_steps 83400 - lr: 0.00002047  loss: 0.00064218
03/03/2022 00:17:49 - INFO - __main__ - global_steps 83600 - lr: 0.00002044  loss: 0.00060506
03/03/2022 00:18:41 - INFO - __main__ - global_steps 83800 - lr: 0.00002041  loss: 0.00060745
03/03/2022 00:19:35 - INFO - __main__ - global_steps 84000 - lr: 0.00002038  loss: 0.00061772
03/03/2022 00:20:29 - INFO - __main__ - global_steps 84200 - lr: 0.00002034  loss: 0.00055645
03/03/2022 00:21:22 - INFO - __main__ - global_steps 84400 - lr: 0.00002031  loss: 0.00058667
03/03/2022 00:22:16 - INFO - __main__ - global_steps 84600 - lr: 0.00002028  loss: 0.00056177
03/03/2022 00:23:10 - INFO - __main__ - global_steps 84800 - lr: 0.00002025  loss: 0.00059232
03/03/2022 00:24:04 - INFO - __main__ - global_steps 85000 - lr: 0.00002022  loss: 0.00057911
03/03/2022 00:24:55 - INFO - __main__ - global_steps 85200 - lr: 0.00002019  loss: 0.00063470
03/03/2022 00:25:48 - INFO - __main__ - global_steps 85400 - lr: 0.00002016  loss: 0.00061571
03/03/2022 00:26:42 - INFO - __main__ - global_steps 85600 - lr: 0.00002013  loss: 0.00060091
03/03/2022 00:27:34 - INFO - __main__ - global_steps 85800 - lr: 0.00002010  loss: 0.00060798
03/03/2022 00:28:26 - INFO - __main__ - global_steps 86000 - lr: 0.00002007  loss: 0.00055805
03/03/2022 00:29:19 - INFO - __main__ - global_steps 86200 - lr: 0.00002004  loss: 0.00061720
03/03/2022 00:30:15 - INFO - __main__ - global_steps 86400 - lr: 0.00002000  loss: 0.00055896
03/03/2022 00:30:23 - INFO - __main__ - ********** Evaluate Step 86432 **********
03/03/2022 00:30:23 - INFO - __main__ - ##--------------------- Dev
03/03/2022 00:33:42 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 00:33:42 - INFO - __main__ - f1 = 0.8198085818053367
03/03/2022 00:33:42 - INFO - __main__ - precision = 0.8246241311155037
03/03/2022 00:33:42 - INFO - __main__ - recall = 0.8150489485930027
03/03/2022 00:33:42 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 00:33:42 - INFO - __main__ - **--------------------- Dev End
03/03/2022 00:33:42 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-86432-spo-f1-0.8198085818053367
03/03/2022 00:33:42 - INFO - __main__ - *************************************
03/03/2022 00:34:27 - INFO - __main__ - global_steps 86600 - lr: 0.00001997  loss: 0.00050093
03/03/2022 00:35:21 - INFO - __main__ - global_steps 86800 - lr: 0.00001994  loss: 0.00049230
03/03/2022 00:36:14 - INFO - __main__ - global_steps 87000 - lr: 0.00001991  loss: 0.00048614
03/03/2022 00:37:08 - INFO - __main__ - global_steps 87200 - lr: 0.00001988  loss: 0.00046667
03/03/2022 00:38:02 - INFO - __main__ - global_steps 87400 - lr: 0.00001985  loss: 0.00051945
03/03/2022 00:38:57 - INFO - __main__ - global_steps 87600 - lr: 0.00001982  loss: 0.00050199
03/03/2022 00:39:52 - INFO - __main__ - global_steps 87800 - lr: 0.00001979  loss: 0.00049655
03/03/2022 00:40:45 - INFO - __main__ - global_steps 88000 - lr: 0.00001976  loss: 0.00050143
03/03/2022 00:41:39 - INFO - __main__ - global_steps 88200 - lr: 0.00001973  loss: 0.00048295
03/03/2022 00:42:33 - INFO - __main__ - global_steps 88400 - lr: 0.00001970  loss: 0.00051637
03/03/2022 00:43:27 - INFO - __main__ - global_steps 88600 - lr: 0.00001967  loss: 0.00050339
03/03/2022 00:44:20 - INFO - __main__ - global_steps 88800 - lr: 0.00001963  loss: 0.00048976
03/03/2022 00:45:12 - INFO - __main__ - global_steps 89000 - lr: 0.00001960  loss: 0.00055156
03/03/2022 00:46:05 - INFO - __main__ - global_steps 89200 - lr: 0.00001957  loss: 0.00051695
03/03/2022 00:47:00 - INFO - __main__ - global_steps 89400 - lr: 0.00001954  loss: 0.00051577
03/03/2022 00:47:53 - INFO - __main__ - global_steps 89600 - lr: 0.00001951  loss: 0.00047947
03/03/2022 00:48:45 - INFO - __main__ - global_steps 89800 - lr: 0.00001948  loss: 0.00050241
03/03/2022 00:49:39 - INFO - __main__ - global_steps 90000 - lr: 0.00001945  loss: 0.00052037
03/03/2022 00:50:32 - INFO - __main__ - global_steps 90200 - lr: 0.00001942  loss: 0.00050604
03/03/2022 00:51:26 - INFO - __main__ - global_steps 90400 - lr: 0.00001939  loss: 0.00056095
03/03/2022 00:52:18 - INFO - __main__ - global_steps 90600 - lr: 0.00001936  loss: 0.00047400
03/03/2022 00:53:12 - INFO - __main__ - global_steps 90800 - lr: 0.00001933  loss: 0.00051675
03/03/2022 00:54:04 - INFO - __main__ - global_steps 91000 - lr: 0.00001930  loss: 0.00053590
03/03/2022 00:54:57 - INFO - __main__ - global_steps 91200 - lr: 0.00001926  loss: 0.00051958
03/03/2022 00:55:50 - INFO - __main__ - global_steps 91400 - lr: 0.00001923  loss: 0.00052690
03/03/2022 00:56:45 - INFO - __main__ - global_steps 91600 - lr: 0.00001920  loss: 0.00050986
03/03/2022 00:57:38 - INFO - __main__ - global_steps 91800 - lr: 0.00001917  loss: 0.00050220
03/03/2022 00:58:31 - INFO - __main__ - global_steps 92000 - lr: 0.00001914  loss: 0.00057855
03/03/2022 00:59:25 - INFO - __main__ - global_steps 92200 - lr: 0.00001911  loss: 0.00050571
03/03/2022 01:00:20 - INFO - __main__ - global_steps 92400 - lr: 0.00001908  loss: 0.00052326
03/03/2022 01:01:12 - INFO - __main__ - global_steps 92600 - lr: 0.00001905  loss: 0.00055886
03/03/2022 01:02:05 - INFO - __main__ - global_steps 92800 - lr: 0.00001902  loss: 0.00055243
03/03/2022 01:02:58 - INFO - __main__ - global_steps 93000 - lr: 0.00001899  loss: 0.00054064
03/03/2022 01:03:51 - INFO - __main__ - global_steps 93200 - lr: 0.00001896  loss: 0.00049585
03/03/2022 01:04:45 - INFO - __main__ - global_steps 93400 - lr: 0.00001893  loss: 0.00051963
03/03/2022 01:05:37 - INFO - __main__ - global_steps 93600 - lr: 0.00001889  loss: 0.00051308
03/03/2022 01:06:30 - INFO - __main__ - global_steps 93800 - lr: 0.00001886  loss: 0.00054852
03/03/2022 01:07:23 - INFO - __main__ - global_steps 94000 - lr: 0.00001883  loss: 0.00050502
03/03/2022 01:08:16 - INFO - __main__ - global_steps 94200 - lr: 0.00001880  loss: 0.00051338
03/03/2022 01:09:11 - INFO - __main__ - global_steps 94400 - lr: 0.00001877  loss: 0.00053892
03/03/2022 01:10:05 - INFO - __main__ - global_steps 94600 - lr: 0.00001874  loss: 0.00053062
03/03/2022 01:10:57 - INFO - __main__ - global_steps 94800 - lr: 0.00001871  loss: 0.00052951
03/03/2022 01:11:50 - INFO - __main__ - global_steps 95000 - lr: 0.00001868  loss: 0.00052962
03/03/2022 01:12:43 - INFO - __main__ - global_steps 95200 - lr: 0.00001865  loss: 0.00049078
03/03/2022 01:13:36 - INFO - __main__ - global_steps 95400 - lr: 0.00001862  loss: 0.00052788
03/03/2022 01:14:28 - INFO - __main__ - global_steps 95600 - lr: 0.00001859  loss: 0.00050295
03/03/2022 01:15:22 - INFO - __main__ - global_steps 95800 - lr: 0.00001855  loss: 0.00048376
03/03/2022 01:16:16 - INFO - __main__ - global_steps 96000 - lr: 0.00001852  loss: 0.00053611
03/03/2022 01:17:09 - INFO - __main__ - global_steps 96200 - lr: 0.00001849  loss: 0.00053569
03/03/2022 01:18:03 - INFO - __main__ - global_steps 96400 - lr: 0.00001846  loss: 0.00052612
03/03/2022 01:18:57 - INFO - __main__ - global_steps 96600 - lr: 0.00001843  loss: 0.00052953
03/03/2022 01:19:50 - INFO - __main__ - global_steps 96800 - lr: 0.00001840  loss: 0.00050712
03/03/2022 01:20:45 - INFO - __main__ - global_steps 97000 - lr: 0.00001837  loss: 0.00051866
03/03/2022 01:21:37 - INFO - __main__ - global_steps 97200 - lr: 0.00001834  loss: 0.00052376
03/03/2022 01:21:47 - INFO - __main__ - ********** Evaluate Step 97236 **********
03/03/2022 01:21:47 - INFO - __main__ - ##--------------------- Dev
03/03/2022 01:25:05 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 01:25:05 - INFO - __main__ - f1 = 0.8198242887220701
03/03/2022 01:25:05 - INFO - __main__ - precision = 0.823446046192343
03/03/2022 01:25:05 - INFO - __main__ - recall = 0.8162342508450771
03/03/2022 01:25:05 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 01:25:05 - INFO - __main__ - **--------------------- Dev End
03/03/2022 01:25:06 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-97236-spo-f1-0.8198242887220701
03/03/2022 01:25:06 - INFO - __main__ - *************************************
03/03/2022 01:25:51 - INFO - __main__ - global_steps 97400 - lr: 0.00001831  loss: 0.00041986
03/03/2022 01:26:44 - INFO - __main__ - global_steps 97600 - lr: 0.00001828  loss: 0.00043352
03/03/2022 01:27:38 - INFO - __main__ - global_steps 97800 - lr: 0.00001825  loss: 0.00042619
03/03/2022 01:28:30 - INFO - __main__ - global_steps 98000 - lr: 0.00001822  loss: 0.00043279
03/03/2022 01:29:24 - INFO - __main__ - global_steps 98200 - lr: 0.00001818  loss: 0.00041383
03/03/2022 01:30:17 - INFO - __main__ - global_steps 98400 - lr: 0.00001815  loss: 0.00043504
03/03/2022 01:31:09 - INFO - __main__ - global_steps 98600 - lr: 0.00001812  loss: 0.00046592
03/03/2022 01:32:02 - INFO - __main__ - global_steps 98800 - lr: 0.00001809  loss: 0.00044105
03/03/2022 01:32:55 - INFO - __main__ - global_steps 99000 - lr: 0.00001806  loss: 0.00044403
03/03/2022 01:33:47 - INFO - __main__ - global_steps 99200 - lr: 0.00001803  loss: 0.00041961
03/03/2022 01:34:40 - INFO - __main__ - global_steps 99400 - lr: 0.00001800  loss: 0.00046356
03/03/2022 01:35:33 - INFO - __main__ - global_steps 99600 - lr: 0.00001797  loss: 0.00044318
03/03/2022 01:36:26 - INFO - __main__ - global_steps 99800 - lr: 0.00001794  loss: 0.00045847
03/03/2022 01:37:18 - INFO - __main__ - global_steps 100000 - lr: 0.00001791  loss: 0.00039565
03/03/2022 01:38:11 - INFO - __main__ - global_steps 100200 - lr: 0.00001788  loss: 0.00045137
03/03/2022 01:39:05 - INFO - __main__ - global_steps 100400 - lr: 0.00001785  loss: 0.00045419
03/03/2022 01:39:59 - INFO - __main__ - global_steps 100600 - lr: 0.00001781  loss: 0.00041882
03/03/2022 01:40:53 - INFO - __main__ - global_steps 100800 - lr: 0.00001778  loss: 0.00044398
03/03/2022 01:41:47 - INFO - __main__ - global_steps 101000 - lr: 0.00001775  loss: 0.00044043
03/03/2022 01:42:39 - INFO - __main__ - global_steps 101200 - lr: 0.00001772  loss: 0.00043145
03/03/2022 01:43:31 - INFO - __main__ - global_steps 101400 - lr: 0.00001769  loss: 0.00044132
03/03/2022 01:44:24 - INFO - __main__ - global_steps 101600 - lr: 0.00001766  loss: 0.00043693
03/03/2022 01:45:18 - INFO - __main__ - global_steps 101800 - lr: 0.00001763  loss: 0.00042369
03/03/2022 01:46:12 - INFO - __main__ - global_steps 102000 - lr: 0.00001760  loss: 0.00044266
03/03/2022 01:47:05 - INFO - __main__ - global_steps 102200 - lr: 0.00001757  loss: 0.00045260
03/03/2022 01:47:58 - INFO - __main__ - global_steps 102400 - lr: 0.00001754  loss: 0.00047311
03/03/2022 01:48:52 - INFO - __main__ - global_steps 102600 - lr: 0.00001751  loss: 0.00048803
03/03/2022 01:49:47 - INFO - __main__ - global_steps 102800 - lr: 0.00001748  loss: 0.00045552
03/03/2022 01:50:40 - INFO - __main__ - global_steps 103000 - lr: 0.00001744  loss: 0.00049739
03/03/2022 01:51:32 - INFO - __main__ - global_steps 103200 - lr: 0.00001741  loss: 0.00049041
03/03/2022 01:52:27 - INFO - __main__ - global_steps 103400 - lr: 0.00001738  loss: 0.00046165
03/03/2022 01:53:20 - INFO - __main__ - global_steps 103600 - lr: 0.00001735  loss: 0.00045837
03/03/2022 01:54:13 - INFO - __main__ - global_steps 103800 - lr: 0.00001732  loss: 0.00045261
03/03/2022 01:55:06 - INFO - __main__ - global_steps 104000 - lr: 0.00001729  loss: 0.00046193
03/03/2022 01:56:01 - INFO - __main__ - global_steps 104200 - lr: 0.00001726  loss: 0.00043953
03/03/2022 01:56:52 - INFO - __main__ - global_steps 104400 - lr: 0.00001723  loss: 0.00049465
03/03/2022 01:57:45 - INFO - __main__ - global_steps 104600 - lr: 0.00001720  loss: 0.00046847
03/03/2022 01:58:39 - INFO - __main__ - global_steps 104800 - lr: 0.00001717  loss: 0.00048704
03/03/2022 01:59:32 - INFO - __main__ - global_steps 105000 - lr: 0.00001714  loss: 0.00051617
03/03/2022 02:00:25 - INFO - __main__ - global_steps 105200 - lr: 0.00001710  loss: 0.00045206
03/03/2022 02:01:21 - INFO - __main__ - global_steps 105400 - lr: 0.00001707  loss: 0.00042787
03/03/2022 02:02:12 - INFO - __main__ - global_steps 105600 - lr: 0.00001704  loss: 0.00047498
03/03/2022 02:03:03 - INFO - __main__ - global_steps 105800 - lr: 0.00001701  loss: 0.00047658
03/03/2022 02:03:57 - INFO - __main__ - global_steps 106000 - lr: 0.00001698  loss: 0.00046071
03/03/2022 02:04:53 - INFO - __main__ - global_steps 106200 - lr: 0.00001695  loss: 0.00042071
03/03/2022 02:05:46 - INFO - __main__ - global_steps 106400 - lr: 0.00001692  loss: 0.00046682
03/03/2022 02:06:41 - INFO - __main__ - global_steps 106600 - lr: 0.00001689  loss: 0.00044030
03/03/2022 02:07:35 - INFO - __main__ - global_steps 106800 - lr: 0.00001686  loss: 0.00045515
03/03/2022 02:08:27 - INFO - __main__ - global_steps 107000 - lr: 0.00001683  loss: 0.00046462
03/03/2022 02:09:22 - INFO - __main__ - global_steps 107200 - lr: 0.00001680  loss: 0.00041084
03/03/2022 02:10:15 - INFO - __main__ - global_steps 107400 - lr: 0.00001677  loss: 0.00043782
03/03/2022 02:11:07 - INFO - __main__ - global_steps 107600 - lr: 0.00001673  loss: 0.00044401
03/03/2022 02:11:59 - INFO - __main__ - global_steps 107800 - lr: 0.00001670  loss: 0.00048719
03/03/2022 02:12:52 - INFO - __main__ - global_steps 108000 - lr: 0.00001667  loss: 0.00046482
03/03/2022 02:13:03 - INFO - __main__ - ********** Evaluate Step 108040 **********
03/03/2022 02:13:03 - INFO - __main__ - ##--------------------- Dev
03/03/2022 02:16:23 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 02:16:23 - INFO - __main__ - f1 = 0.8206018139550117
03/03/2022 02:16:23 - INFO - __main__ - precision = 0.8160859654835563
03/03/2022 02:16:23 - INFO - __main__ - recall = 0.8251679178190442
03/03/2022 02:16:23 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 02:16:23 - INFO - __main__ - **--------------------- Dev End
03/03/2022 02:16:23 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-108040-spo-f1-0.8206018139550117
03/03/2022 02:16:23 - INFO - __main__ - *************************************
03/03/2022 02:17:08 - INFO - __main__ - global_steps 108200 - lr: 0.00001664  loss: 0.00038985
03/03/2022 02:18:02 - INFO - __main__ - global_steps 108400 - lr: 0.00001661  loss: 0.00034167
03/03/2022 02:18:55 - INFO - __main__ - global_steps 108600 - lr: 0.00001658  loss: 0.00036358
03/03/2022 02:19:49 - INFO - __main__ - global_steps 108800 - lr: 0.00001655  loss: 0.00036126
03/03/2022 02:20:43 - INFO - __main__ - global_steps 109000 - lr: 0.00001652  loss: 0.00037315
03/03/2022 02:21:36 - INFO - __main__ - global_steps 109200 - lr: 0.00001649  loss: 0.00039172
03/03/2022 02:22:30 - INFO - __main__ - global_steps 109400 - lr: 0.00001646  loss: 0.00035106
03/03/2022 02:23:22 - INFO - __main__ - global_steps 109600 - lr: 0.00001643  loss: 0.00038765
03/03/2022 02:24:15 - INFO - __main__ - global_steps 109800 - lr: 0.00001640  loss: 0.00036929
03/03/2022 02:25:10 - INFO - __main__ - global_steps 110000 - lr: 0.00001636  loss: 0.00038670
03/03/2022 02:26:02 - INFO - __main__ - global_steps 110200 - lr: 0.00001633  loss: 0.00038339
03/03/2022 02:26:55 - INFO - __main__ - global_steps 110400 - lr: 0.00001630  loss: 0.00038303
03/03/2022 02:27:48 - INFO - __main__ - global_steps 110600 - lr: 0.00001627  loss: 0.00036037
03/03/2022 02:28:41 - INFO - __main__ - global_steps 110800 - lr: 0.00001624  loss: 0.00039932
03/03/2022 02:29:34 - INFO - __main__ - global_steps 111000 - lr: 0.00001621  loss: 0.00038620
03/03/2022 02:30:26 - INFO - __main__ - global_steps 111200 - lr: 0.00001618  loss: 0.00042195
03/03/2022 02:31:18 - INFO - __main__ - global_steps 111400 - lr: 0.00001615  loss: 0.00044496
03/03/2022 02:32:10 - INFO - __main__ - global_steps 111600 - lr: 0.00001612  loss: 0.00043603
03/03/2022 02:33:04 - INFO - __main__ - global_steps 111800 - lr: 0.00001609  loss: 0.00039690
03/03/2022 02:33:58 - INFO - __main__ - global_steps 112000 - lr: 0.00001606  loss: 0.00041038
03/03/2022 02:34:51 - INFO - __main__ - global_steps 112200 - lr: 0.00001602  loss: 0.00036791
03/03/2022 02:35:46 - INFO - __main__ - global_steps 112400 - lr: 0.00001599  loss: 0.00040791
03/03/2022 02:36:41 - INFO - __main__ - global_steps 112600 - lr: 0.00001596  loss: 0.00040757
03/03/2022 02:37:34 - INFO - __main__ - global_steps 112800 - lr: 0.00001593  loss: 0.00040352
03/03/2022 02:38:30 - INFO - __main__ - global_steps 113000 - lr: 0.00001590  loss: 0.00038031
03/03/2022 02:39:24 - INFO - __main__ - global_steps 113200 - lr: 0.00001587  loss: 0.00038070
03/03/2022 02:40:19 - INFO - __main__ - global_steps 113400 - lr: 0.00001584  loss: 0.00040914
03/03/2022 02:41:13 - INFO - __main__ - global_steps 113600 - lr: 0.00001581  loss: 0.00037936
03/03/2022 02:42:07 - INFO - __main__ - global_steps 113800 - lr: 0.00001578  loss: 0.00042270
03/03/2022 02:43:00 - INFO - __main__ - global_steps 114000 - lr: 0.00001575  loss: 0.00038649
03/03/2022 02:43:56 - INFO - __main__ - global_steps 114200 - lr: 0.00001572  loss: 0.00036331
03/03/2022 02:44:49 - INFO - __main__ - global_steps 114400 - lr: 0.00001569  loss: 0.00036161
03/03/2022 02:45:42 - INFO - __main__ - global_steps 114600 - lr: 0.00001565  loss: 0.00039742
03/03/2022 02:46:35 - INFO - __main__ - global_steps 114800 - lr: 0.00001562  loss: 0.00042460
03/03/2022 02:47:31 - INFO - __main__ - global_steps 115000 - lr: 0.00001559  loss: 0.00037792
03/03/2022 02:48:23 - INFO - __main__ - global_steps 115200 - lr: 0.00001556  loss: 0.00040861
03/03/2022 02:49:15 - INFO - __main__ - global_steps 115400 - lr: 0.00001553  loss: 0.00041522
03/03/2022 02:50:08 - INFO - __main__ - global_steps 115600 - lr: 0.00001550  loss: 0.00040118
03/03/2022 02:51:02 - INFO - __main__ - global_steps 115800 - lr: 0.00001547  loss: 0.00038244
03/03/2022 02:51:55 - INFO - __main__ - global_steps 116000 - lr: 0.00001544  loss: 0.00038221
03/03/2022 02:52:48 - INFO - __main__ - global_steps 116200 - lr: 0.00001541  loss: 0.00040102
03/03/2022 02:53:41 - INFO - __main__ - global_steps 116400 - lr: 0.00001538  loss: 0.00039359
03/03/2022 02:54:33 - INFO - __main__ - global_steps 116600 - lr: 0.00001535  loss: 0.00041853
03/03/2022 02:55:26 - INFO - __main__ - global_steps 116800 - lr: 0.00001532  loss: 0.00039900
03/03/2022 02:56:20 - INFO - __main__ - global_steps 117000 - lr: 0.00001528  loss: 0.00043272
03/03/2022 02:57:15 - INFO - __main__ - global_steps 117200 - lr: 0.00001525  loss: 0.00035683
03/03/2022 02:58:09 - INFO - __main__ - global_steps 117400 - lr: 0.00001522  loss: 0.00038711
03/03/2022 02:59:03 - INFO - __main__ - global_steps 117600 - lr: 0.00001519  loss: 0.00038842
03/03/2022 02:59:56 - INFO - __main__ - global_steps 117800 - lr: 0.00001516  loss: 0.00042089
03/03/2022 03:00:49 - INFO - __main__ - global_steps 118000 - lr: 0.00001513  loss: 0.00040581
03/03/2022 03:01:43 - INFO - __main__ - global_steps 118200 - lr: 0.00001510  loss: 0.00039849
03/03/2022 03:02:37 - INFO - __main__ - global_steps 118400 - lr: 0.00001507  loss: 0.00042319
03/03/2022 03:03:31 - INFO - __main__ - global_steps 118600 - lr: 0.00001504  loss: 0.00039256
03/03/2022 03:04:26 - INFO - __main__ - global_steps 118800 - lr: 0.00001501  loss: 0.00041705
03/03/2022 03:04:37 - INFO - __main__ - ********** Evaluate Step 118844 **********
03/03/2022 03:04:37 - INFO - __main__ - ##--------------------- Dev
03/03/2022 03:07:57 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 03:07:57 - INFO - __main__ - f1 = 0.8216261688290682
03/03/2022 03:07:57 - INFO - __main__ - precision = 0.8076458240569943
03/03/2022 03:07:57 - INFO - __main__ - recall = 0.8360990385881737
03/03/2022 03:07:57 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 03:07:57 - INFO - __main__ - **--------------------- Dev End
03/03/2022 03:07:58 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-64824-spo-f1-0.8211803640375073
03/03/2022 03:07:58 - INFO - __main__ - *************************************
03/03/2022 03:08:42 - INFO - __main__ - global_steps 119000 - lr: 0.00001498  loss: 0.00035077
03/03/2022 03:09:35 - INFO - __main__ - global_steps 119200 - lr: 0.00001495  loss: 0.00033267
03/03/2022 03:10:28 - INFO - __main__ - global_steps 119400 - lr: 0.00001491  loss: 0.00032334
03/03/2022 03:11:23 - INFO - __main__ - global_steps 119600 - lr: 0.00001488  loss: 0.00029579
03/03/2022 03:12:17 - INFO - __main__ - global_steps 119800 - lr: 0.00001485  loss: 0.00033041
03/03/2022 03:13:11 - INFO - __main__ - global_steps 120000 - lr: 0.00001482  loss: 0.00032098
03/03/2022 03:14:04 - INFO - __main__ - global_steps 120200 - lr: 0.00001479  loss: 0.00034517
03/03/2022 03:14:59 - INFO - __main__ - global_steps 120400 - lr: 0.00001476  loss: 0.00031644
03/03/2022 03:15:55 - INFO - __main__ - global_steps 120600 - lr: 0.00001473  loss: 0.00031294
03/03/2022 03:16:48 - INFO - __main__ - global_steps 120800 - lr: 0.00001470  loss: 0.00032650
03/03/2022 03:17:40 - INFO - __main__ - global_steps 121000 - lr: 0.00001467  loss: 0.00034690
03/03/2022 03:18:34 - INFO - __main__ - global_steps 121200 - lr: 0.00001464  loss: 0.00034100
03/03/2022 03:19:29 - INFO - __main__ - global_steps 121400 - lr: 0.00001461  loss: 0.00035549
03/03/2022 03:20:22 - INFO - __main__ - global_steps 121600 - lr: 0.00001457  loss: 0.00033748
03/03/2022 03:21:14 - INFO - __main__ - global_steps 121800 - lr: 0.00001454  loss: 0.00032366
03/03/2022 03:22:09 - INFO - __main__ - global_steps 122000 - lr: 0.00001451  loss: 0.00033442
03/03/2022 03:23:03 - INFO - __main__ - global_steps 122200 - lr: 0.00001448  loss: 0.00031567
03/03/2022 03:23:56 - INFO - __main__ - global_steps 122400 - lr: 0.00001445  loss: 0.00034016
03/03/2022 03:24:49 - INFO - __main__ - global_steps 122600 - lr: 0.00001442  loss: 0.00033415
03/03/2022 03:25:42 - INFO - __main__ - global_steps 122800 - lr: 0.00001439  loss: 0.00031309
03/03/2022 03:26:36 - INFO - __main__ - global_steps 123000 - lr: 0.00001436  loss: 0.00031803
03/03/2022 03:27:29 - INFO - __main__ - global_steps 123200 - lr: 0.00001433  loss: 0.00035627
03/03/2022 03:28:24 - INFO - __main__ - global_steps 123400 - lr: 0.00001430  loss: 0.00030522
03/03/2022 03:29:17 - INFO - __main__ - global_steps 123600 - lr: 0.00001427  loss: 0.00034584
03/03/2022 03:30:11 - INFO - __main__ - global_steps 123800 - lr: 0.00001424  loss: 0.00033563
03/03/2022 03:31:03 - INFO - __main__ - global_steps 124000 - lr: 0.00001420  loss: 0.00037637
03/03/2022 03:31:56 - INFO - __main__ - global_steps 124200 - lr: 0.00001417  loss: 0.00033379
03/03/2022 03:32:49 - INFO - __main__ - global_steps 124400 - lr: 0.00001414  loss: 0.00036331
03/03/2022 03:33:43 - INFO - __main__ - global_steps 124600 - lr: 0.00001411  loss: 0.00036218
03/03/2022 03:34:37 - INFO - __main__ - global_steps 124800 - lr: 0.00001408  loss: 0.00033825
03/03/2022 03:35:29 - INFO - __main__ - global_steps 125000 - lr: 0.00001405  loss: 0.00036730
03/03/2022 03:36:23 - INFO - __main__ - global_steps 125200 - lr: 0.00001402  loss: 0.00034572
03/03/2022 03:37:16 - INFO - __main__ - global_steps 125400 - lr: 0.00001399  loss: 0.00033459
03/03/2022 03:38:09 - INFO - __main__ - global_steps 125600 - lr: 0.00001396  loss: 0.00038001
03/03/2022 03:39:03 - INFO - __main__ - global_steps 125800 - lr: 0.00001393  loss: 0.00037751
03/03/2022 03:39:55 - INFO - __main__ - global_steps 126000 - lr: 0.00001390  loss: 0.00035007
03/03/2022 03:40:50 - INFO - __main__ - global_steps 126200 - lr: 0.00001387  loss: 0.00032491
03/03/2022 03:41:43 - INFO - __main__ - global_steps 126400 - lr: 0.00001383  loss: 0.00038408
03/03/2022 03:42:37 - INFO - __main__ - global_steps 126600 - lr: 0.00001380  loss: 0.00033652
03/03/2022 03:43:29 - INFO - __main__ - global_steps 126800 - lr: 0.00001377  loss: 0.00035181
03/03/2022 03:44:21 - INFO - __main__ - global_steps 127000 - lr: 0.00001374  loss: 0.00034636
03/03/2022 03:45:12 - INFO - __main__ - global_steps 127200 - lr: 0.00001371  loss: 0.00037425
03/03/2022 03:46:06 - INFO - __main__ - global_steps 127400 - lr: 0.00001368  loss: 0.00032267
03/03/2022 03:47:03 - INFO - __main__ - global_steps 127600 - lr: 0.00001365  loss: 0.00035051
03/03/2022 03:47:55 - INFO - __main__ - global_steps 127800 - lr: 0.00001362  loss: 0.00034687
03/03/2022 03:48:51 - INFO - __main__ - global_steps 128000 - lr: 0.00001359  loss: 0.00033241
03/03/2022 03:49:45 - INFO - __main__ - global_steps 128200 - lr: 0.00001356  loss: 0.00034311
03/03/2022 03:50:39 - INFO - __main__ - global_steps 128400 - lr: 0.00001353  loss: 0.00036161
03/03/2022 03:51:32 - INFO - __main__ - global_steps 128600 - lr: 0.00001350  loss: 0.00034781
03/03/2022 03:52:26 - INFO - __main__ - global_steps 128800 - lr: 0.00001346  loss: 0.00037161
03/03/2022 03:53:21 - INFO - __main__ - global_steps 129000 - lr: 0.00001343  loss: 0.00034477
03/03/2022 03:54:15 - INFO - __main__ - global_steps 129200 - lr: 0.00001340  loss: 0.00035202
03/03/2022 03:55:10 - INFO - __main__ - global_steps 129400 - lr: 0.00001337  loss: 0.00034741
03/03/2022 03:56:03 - INFO - __main__ - global_steps 129600 - lr: 0.00001334  loss: 0.00036050
03/03/2022 03:56:15 - INFO - __main__ - ********** Evaluate Step 129648 **********
03/03/2022 03:56:15 - INFO - __main__ - ##--------------------- Dev
03/03/2022 03:59:34 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 03:59:34 - INFO - __main__ - f1 = 0.8201602389097518
03/03/2022 03:59:34 - INFO - __main__ - precision = 0.8329221646334567
03/03/2022 03:59:34 - INFO - __main__ - recall = 0.8077834847886215
03/03/2022 03:59:34 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 03:59:34 - INFO - __main__ - **--------------------- Dev End
03/03/2022 03:59:34 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-129648-spo-f1-0.8201602389097518
03/03/2022 03:59:34 - INFO - __main__ - *************************************
03/03/2022 04:00:15 - INFO - __main__ - global_steps 129800 - lr: 0.00001331  loss: 0.00030042
03/03/2022 04:01:08 - INFO - __main__ - global_steps 130000 - lr: 0.00001328  loss: 0.00027280
03/03/2022 04:02:00 - INFO - __main__ - global_steps 130200 - lr: 0.00001325  loss: 0.00026677
03/03/2022 04:02:51 - INFO - __main__ - global_steps 130400 - lr: 0.00001322  loss: 0.00028020
03/03/2022 04:03:44 - INFO - __main__ - global_steps 130600 - lr: 0.00001319  loss: 0.00028366
03/03/2022 04:04:39 - INFO - __main__ - global_steps 130800 - lr: 0.00001316  loss: 0.00027865
03/03/2022 04:05:33 - INFO - __main__ - global_steps 131000 - lr: 0.00001312  loss: 0.00029620
03/03/2022 04:06:28 - INFO - __main__ - global_steps 131200 - lr: 0.00001309  loss: 0.00026826
03/03/2022 04:07:21 - INFO - __main__ - global_steps 131400 - lr: 0.00001306  loss: 0.00026314
03/03/2022 04:08:14 - INFO - __main__ - global_steps 131600 - lr: 0.00001303  loss: 0.00028149
03/03/2022 04:09:08 - INFO - __main__ - global_steps 131800 - lr: 0.00001300  loss: 0.00028875
03/03/2022 04:09:59 - INFO - __main__ - global_steps 132000 - lr: 0.00001297  loss: 0.00027425
03/03/2022 04:10:51 - INFO - __main__ - global_steps 132200 - lr: 0.00001294  loss: 0.00028510
03/03/2022 04:11:48 - INFO - __main__ - global_steps 132400 - lr: 0.00001291  loss: 0.00026974
03/03/2022 04:12:41 - INFO - __main__ - global_steps 132600 - lr: 0.00001288  loss: 0.00026089
03/03/2022 04:13:34 - INFO - __main__ - global_steps 132800 - lr: 0.00001285  loss: 0.00029326
03/03/2022 04:14:26 - INFO - __main__ - global_steps 133000 - lr: 0.00001282  loss: 0.00031257
03/03/2022 04:15:20 - INFO - __main__ - global_steps 133200 - lr: 0.00001279  loss: 0.00028588
03/03/2022 04:16:15 - INFO - __main__ - global_steps 133400 - lr: 0.00001275  loss: 0.00028653
03/03/2022 04:17:07 - INFO - __main__ - global_steps 133600 - lr: 0.00001272  loss: 0.00029154
03/03/2022 04:18:00 - INFO - __main__ - global_steps 133800 - lr: 0.00001269  loss: 0.00029244
03/03/2022 04:18:53 - INFO - __main__ - global_steps 134000 - lr: 0.00001266  loss: 0.00027568
03/03/2022 04:19:46 - INFO - __main__ - global_steps 134200 - lr: 0.00001263  loss: 0.00030511
03/03/2022 04:20:41 - INFO - __main__ - global_steps 134400 - lr: 0.00001260  loss: 0.00030137
03/03/2022 04:21:35 - INFO - __main__ - global_steps 134600 - lr: 0.00001257  loss: 0.00027818
03/03/2022 04:22:29 - INFO - __main__ - global_steps 134800 - lr: 0.00001254  loss: 0.00029969
03/03/2022 04:23:23 - INFO - __main__ - global_steps 135000 - lr: 0.00001251  loss: 0.00033018
03/03/2022 04:24:18 - INFO - __main__ - global_steps 135200 - lr: 0.00001248  loss: 0.00027897
03/03/2022 04:25:10 - INFO - __main__ - global_steps 135400 - lr: 0.00001245  loss: 0.00029723
03/03/2022 04:26:04 - INFO - __main__ - global_steps 135600 - lr: 0.00001242  loss: 0.00029055
03/03/2022 04:26:56 - INFO - __main__ - global_steps 135800 - lr: 0.00001238  loss: 0.00031449
03/03/2022 04:27:48 - INFO - __main__ - global_steps 136000 - lr: 0.00001235  loss: 0.00031248
03/03/2022 04:28:43 - INFO - __main__ - global_steps 136200 - lr: 0.00001232  loss: 0.00031474
03/03/2022 04:29:35 - INFO - __main__ - global_steps 136400 - lr: 0.00001229  loss: 0.00030231
03/03/2022 04:30:27 - INFO - __main__ - global_steps 136600 - lr: 0.00001226  loss: 0.00030856
03/03/2022 04:31:20 - INFO - __main__ - global_steps 136800 - lr: 0.00001223  loss: 0.00030114
03/03/2022 04:32:15 - INFO - __main__ - global_steps 137000 - lr: 0.00001220  loss: 0.00027012
03/03/2022 04:33:09 - INFO - __main__ - global_steps 137200 - lr: 0.00001217  loss: 0.00029528
03/03/2022 04:34:02 - INFO - __main__ - global_steps 137400 - lr: 0.00001214  loss: 0.00027803
03/03/2022 04:34:56 - INFO - __main__ - global_steps 137600 - lr: 0.00001211  loss: 0.00030035
03/03/2022 04:35:48 - INFO - __main__ - global_steps 137800 - lr: 0.00001208  loss: 0.00032934
03/03/2022 04:36:41 - INFO - __main__ - global_steps 138000 - lr: 0.00001204  loss: 0.00030682
03/03/2022 04:37:31 - INFO - __main__ - global_steps 138200 - lr: 0.00001201  loss: 0.00029042
03/03/2022 04:38:25 - INFO - __main__ - global_steps 138400 - lr: 0.00001198  loss: 0.00030418
03/03/2022 04:39:20 - INFO - __main__ - global_steps 138600 - lr: 0.00001195  loss: 0.00028811
03/03/2022 04:40:12 - INFO - __main__ - global_steps 138800 - lr: 0.00001192  loss: 0.00029112
03/03/2022 04:41:03 - INFO - __main__ - global_steps 139000 - lr: 0.00001189  loss: 0.00032442
03/03/2022 04:41:57 - INFO - __main__ - global_steps 139200 - lr: 0.00001186  loss: 0.00030368
03/03/2022 04:42:51 - INFO - __main__ - global_steps 139400 - lr: 0.00001183  loss: 0.00029905
03/03/2022 04:43:45 - INFO - __main__ - global_steps 139600 - lr: 0.00001180  loss: 0.00028388
03/03/2022 04:44:38 - INFO - __main__ - global_steps 139800 - lr: 0.00001177  loss: 0.00029571
03/03/2022 04:45:29 - INFO - __main__ - global_steps 140000 - lr: 0.00001174  loss: 0.00032300
03/03/2022 04:46:23 - INFO - __main__ - global_steps 140200 - lr: 0.00001171  loss: 0.00030164
03/03/2022 04:47:17 - INFO - __main__ - global_steps 140400 - lr: 0.00001167  loss: 0.00028825
03/03/2022 04:47:31 - INFO - __main__ - ********** Evaluate Step 140452 **********
03/03/2022 04:47:31 - INFO - __main__ - ##--------------------- Dev
03/03/2022 04:50:51 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 04:50:51 - INFO - __main__ - f1 = 0.8199262234968315
03/03/2022 04:50:51 - INFO - __main__ - precision = 0.8177689469202388
03/03/2022 04:50:51 - INFO - __main__ - recall = 0.8220949119803331
03/03/2022 04:50:51 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 04:50:51 - INFO - __main__ - **--------------------- Dev End
03/03/2022 04:50:51 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-140452-spo-f1-0.8199262234968315
03/03/2022 04:50:51 - INFO - __main__ - *************************************
03/03/2022 04:51:33 - INFO - __main__ - global_steps 140600 - lr: 0.00001164  loss: 0.00025815
03/03/2022 04:52:26 - INFO - __main__ - global_steps 140800 - lr: 0.00001161  loss: 0.00025265
03/03/2022 04:53:19 - INFO - __main__ - global_steps 141000 - lr: 0.00001158  loss: 0.00024988
03/03/2022 04:54:12 - INFO - __main__ - global_steps 141200 - lr: 0.00001155  loss: 0.00022750
03/03/2022 04:55:06 - INFO - __main__ - global_steps 141400 - lr: 0.00001152  loss: 0.00022674
03/03/2022 04:55:58 - INFO - __main__ - global_steps 141600 - lr: 0.00001149  loss: 0.00023659
03/03/2022 04:56:52 - INFO - __main__ - global_steps 141800 - lr: 0.00001146  loss: 0.00022938
03/03/2022 04:57:47 - INFO - __main__ - global_steps 142000 - lr: 0.00001143  loss: 0.00024241
03/03/2022 04:58:40 - INFO - __main__ - global_steps 142200 - lr: 0.00001140  loss: 0.00027907
03/03/2022 04:59:34 - INFO - __main__ - global_steps 142400 - lr: 0.00001137  loss: 0.00023558
03/03/2022 05:00:29 - INFO - __main__ - global_steps 142600 - lr: 0.00001134  loss: 0.00023234
03/03/2022 05:01:21 - INFO - __main__ - global_steps 142800 - lr: 0.00001130  loss: 0.00024081
03/03/2022 05:02:15 - INFO - __main__ - global_steps 143000 - lr: 0.00001127  loss: 0.00025637
03/03/2022 05:03:09 - INFO - __main__ - global_steps 143200 - lr: 0.00001124  loss: 0.00023625
03/03/2022 05:04:03 - INFO - __main__ - global_steps 143400 - lr: 0.00001121  loss: 0.00023638
03/03/2022 05:04:56 - INFO - __main__ - global_steps 143600 - lr: 0.00001118  loss: 0.00027386
03/03/2022 05:05:51 - INFO - __main__ - global_steps 143800 - lr: 0.00001115  loss: 0.00027561
03/03/2022 05:06:44 - INFO - __main__ - global_steps 144000 - lr: 0.00001112  loss: 0.00023615
03/03/2022 05:07:37 - INFO - __main__ - global_steps 144200 - lr: 0.00001109  loss: 0.00025151
03/03/2022 05:08:31 - INFO - __main__ - global_steps 144400 - lr: 0.00001106  loss: 0.00025576
03/03/2022 05:09:23 - INFO - __main__ - global_steps 144600 - lr: 0.00001103  loss: 0.00025044
03/03/2022 05:10:16 - INFO - __main__ - global_steps 144800 - lr: 0.00001100  loss: 0.00024265
03/03/2022 05:11:09 - INFO - __main__ - global_steps 145000 - lr: 0.00001097  loss: 0.00027441
03/03/2022 05:12:03 - INFO - __main__ - global_steps 145200 - lr: 0.00001093  loss: 0.00023105
03/03/2022 05:12:57 - INFO - __main__ - global_steps 145400 - lr: 0.00001090  loss: 0.00024366
03/03/2022 05:13:50 - INFO - __main__ - global_steps 145600 - lr: 0.00001087  loss: 0.00026906
03/03/2022 05:14:44 - INFO - __main__ - global_steps 145800 - lr: 0.00001084  loss: 0.00023883
03/03/2022 05:15:39 - INFO - __main__ - global_steps 146000 - lr: 0.00001081  loss: 0.00023067
03/03/2022 05:16:31 - INFO - __main__ - global_steps 146200 - lr: 0.00001078  loss: 0.00026087
03/03/2022 05:17:26 - INFO - __main__ - global_steps 146400 - lr: 0.00001075  loss: 0.00024610
03/03/2022 05:18:18 - INFO - __main__ - global_steps 146600 - lr: 0.00001072  loss: 0.00025553
03/03/2022 05:19:11 - INFO - __main__ - global_steps 146800 - lr: 0.00001069  loss: 0.00023953
03/03/2022 05:20:04 - INFO - __main__ - global_steps 147000 - lr: 0.00001066  loss: 0.00023531
03/03/2022 05:20:57 - INFO - __main__ - global_steps 147200 - lr: 0.00001063  loss: 0.00027002
03/03/2022 05:21:52 - INFO - __main__ - global_steps 147400 - lr: 0.00001059  loss: 0.00024658
03/03/2022 05:22:44 - INFO - __main__ - global_steps 147600 - lr: 0.00001056  loss: 0.00025079
03/03/2022 05:23:39 - INFO - __main__ - global_steps 147800 - lr: 0.00001053  loss: 0.00024220
03/03/2022 05:24:31 - INFO - __main__ - global_steps 148000 - lr: 0.00001050  loss: 0.00025871
03/03/2022 05:25:26 - INFO - __main__ - global_steps 148200 - lr: 0.00001047  loss: 0.00022896
03/03/2022 05:26:18 - INFO - __main__ - global_steps 148400 - lr: 0.00001044  loss: 0.00026905
03/03/2022 05:27:11 - INFO - __main__ - global_steps 148600 - lr: 0.00001041  loss: 0.00025533
03/03/2022 05:28:04 - INFO - __main__ - global_steps 148800 - lr: 0.00001038  loss: 0.00026740
03/03/2022 05:28:56 - INFO - __main__ - global_steps 149000 - lr: 0.00001035  loss: 0.00026198
03/03/2022 05:29:49 - INFO - __main__ - global_steps 149200 - lr: 0.00001032  loss: 0.00025235
03/03/2022 05:30:42 - INFO - __main__ - global_steps 149400 - lr: 0.00001029  loss: 0.00027706
03/03/2022 05:31:35 - INFO - __main__ - global_steps 149600 - lr: 0.00001026  loss: 0.00027116
03/03/2022 05:32:27 - INFO - __main__ - global_steps 149800 - lr: 0.00001022  loss: 0.00025632
03/03/2022 05:33:20 - INFO - __main__ - global_steps 150000 - lr: 0.00001019  loss: 0.00026222
03/03/2022 05:34:11 - INFO - __main__ - global_steps 150200 - lr: 0.00001016  loss: 0.00025354
03/03/2022 05:35:06 - INFO - __main__ - global_steps 150400 - lr: 0.00001013  loss: 0.00024353
03/03/2022 05:35:58 - INFO - __main__ - global_steps 150600 - lr: 0.00001010  loss: 0.00025292
03/03/2022 05:36:53 - INFO - __main__ - global_steps 150800 - lr: 0.00001007  loss: 0.00026387
03/03/2022 05:37:46 - INFO - __main__ - global_steps 151000 - lr: 0.00001004  loss: 0.00026184
03/03/2022 05:38:39 - INFO - __main__ - global_steps 151200 - lr: 0.00001001  loss: 0.00025650
03/03/2022 05:38:52 - INFO - __main__ - ********** Evaluate Step 151256 **********
03/03/2022 05:38:52 - INFO - __main__ - ##--------------------- Dev
03/03/2022 05:42:11 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 05:42:11 - INFO - __main__ - f1 = 0.8194199161402866
03/03/2022 05:42:11 - INFO - __main__ - precision = 0.8090673741415096
03/03/2022 05:42:11 - INFO - __main__ - recall = 0.8300408270775719
03/03/2022 05:42:11 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 05:42:11 - INFO - __main__ - **--------------------- Dev End
03/03/2022 05:42:12 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-151256-spo-f1-0.8194199161402866
03/03/2022 05:42:12 - INFO - __main__ - *************************************
03/03/2022 05:42:53 - INFO - __main__ - global_steps 151400 - lr: 0.00000998  loss: 0.00020249
03/03/2022 05:43:45 - INFO - __main__ - global_steps 151600 - lr: 0.00000995  loss: 0.00021153
03/03/2022 05:44:37 - INFO - __main__ - global_steps 151800 - lr: 0.00000992  loss: 0.00020009
03/03/2022 05:45:29 - INFO - __main__ - global_steps 152000 - lr: 0.00000989  loss: 0.00020128
03/03/2022 05:46:22 - INFO - __main__ - global_steps 152200 - lr: 0.00000985  loss: 0.00021234
03/03/2022 05:47:15 - INFO - __main__ - global_steps 152400 - lr: 0.00000982  loss: 0.00020964
03/03/2022 05:48:08 - INFO - __main__ - global_steps 152600 - lr: 0.00000979  loss: 0.00019633
03/03/2022 05:49:04 - INFO - __main__ - global_steps 152800 - lr: 0.00000976  loss: 0.00020194
03/03/2022 05:49:58 - INFO - __main__ - global_steps 153000 - lr: 0.00000973  loss: 0.00022537
03/03/2022 05:50:51 - INFO - __main__ - global_steps 153200 - lr: 0.00000970  loss: 0.00020425
03/03/2022 05:51:45 - INFO - __main__ - global_steps 153400 - lr: 0.00000967  loss: 0.00021623
03/03/2022 05:52:40 - INFO - __main__ - global_steps 153600 - lr: 0.00000964  loss: 0.00020060
03/03/2022 05:53:33 - INFO - __main__ - global_steps 153800 - lr: 0.00000961  loss: 0.00018955
03/03/2022 05:54:25 - INFO - __main__ - global_steps 154000 - lr: 0.00000958  loss: 0.00020594
03/03/2022 05:55:20 - INFO - __main__ - global_steps 154200 - lr: 0.00000955  loss: 0.00022212
03/03/2022 05:56:14 - INFO - __main__ - global_steps 154400 - lr: 0.00000951  loss: 0.00020475
03/03/2022 05:57:08 - INFO - __main__ - global_steps 154600 - lr: 0.00000948  loss: 0.00020745
03/03/2022 05:58:02 - INFO - __main__ - global_steps 154800 - lr: 0.00000945  loss: 0.00022211
03/03/2022 05:58:55 - INFO - __main__ - global_steps 155000 - lr: 0.00000942  loss: 0.00021056
03/03/2022 05:59:50 - INFO - __main__ - global_steps 155200 - lr: 0.00000939  loss: 0.00020147
03/03/2022 06:00:44 - INFO - __main__ - global_steps 155400 - lr: 0.00000936  loss: 0.00021434
03/03/2022 06:01:40 - INFO - __main__ - global_steps 155600 - lr: 0.00000933  loss: 0.00019718
03/03/2022 06:02:34 - INFO - __main__ - global_steps 155800 - lr: 0.00000930  loss: 0.00020978
03/03/2022 06:03:27 - INFO - __main__ - global_steps 156000 - lr: 0.00000927  loss: 0.00020752
03/03/2022 06:04:20 - INFO - __main__ - global_steps 156200 - lr: 0.00000924  loss: 0.00022116
03/03/2022 06:05:12 - INFO - __main__ - global_steps 156400 - lr: 0.00000921  loss: 0.00021615
03/03/2022 06:06:04 - INFO - __main__ - global_steps 156600 - lr: 0.00000918  loss: 0.00021131
03/03/2022 06:06:57 - INFO - __main__ - global_steps 156800 - lr: 0.00000914  loss: 0.00021200
03/03/2022 06:07:51 - INFO - __main__ - global_steps 157000 - lr: 0.00000911  loss: 0.00022691
03/03/2022 06:08:43 - INFO - __main__ - global_steps 157200 - lr: 0.00000908  loss: 0.00019723
03/03/2022 06:09:38 - INFO - __main__ - global_steps 157400 - lr: 0.00000905  loss: 0.00021735
03/03/2022 06:10:31 - INFO - __main__ - global_steps 157600 - lr: 0.00000902  loss: 0.00021798
03/03/2022 06:11:24 - INFO - __main__ - global_steps 157800 - lr: 0.00000899  loss: 0.00021462
03/03/2022 06:12:19 - INFO - __main__ - global_steps 158000 - lr: 0.00000896  loss: 0.00023333
03/03/2022 06:13:11 - INFO - __main__ - global_steps 158200 - lr: 0.00000893  loss: 0.00022127
03/03/2022 06:14:04 - INFO - __main__ - global_steps 158400 - lr: 0.00000890  loss: 0.00023238
03/03/2022 06:14:57 - INFO - __main__ - global_steps 158600 - lr: 0.00000887  loss: 0.00019888
03/03/2022 06:15:51 - INFO - __main__ - global_steps 158800 - lr: 0.00000884  loss: 0.00023336
03/03/2022 06:16:44 - INFO - __main__ - global_steps 159000 - lr: 0.00000881  loss: 0.00021660
03/03/2022 06:17:37 - INFO - __main__ - global_steps 159200 - lr: 0.00000877  loss: 0.00022086
03/03/2022 06:18:30 - INFO - __main__ - global_steps 159400 - lr: 0.00000874  loss: 0.00022125
03/03/2022 06:19:23 - INFO - __main__ - global_steps 159600 - lr: 0.00000871  loss: 0.00025347
03/03/2022 06:20:17 - INFO - __main__ - global_steps 159800 - lr: 0.00000868  loss: 0.00020906
03/03/2022 06:21:11 - INFO - __main__ - global_steps 160000 - lr: 0.00000865  loss: 0.00024464
03/03/2022 06:22:04 - INFO - __main__ - global_steps 160200 - lr: 0.00000862  loss: 0.00020829
03/03/2022 06:22:59 - INFO - __main__ - global_steps 160400 - lr: 0.00000859  loss: 0.00021579
03/03/2022 06:23:56 - INFO - __main__ - global_steps 160600 - lr: 0.00000856  loss: 0.00023149
03/03/2022 06:24:48 - INFO - __main__ - global_steps 160800 - lr: 0.00000853  loss: 0.00022213
03/03/2022 06:25:41 - INFO - __main__ - global_steps 161000 - lr: 0.00000850  loss: 0.00022865
03/03/2022 06:26:33 - INFO - __main__ - global_steps 161200 - lr: 0.00000847  loss: 0.00022096
03/03/2022 06:27:26 - INFO - __main__ - global_steps 161400 - lr: 0.00000844  loss: 0.00022947
03/03/2022 06:28:18 - INFO - __main__ - global_steps 161600 - lr: 0.00000840  loss: 0.00021924
03/03/2022 06:29:13 - INFO - __main__ - global_steps 161800 - lr: 0.00000837  loss: 0.00021521
03/03/2022 06:30:07 - INFO - __main__ - global_steps 162000 - lr: 0.00000834  loss: 0.00021897
03/03/2022 06:30:24 - INFO - __main__ - ********** Evaluate Step 162060 **********
03/03/2022 06:30:24 - INFO - __main__ - ##--------------------- Dev
03/03/2022 06:33:42 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 06:33:42 - INFO - __main__ - f1 = 0.819880101402444
03/03/2022 06:33:42 - INFO - __main__ - precision = 0.812849222272561
03/03/2022 06:33:42 - INFO - __main__ - recall = 0.827033671363976
03/03/2022 06:33:42 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 06:33:42 - INFO - __main__ - **--------------------- Dev End
03/03/2022 06:33:43 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-162060-spo-f1-0.819880101402444
03/03/2022 06:33:43 - INFO - __main__ - *************************************
03/03/2022 06:34:21 - INFO - __main__ - global_steps 162200 - lr: 0.00000831  loss: 0.00017580
03/03/2022 06:35:15 - INFO - __main__ - global_steps 162400 - lr: 0.00000828  loss: 0.00018705
03/03/2022 06:36:08 - INFO - __main__ - global_steps 162600 - lr: 0.00000825  loss: 0.00015985
03/03/2022 06:37:02 - INFO - __main__ - global_steps 162800 - lr: 0.00000822  loss: 0.00016204
03/03/2022 06:37:54 - INFO - __main__ - global_steps 163000 - lr: 0.00000819  loss: 0.00018282
03/03/2022 06:38:46 - INFO - __main__ - global_steps 163200 - lr: 0.00000816  loss: 0.00018313
03/03/2022 06:39:39 - INFO - __main__ - global_steps 163400 - lr: 0.00000813  loss: 0.00018019
03/03/2022 06:40:33 - INFO - __main__ - global_steps 163600 - lr: 0.00000810  loss: 0.00018263
03/03/2022 06:41:26 - INFO - __main__ - global_steps 163800 - lr: 0.00000806  loss: 0.00017520
03/03/2022 06:42:18 - INFO - __main__ - global_steps 164000 - lr: 0.00000803  loss: 0.00017582
03/03/2022 06:43:10 - INFO - __main__ - global_steps 164200 - lr: 0.00000800  loss: 0.00017112
03/03/2022 06:44:06 - INFO - __main__ - global_steps 164400 - lr: 0.00000797  loss: 0.00019505
03/03/2022 06:45:00 - INFO - __main__ - global_steps 164600 - lr: 0.00000794  loss: 0.00018855
03/03/2022 06:45:53 - INFO - __main__ - global_steps 164800 - lr: 0.00000791  loss: 0.00019092
03/03/2022 06:46:46 - INFO - __main__ - global_steps 165000 - lr: 0.00000788  loss: 0.00018684
03/03/2022 06:47:38 - INFO - __main__ - global_steps 165200 - lr: 0.00000785  loss: 0.00017995
03/03/2022 06:48:31 - INFO - __main__ - global_steps 165400 - lr: 0.00000782  loss: 0.00019153
03/03/2022 06:49:25 - INFO - __main__ - global_steps 165600 - lr: 0.00000779  loss: 0.00017227
03/03/2022 06:50:21 - INFO - __main__ - global_steps 165800 - lr: 0.00000776  loss: 0.00017890
03/03/2022 06:51:14 - INFO - __main__ - global_steps 166000 - lr: 0.00000773  loss: 0.00018161
03/03/2022 06:52:06 - INFO - __main__ - global_steps 166200 - lr: 0.00000769  loss: 0.00018837
03/03/2022 06:53:00 - INFO - __main__ - global_steps 166400 - lr: 0.00000766  loss: 0.00018717
03/03/2022 06:53:55 - INFO - __main__ - global_steps 166600 - lr: 0.00000763  loss: 0.00017346
03/03/2022 06:54:48 - INFO - __main__ - global_steps 166800 - lr: 0.00000760  loss: 0.00016794
03/03/2022 06:55:42 - INFO - __main__ - global_steps 167000 - lr: 0.00000757  loss: 0.00019017
03/03/2022 06:56:35 - INFO - __main__ - global_steps 167200 - lr: 0.00000754  loss: 0.00017460
03/03/2022 06:57:28 - INFO - __main__ - global_steps 167400 - lr: 0.00000751  loss: 0.00019803
03/03/2022 06:58:19 - INFO - __main__ - global_steps 167600 - lr: 0.00000748  loss: 0.00018940
03/03/2022 06:59:12 - INFO - __main__ - global_steps 167800 - lr: 0.00000745  loss: 0.00018297
03/03/2022 07:00:07 - INFO - __main__ - global_steps 168000 - lr: 0.00000742  loss: 0.00018862
03/03/2022 07:01:00 - INFO - __main__ - global_steps 168200 - lr: 0.00000739  loss: 0.00019065
03/03/2022 07:01:53 - INFO - __main__ - global_steps 168400 - lr: 0.00000736  loss: 0.00018227
03/03/2022 07:02:48 - INFO - __main__ - global_steps 168600 - lr: 0.00000732  loss: 0.00016725
03/03/2022 07:03:40 - INFO - __main__ - global_steps 168800 - lr: 0.00000729  loss: 0.00018800
03/03/2022 07:04:34 - INFO - __main__ - global_steps 169000 - lr: 0.00000726  loss: 0.00017387
03/03/2022 07:05:29 - INFO - __main__ - global_steps 169200 - lr: 0.00000723  loss: 0.00019284
03/03/2022 07:06:22 - INFO - __main__ - global_steps 169400 - lr: 0.00000720  loss: 0.00019208
03/03/2022 07:07:16 - INFO - __main__ - global_steps 169600 - lr: 0.00000717  loss: 0.00016848
03/03/2022 07:08:09 - INFO - __main__ - global_steps 169800 - lr: 0.00000714  loss: 0.00017494
03/03/2022 07:09:03 - INFO - __main__ - global_steps 170000 - lr: 0.00000711  loss: 0.00017655
03/03/2022 07:09:56 - INFO - __main__ - global_steps 170200 - lr: 0.00000708  loss: 0.00017748
03/03/2022 07:10:50 - INFO - __main__ - global_steps 170400 - lr: 0.00000705  loss: 0.00017510
03/03/2022 07:11:42 - INFO - __main__ - global_steps 170600 - lr: 0.00000702  loss: 0.00019780
03/03/2022 07:12:37 - INFO - __main__ - global_steps 170800 - lr: 0.00000699  loss: 0.00018184
03/03/2022 07:13:31 - INFO - __main__ - global_steps 171000 - lr: 0.00000695  loss: 0.00019290
03/03/2022 07:14:24 - INFO - __main__ - global_steps 171200 - lr: 0.00000692  loss: 0.00017436
03/03/2022 07:15:17 - INFO - __main__ - global_steps 171400 - lr: 0.00000689  loss: 0.00019130
03/03/2022 07:16:10 - INFO - __main__ - global_steps 171600 - lr: 0.00000686  loss: 0.00017166
03/03/2022 07:17:03 - INFO - __main__ - global_steps 171800 - lr: 0.00000683  loss: 0.00018309
03/03/2022 07:17:57 - INFO - __main__ - global_steps 172000 - lr: 0.00000680  loss: 0.00019544
03/03/2022 07:18:50 - INFO - __main__ - global_steps 172200 - lr: 0.00000677  loss: 0.00018946
03/03/2022 07:19:43 - INFO - __main__ - global_steps 172400 - lr: 0.00000674  loss: 0.00017788
03/03/2022 07:20:35 - INFO - __main__ - global_steps 172600 - lr: 0.00000671  loss: 0.00020193
03/03/2022 07:21:29 - INFO - __main__ - global_steps 172800 - lr: 0.00000668  loss: 0.00019046
03/03/2022 07:21:46 - INFO - __main__ - ********** Evaluate Step 172864 **********
03/03/2022 07:21:46 - INFO - __main__ - ##--------------------- Dev
03/03/2022 07:25:05 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 07:25:05 - INFO - __main__ - f1 = 0.8201074792123962
03/03/2022 07:25:05 - INFO - __main__ - precision = 0.8081619605753867
03/03/2022 07:25:05 - INFO - __main__ - recall = 0.8324114315817204
03/03/2022 07:25:05 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 07:25:05 - INFO - __main__ - **--------------------- Dev End
03/03/2022 07:25:06 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-172864-spo-f1-0.8201074792123962
03/03/2022 07:25:06 - INFO - __main__ - *************************************
03/03/2022 07:25:43 - INFO - __main__ - global_steps 173000 - lr: 0.00000665  loss: 0.00016560
03/03/2022 07:26:37 - INFO - __main__ - global_steps 173200 - lr: 0.00000661  loss: 0.00015908
03/03/2022 07:27:31 - INFO - __main__ - global_steps 173400 - lr: 0.00000658  loss: 0.00014954
03/03/2022 07:28:25 - INFO - __main__ - global_steps 173600 - lr: 0.00000655  loss: 0.00014959
03/03/2022 07:29:18 - INFO - __main__ - global_steps 173800 - lr: 0.00000652  loss: 0.00013164
03/03/2022 07:30:10 - INFO - __main__ - global_steps 174000 - lr: 0.00000649  loss: 0.00014795
03/03/2022 07:31:04 - INFO - __main__ - global_steps 174200 - lr: 0.00000646  loss: 0.00015737
03/03/2022 07:31:59 - INFO - __main__ - global_steps 174400 - lr: 0.00000643  loss: 0.00015831
03/03/2022 07:32:52 - INFO - __main__ - global_steps 174600 - lr: 0.00000640  loss: 0.00014768
03/03/2022 07:33:46 - INFO - __main__ - global_steps 174800 - lr: 0.00000637  loss: 0.00013782
03/03/2022 07:34:40 - INFO - __main__ - global_steps 175000 - lr: 0.00000634  loss: 0.00014791
03/03/2022 07:35:35 - INFO - __main__ - global_steps 175200 - lr: 0.00000631  loss: 0.00014681
03/03/2022 07:36:27 - INFO - __main__ - global_steps 175400 - lr: 0.00000628  loss: 0.00014444
03/03/2022 07:37:20 - INFO - __main__ - global_steps 175600 - lr: 0.00000624  loss: 0.00015242
03/03/2022 07:38:12 - INFO - __main__ - global_steps 175800 - lr: 0.00000621  loss: 0.00015375
03/03/2022 07:39:07 - INFO - __main__ - global_steps 176000 - lr: 0.00000618  loss: 0.00014086
03/03/2022 07:40:01 - INFO - __main__ - global_steps 176200 - lr: 0.00000615  loss: 0.00017699
03/03/2022 07:40:55 - INFO - __main__ - global_steps 176400 - lr: 0.00000612  loss: 0.00015804
03/03/2022 07:41:51 - INFO - __main__ - global_steps 176600 - lr: 0.00000609  loss: 0.00013372
03/03/2022 07:42:43 - INFO - __main__ - global_steps 176800 - lr: 0.00000606  loss: 0.00014393
03/03/2022 07:43:38 - INFO - __main__ - global_steps 177000 - lr: 0.00000603  loss: 0.00016929
03/03/2022 07:44:32 - INFO - __main__ - global_steps 177200 - lr: 0.00000600  loss: 0.00014486
03/03/2022 07:45:27 - INFO - __main__ - global_steps 177400 - lr: 0.00000597  loss: 0.00017604
03/03/2022 07:46:20 - INFO - __main__ - global_steps 177600 - lr: 0.00000594  loss: 0.00013150
03/03/2022 07:47:15 - INFO - __main__ - global_steps 177800 - lr: 0.00000591  loss: 0.00014742
03/03/2022 07:48:09 - INFO - __main__ - global_steps 178000 - lr: 0.00000587  loss: 0.00015654
03/03/2022 07:49:02 - INFO - __main__ - global_steps 178200 - lr: 0.00000584  loss: 0.00016042
03/03/2022 07:49:55 - INFO - __main__ - global_steps 178400 - lr: 0.00000581  loss: 0.00015627
03/03/2022 07:50:49 - INFO - __main__ - global_steps 178600 - lr: 0.00000578  loss: 0.00014335
03/03/2022 07:51:42 - INFO - __main__ - global_steps 178800 - lr: 0.00000575  loss: 0.00014595
03/03/2022 07:52:35 - INFO - __main__ - global_steps 179000 - lr: 0.00000572  loss: 0.00016168
03/03/2022 07:53:26 - INFO - __main__ - global_steps 179200 - lr: 0.00000569  loss: 0.00016118
03/03/2022 07:54:20 - INFO - __main__ - global_steps 179400 - lr: 0.00000566  loss: 0.00014236
03/03/2022 07:55:12 - INFO - __main__ - global_steps 179600 - lr: 0.00000563  loss: 0.00015034
03/03/2022 07:56:05 - INFO - __main__ - global_steps 179800 - lr: 0.00000560  loss: 0.00015261
03/03/2022 07:57:01 - INFO - __main__ - global_steps 180000 - lr: 0.00000557  loss: 0.00015412
03/03/2022 07:57:54 - INFO - __main__ - global_steps 180200 - lr: 0.00000553  loss: 0.00016199
03/03/2022 07:58:49 - INFO - __main__ - global_steps 180400 - lr: 0.00000550  loss: 0.00014438
03/03/2022 07:59:42 - INFO - __main__ - global_steps 180600 - lr: 0.00000547  loss: 0.00015624
03/03/2022 08:00:37 - INFO - __main__ - global_steps 180800 - lr: 0.00000544  loss: 0.00015206
03/03/2022 08:01:33 - INFO - __main__ - global_steps 181000 - lr: 0.00000541  loss: 0.00014197
03/03/2022 08:02:26 - INFO - __main__ - global_steps 181200 - lr: 0.00000538  loss: 0.00015081
03/03/2022 08:03:18 - INFO - __main__ - global_steps 181400 - lr: 0.00000535  loss: 0.00014993
03/03/2022 08:04:10 - INFO - __main__ - global_steps 181600 - lr: 0.00000532  loss: 0.00016467
03/03/2022 08:05:03 - INFO - __main__ - global_steps 181800 - lr: 0.00000529  loss: 0.00015531
03/03/2022 08:05:56 - INFO - __main__ - global_steps 182000 - lr: 0.00000526  loss: 0.00015543
03/03/2022 08:06:51 - INFO - __main__ - global_steps 182200 - lr: 0.00000523  loss: 0.00014768
03/03/2022 08:07:44 - INFO - __main__ - global_steps 182400 - lr: 0.00000520  loss: 0.00016093
03/03/2022 08:08:38 - INFO - __main__ - global_steps 182600 - lr: 0.00000516  loss: 0.00016034
03/03/2022 08:09:32 - INFO - __main__ - global_steps 182800 - lr: 0.00000513  loss: 0.00013989
03/03/2022 08:10:26 - INFO - __main__ - global_steps 183000 - lr: 0.00000510  loss: 0.00013466
03/03/2022 08:11:18 - INFO - __main__ - global_steps 183200 - lr: 0.00000507  loss: 0.00016457
03/03/2022 08:12:11 - INFO - __main__ - global_steps 183400 - lr: 0.00000504  loss: 0.00014689
03/03/2022 08:13:06 - INFO - __main__ - global_steps 183600 - lr: 0.00000501  loss: 0.00015629
03/03/2022 08:13:24 - INFO - __main__ - ********** Evaluate Step 183668 **********
03/03/2022 08:13:24 - INFO - __main__ - ##--------------------- Dev
03/03/2022 08:16:43 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 08:16:43 - INFO - __main__ - f1 = 0.8187736793972917
03/03/2022 08:16:43 - INFO - __main__ - precision = 0.8122650883483825
03/03/2022 08:16:43 - INFO - __main__ - recall = 0.8253874182360951
03/03/2022 08:16:43 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 08:16:43 - INFO - __main__ - **--------------------- Dev End
03/03/2022 08:16:43 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-183668-spo-f1-0.8187736793972917
03/03/2022 08:16:43 - INFO - __main__ - *************************************
03/03/2022 08:17:20 - INFO - __main__ - global_steps 183800 - lr: 0.00000498  loss: 0.00013258
03/03/2022 08:18:11 - INFO - __main__ - global_steps 184000 - lr: 0.00000495  loss: 0.00012577
03/03/2022 08:19:05 - INFO - __main__ - global_steps 184200 - lr: 0.00000492  loss: 0.00014163
03/03/2022 08:19:58 - INFO - __main__ - global_steps 184400 - lr: 0.00000489  loss: 0.00014257
03/03/2022 08:20:54 - INFO - __main__ - global_steps 184600 - lr: 0.00000486  loss: 0.00012613
03/03/2022 08:21:47 - INFO - __main__ - global_steps 184800 - lr: 0.00000483  loss: 0.00013284
03/03/2022 08:22:40 - INFO - __main__ - global_steps 185000 - lr: 0.00000479  loss: 0.00012562
03/03/2022 08:23:33 - INFO - __main__ - global_steps 185200 - lr: 0.00000476  loss: 0.00013404
03/03/2022 08:24:30 - INFO - __main__ - global_steps 185400 - lr: 0.00000473  loss: 0.00011783
03/03/2022 08:25:23 - INFO - __main__ - global_steps 185600 - lr: 0.00000470  loss: 0.00014274
03/03/2022 08:26:17 - INFO - __main__ - global_steps 185800 - lr: 0.00000467  loss: 0.00013977
03/03/2022 08:27:10 - INFO - __main__ - global_steps 186000 - lr: 0.00000464  loss: 0.00011139
03/03/2022 08:28:03 - INFO - __main__ - global_steps 186200 - lr: 0.00000461  loss: 0.00012966
03/03/2022 08:28:58 - INFO - __main__ - global_steps 186400 - lr: 0.00000458  loss: 0.00011541
03/03/2022 08:29:54 - INFO - __main__ - global_steps 186600 - lr: 0.00000455  loss: 0.00012657
03/03/2022 08:30:49 - INFO - __main__ - global_steps 186800 - lr: 0.00000452  loss: 0.00011867
03/03/2022 08:31:42 - INFO - __main__ - global_steps 187000 - lr: 0.00000449  loss: 0.00012859
03/03/2022 08:32:34 - INFO - __main__ - global_steps 187200 - lr: 0.00000446  loss: 0.00013775
03/03/2022 08:33:27 - INFO - __main__ - global_steps 187400 - lr: 0.00000442  loss: 0.00014317
03/03/2022 08:34:21 - INFO - __main__ - global_steps 187600 - lr: 0.00000439  loss: 0.00013316
03/03/2022 08:35:15 - INFO - __main__ - global_steps 187800 - lr: 0.00000436  loss: 0.00012180
03/03/2022 08:36:07 - INFO - __main__ - global_steps 188000 - lr: 0.00000433  loss: 0.00013424
03/03/2022 08:37:01 - INFO - __main__ - global_steps 188200 - lr: 0.00000430  loss: 0.00012413
03/03/2022 08:37:54 - INFO - __main__ - global_steps 188400 - lr: 0.00000427  loss: 0.00013015
03/03/2022 08:38:47 - INFO - __main__ - global_steps 188600 - lr: 0.00000424  loss: 0.00013516
03/03/2022 08:39:41 - INFO - __main__ - global_steps 188800 - lr: 0.00000421  loss: 0.00012867
03/03/2022 08:40:34 - INFO - __main__ - global_steps 189000 - lr: 0.00000418  loss: 0.00012291
03/03/2022 08:41:27 - INFO - __main__ - global_steps 189200 - lr: 0.00000415  loss: 0.00013646
03/03/2022 08:42:20 - INFO - __main__ - global_steps 189400 - lr: 0.00000412  loss: 0.00012554
03/03/2022 08:43:14 - INFO - __main__ - global_steps 189600 - lr: 0.00000408  loss: 0.00014114
03/03/2022 08:44:08 - INFO - __main__ - global_steps 189800 - lr: 0.00000405  loss: 0.00012878
03/03/2022 08:45:01 - INFO - __main__ - global_steps 190000 - lr: 0.00000402  loss: 0.00013499
03/03/2022 08:45:53 - INFO - __main__ - global_steps 190200 - lr: 0.00000399  loss: 0.00013380
03/03/2022 08:46:46 - INFO - __main__ - global_steps 190400 - lr: 0.00000396  loss: 0.00011917
03/03/2022 08:47:40 - INFO - __main__ - global_steps 190600 - lr: 0.00000393  loss: 0.00012348
03/03/2022 08:48:35 - INFO - __main__ - global_steps 190800 - lr: 0.00000390  loss: 0.00012959
03/03/2022 08:49:28 - INFO - __main__ - global_steps 191000 - lr: 0.00000387  loss: 0.00013227
03/03/2022 08:50:21 - INFO - __main__ - global_steps 191200 - lr: 0.00000384  loss: 0.00012632
03/03/2022 08:51:15 - INFO - __main__ - global_steps 191400 - lr: 0.00000381  loss: 0.00013529
03/03/2022 08:52:07 - INFO - __main__ - global_steps 191600 - lr: 0.00000378  loss: 0.00012055
03/03/2022 08:53:02 - INFO - __main__ - global_steps 191800 - lr: 0.00000375  loss: 0.00013563
03/03/2022 08:53:55 - INFO - __main__ - global_steps 192000 - lr: 0.00000371  loss: 0.00012344
03/03/2022 08:54:49 - INFO - __main__ - global_steps 192200 - lr: 0.00000368  loss: 0.00011740
03/03/2022 08:55:42 - INFO - __main__ - global_steps 192400 - lr: 0.00000365  loss: 0.00011669
03/03/2022 08:56:36 - INFO - __main__ - global_steps 192600 - lr: 0.00000362  loss: 0.00012216
03/03/2022 08:57:28 - INFO - __main__ - global_steps 192800 - lr: 0.00000359  loss: 0.00012450
03/03/2022 08:58:23 - INFO - __main__ - global_steps 193000 - lr: 0.00000356  loss: 0.00013163
03/03/2022 08:59:18 - INFO - __main__ - global_steps 193200 - lr: 0.00000353  loss: 0.00011220
03/03/2022 09:00:11 - INFO - __main__ - global_steps 193400 - lr: 0.00000350  loss: 0.00014049
03/03/2022 09:01:04 - INFO - __main__ - global_steps 193600 - lr: 0.00000347  loss: 0.00012252
03/03/2022 09:01:56 - INFO - __main__ - global_steps 193800 - lr: 0.00000344  loss: 0.00013353
03/03/2022 09:02:50 - INFO - __main__ - global_steps 194000 - lr: 0.00000341  loss: 0.00013617
03/03/2022 09:03:47 - INFO - __main__ - global_steps 194200 - lr: 0.00000338  loss: 0.00013600
03/03/2022 09:04:41 - INFO - __main__ - global_steps 194400 - lr: 0.00000334  loss: 0.00011349
03/03/2022 09:05:00 - INFO - __main__ - ********** Evaluate Step 194472 **********
03/03/2022 09:05:00 - INFO - __main__ - ##--------------------- Dev
03/03/2022 09:08:19 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 09:08:19 - INFO - __main__ - f1 = 0.8175647566289335
03/03/2022 09:08:19 - INFO - __main__ - precision = 0.8155469159531719
03/03/2022 09:08:19 - INFO - __main__ - recall = 0.8195926072259542
03/03/2022 09:08:19 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 09:08:19 - INFO - __main__ - **--------------------- Dev End
03/03/2022 09:08:20 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-194472-spo-f1-0.8175647566289335
03/03/2022 09:08:20 - INFO - __main__ - *************************************
03/03/2022 09:08:53 - INFO - __main__ - global_steps 194600 - lr: 0.00000331  loss: 0.00012166
03/03/2022 09:09:47 - INFO - __main__ - global_steps 194800 - lr: 0.00000328  loss: 0.00011234
03/03/2022 09:10:41 - INFO - __main__ - global_steps 195000 - lr: 0.00000325  loss: 0.00010152
03/03/2022 09:11:36 - INFO - __main__ - global_steps 195200 - lr: 0.00000322  loss: 0.00010200
03/03/2022 09:12:27 - INFO - __main__ - global_steps 195400 - lr: 0.00000319  loss: 0.00012151
03/03/2022 09:13:22 - INFO - __main__ - global_steps 195600 - lr: 0.00000316  loss: 0.00010829
03/03/2022 09:14:15 - INFO - __main__ - global_steps 195800 - lr: 0.00000313  loss: 0.00011111
03/03/2022 09:15:10 - INFO - __main__ - global_steps 196000 - lr: 0.00000310  loss: 0.00011863
03/03/2022 09:16:03 - INFO - __main__ - global_steps 196200 - lr: 0.00000307  loss: 0.00011609
03/03/2022 09:16:55 - INFO - __main__ - global_steps 196400 - lr: 0.00000304  loss: 0.00012251
03/03/2022 09:17:47 - INFO - __main__ - global_steps 196600 - lr: 0.00000301  loss: 0.00010200
03/03/2022 09:18:41 - INFO - __main__ - global_steps 196800 - lr: 0.00000297  loss: 0.00011889
03/03/2022 09:19:34 - INFO - __main__ - global_steps 197000 - lr: 0.00000294  loss: 0.00011431
03/03/2022 09:20:26 - INFO - __main__ - global_steps 197200 - lr: 0.00000291  loss: 0.00010402
03/03/2022 09:21:19 - INFO - __main__ - global_steps 197400 - lr: 0.00000288  loss: 0.00010537
03/03/2022 09:22:12 - INFO - __main__ - global_steps 197600 - lr: 0.00000285  loss: 0.00010510
03/03/2022 09:23:05 - INFO - __main__ - global_steps 197800 - lr: 0.00000282  loss: 0.00010969
03/03/2022 09:23:59 - INFO - __main__ - global_steps 198000 - lr: 0.00000279  loss: 0.00010977
03/03/2022 09:24:52 - INFO - __main__ - global_steps 198200 - lr: 0.00000276  loss: 0.00010472
03/03/2022 09:25:47 - INFO - __main__ - global_steps 198400 - lr: 0.00000273  loss: 0.00010606
03/03/2022 09:26:39 - INFO - __main__ - global_steps 198600 - lr: 0.00000270  loss: 0.00011736
03/03/2022 09:27:32 - INFO - __main__ - global_steps 198800 - lr: 0.00000267  loss: 0.00012077
03/03/2022 09:28:25 - INFO - __main__ - global_steps 199000 - lr: 0.00000263  loss: 0.00011722
03/03/2022 09:29:19 - INFO - __main__ - global_steps 199200 - lr: 0.00000260  loss: 0.00010284
03/03/2022 09:30:13 - INFO - __main__ - global_steps 199400 - lr: 0.00000257  loss: 0.00009618
03/03/2022 09:31:06 - INFO - __main__ - global_steps 199600 - lr: 0.00000254  loss: 0.00011242
03/03/2022 09:31:59 - INFO - __main__ - global_steps 199800 - lr: 0.00000251  loss: 0.00010325
03/03/2022 09:32:54 - INFO - __main__ - global_steps 200000 - lr: 0.00000248  loss: 0.00009721
03/03/2022 09:33:49 - INFO - __main__ - global_steps 200200 - lr: 0.00000245  loss: 0.00010559
03/03/2022 09:34:44 - INFO - __main__ - global_steps 200400 - lr: 0.00000242  loss: 0.00010520
03/03/2022 09:35:38 - INFO - __main__ - global_steps 200600 - lr: 0.00000239  loss: 0.00010482
03/03/2022 09:36:34 - INFO - __main__ - global_steps 200800 - lr: 0.00000236  loss: 0.00011552
03/03/2022 09:37:30 - INFO - __main__ - global_steps 201000 - lr: 0.00000233  loss: 0.00010567
03/03/2022 09:38:23 - INFO - __main__ - global_steps 201200 - lr: 0.00000230  loss: 0.00010781
03/03/2022 09:39:17 - INFO - __main__ - global_steps 201400 - lr: 0.00000226  loss: 0.00010639
03/03/2022 09:40:10 - INFO - __main__ - global_steps 201600 - lr: 0.00000223  loss: 0.00012488
03/03/2022 09:41:02 - INFO - __main__ - global_steps 201800 - lr: 0.00000220  loss: 0.00010785
03/03/2022 09:41:54 - INFO - __main__ - global_steps 202000 - lr: 0.00000217  loss: 0.00010687
03/03/2022 09:42:44 - INFO - __main__ - global_steps 202200 - lr: 0.00000214  loss: 0.00011878
03/03/2022 09:43:36 - INFO - __main__ - global_steps 202400 - lr: 0.00000211  loss: 0.00010105
03/03/2022 09:44:31 - INFO - __main__ - global_steps 202600 - lr: 0.00000208  loss: 0.00010464
03/03/2022 09:45:23 - INFO - __main__ - global_steps 202800 - lr: 0.00000205  loss: 0.00011195
03/03/2022 09:46:15 - INFO - __main__ - global_steps 203000 - lr: 0.00000202  loss: 0.00010570
03/03/2022 09:47:08 - INFO - __main__ - global_steps 203200 - lr: 0.00000199  loss: 0.00010549
03/03/2022 09:48:01 - INFO - __main__ - global_steps 203400 - lr: 0.00000196  loss: 0.00009812
03/03/2022 09:48:54 - INFO - __main__ - global_steps 203600 - lr: 0.00000193  loss: 0.00011423
03/03/2022 09:49:48 - INFO - __main__ - global_steps 203800 - lr: 0.00000189  loss: 0.00010878
03/03/2022 09:50:41 - INFO - __main__ - global_steps 204000 - lr: 0.00000186  loss: 0.00009896
03/03/2022 09:51:36 - INFO - __main__ - global_steps 204200 - lr: 0.00000183  loss: 0.00009965
03/03/2022 09:52:30 - INFO - __main__ - global_steps 204400 - lr: 0.00000180  loss: 0.00011369
03/03/2022 09:53:23 - INFO - __main__ - global_steps 204600 - lr: 0.00000177  loss: 0.00011010
03/03/2022 09:54:15 - INFO - __main__ - global_steps 204800 - lr: 0.00000174  loss: 0.00011180
03/03/2022 09:55:10 - INFO - __main__ - global_steps 205000 - lr: 0.00000171  loss: 0.00010766
03/03/2022 09:56:05 - INFO - __main__ - global_steps 205200 - lr: 0.00000168  loss: 0.00010147
03/03/2022 09:56:24 - INFO - __main__ - ********** Evaluate Step 205276 **********
03/03/2022 09:56:24 - INFO - __main__ - ##--------------------- Dev
03/03/2022 09:59:47 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 09:59:47 - INFO - __main__ - f1 = 0.8204152211503957
03/03/2022 09:59:47 - INFO - __main__ - precision = 0.813032138469166
03/03/2022 09:59:47 - INFO - __main__ - recall = 0.8279336230738842
03/03/2022 09:59:47 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 09:59:47 - INFO - __main__ - **--------------------- Dev End
03/03/2022 09:59:47 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-205276-spo-f1-0.8204152211503957
03/03/2022 09:59:47 - INFO - __main__ - *************************************
03/03/2022 10:00:22 - INFO - __main__ - global_steps 205400 - lr: 0.00000165  loss: 0.00011357
03/03/2022 10:01:13 - INFO - __main__ - global_steps 205600 - lr: 0.00000162  loss: 0.00010596
03/03/2022 10:02:06 - INFO - __main__ - global_steps 205800 - lr: 0.00000159  loss: 0.00008410
03/03/2022 10:03:01 - INFO - __main__ - global_steps 206000 - lr: 0.00000155  loss: 0.00009662
03/03/2022 10:03:54 - INFO - __main__ - global_steps 206200 - lr: 0.00000152  loss: 0.00009267
03/03/2022 10:04:47 - INFO - __main__ - global_steps 206400 - lr: 0.00000149  loss: 0.00009185
03/03/2022 10:05:38 - INFO - __main__ - global_steps 206600 - lr: 0.00000146  loss: 0.00009322
03/03/2022 10:06:30 - INFO - __main__ - global_steps 206800 - lr: 0.00000143  loss: 0.00009949
03/03/2022 10:07:24 - INFO - __main__ - global_steps 207000 - lr: 0.00000140  loss: 0.00010478
03/03/2022 10:08:14 - INFO - __main__ - global_steps 207200 - lr: 0.00000137  loss: 0.00009750
03/03/2022 10:09:05 - INFO - __main__ - global_steps 207400 - lr: 0.00000134  loss: 0.00010137
03/03/2022 10:09:59 - INFO - __main__ - global_steps 207600 - lr: 0.00000131  loss: 0.00008849
03/03/2022 10:10:52 - INFO - __main__ - global_steps 207800 - lr: 0.00000128  loss: 0.00009608
03/03/2022 10:11:44 - INFO - __main__ - global_steps 208000 - lr: 0.00000125  loss: 0.00010248
03/03/2022 10:12:37 - INFO - __main__ - global_steps 208200 - lr: 0.00000122  loss: 0.00008455
03/03/2022 10:13:28 - INFO - __main__ - global_steps 208400 - lr: 0.00000118  loss: 0.00009305
03/03/2022 10:14:21 - INFO - __main__ - global_steps 208600 - lr: 0.00000115  loss: 0.00010523
03/03/2022 10:15:14 - INFO - __main__ - global_steps 208800 - lr: 0.00000112  loss: 0.00008984
03/03/2022 10:16:06 - INFO - __main__ - global_steps 209000 - lr: 0.00000109  loss: 0.00009786
03/03/2022 10:16:58 - INFO - __main__ - global_steps 209200 - lr: 0.00000106  loss: 0.00010861
03/03/2022 10:17:53 - INFO - __main__ - global_steps 209400 - lr: 0.00000103  loss: 0.00011353
03/03/2022 10:18:43 - INFO - __main__ - global_steps 209600 - lr: 0.00000100  loss: 0.00009187
03/03/2022 10:19:38 - INFO - __main__ - global_steps 209800 - lr: 0.00000097  loss: 0.00009650
03/03/2022 10:20:32 - INFO - __main__ - global_steps 210000 - lr: 0.00000094  loss: 0.00009151
03/03/2022 10:21:26 - INFO - __main__ - global_steps 210200 - lr: 0.00000091  loss: 0.00009175
03/03/2022 10:22:20 - INFO - __main__ - global_steps 210400 - lr: 0.00000088  loss: 0.00009656
03/03/2022 10:23:15 - INFO - __main__ - global_steps 210600 - lr: 0.00000085  loss: 0.00008836
03/03/2022 10:24:08 - INFO - __main__ - global_steps 210800 - lr: 0.00000081  loss: 0.00009227
03/03/2022 10:25:03 - INFO - __main__ - global_steps 211000 - lr: 0.00000078  loss: 0.00009311
03/03/2022 10:25:59 - INFO - __main__ - global_steps 211200 - lr: 0.00000075  loss: 0.00008275
03/03/2022 10:26:56 - INFO - __main__ - global_steps 211400 - lr: 0.00000072  loss: 0.00008846
03/03/2022 10:27:48 - INFO - __main__ - global_steps 211600 - lr: 0.00000069  loss: 0.00009225
03/03/2022 10:28:42 - INFO - __main__ - global_steps 211800 - lr: 0.00000066  loss: 0.00009361
03/03/2022 10:29:34 - INFO - __main__ - global_steps 212000 - lr: 0.00000063  loss: 0.00009489
03/03/2022 10:30:26 - INFO - __main__ - global_steps 212200 - lr: 0.00000060  loss: 0.00010303
03/03/2022 10:31:21 - INFO - __main__ - global_steps 212400 - lr: 0.00000057  loss: 0.00009541
03/03/2022 10:32:14 - INFO - __main__ - global_steps 212600 - lr: 0.00000054  loss: 0.00009347
03/03/2022 10:33:08 - INFO - __main__ - global_steps 212800 - lr: 0.00000051  loss: 0.00009319
03/03/2022 10:34:00 - INFO - __main__ - global_steps 213000 - lr: 0.00000048  loss: 0.00010029
03/03/2022 10:34:56 - INFO - __main__ - global_steps 213200 - lr: 0.00000044  loss: 0.00008860
03/03/2022 10:35:50 - INFO - __main__ - global_steps 213400 - lr: 0.00000041  loss: 0.00010100
03/03/2022 10:36:44 - INFO - __main__ - global_steps 213600 - lr: 0.00000038  loss: 0.00008019
03/03/2022 10:37:38 - INFO - __main__ - global_steps 213800 - lr: 0.00000035  loss: 0.00010703
03/03/2022 10:38:31 - INFO - __main__ - global_steps 214000 - lr: 0.00000032  loss: 0.00008972
03/03/2022 10:39:26 - INFO - __main__ - global_steps 214200 - lr: 0.00000029  loss: 0.00009926
03/03/2022 10:40:20 - INFO - __main__ - global_steps 214400 - lr: 0.00000026  loss: 0.00009651
03/03/2022 10:41:14 - INFO - __main__ - global_steps 214600 - lr: 0.00000023  loss: 0.00008631
03/03/2022 10:42:08 - INFO - __main__ - global_steps 214800 - lr: 0.00000020  loss: 0.00009572
03/03/2022 10:43:03 - INFO - __main__ - global_steps 215000 - lr: 0.00000017  loss: 0.00010116
03/03/2022 10:43:57 - INFO - __main__ - global_steps 215200 - lr: 0.00000014  loss: 0.00010375
03/03/2022 10:44:50 - INFO - __main__ - global_steps 215400 - lr: 0.00000010  loss: 0.00009401
03/03/2022 10:45:45 - INFO - __main__ - global_steps 215600 - lr: 0.00000007  loss: 0.00009826
03/03/2022 10:46:38 - INFO - __main__ - global_steps 215800 - lr: 0.00000004  loss: 0.00009075
03/03/2022 10:47:32 - INFO - __main__ - global_steps 216000 - lr: 0.00000001  loss: 0.00011350
03/03/2022 10:47:53 - INFO - __main__ - ********** Evaluate Step 216080 **********
03/03/2022 10:47:53 - INFO - __main__ - ##--------------------- Dev
03/03/2022 10:51:13 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 10:51:13 - INFO - __main__ - f1 = 0.8194461082735266
03/03/2022 10:51:13 - INFO - __main__ - precision = 0.8131849130011892
03/03/2022 10:51:13 - INFO - __main__ - recall = 0.8258044690284916
03/03/2022 10:51:13 - INFO - __main__ - --------------------------------------------------------------------------------
03/03/2022 10:51:13 - INFO - __main__ - **--------------------- Dev End
03/03/2022 10:51:13 - INFO - utils.utils - remove old ckpt: outputs/bert-bert-base-chinese/ckpt/step-216080-spo-f1-0.8194461082735266
03/03/2022 10:51:13 - INFO - __main__ - *************************************
